[
  {
    "id": 1,
    "question": "What is the primary purpose of Big O notation in algorithm analysis?",
    "options": [
      "To calculate the exact execution time of an algorithm in milliseconds",
      "To describe the upper bound of an algorithm's growth rate as input size increases",
      "To measure the specific amount of memory an algorithm consumes on the heap",
      "To count the number of lines of code required to implement the logic"
    ],
    "answer": "To describe the upper bound of an algorithm's growth rate as input size increases",
    "explanation": "Big O notation describes the limiting behavior of a function, specifically the worst-case scenario in terms of time or space complexity as the input size approaches infinity. It abstracts away hardware details to focus on algorithmic efficiency.",
    "difficulty": "Beginner"
  },
  {
    "id": 2,
    "question": "What is the time complexity of accessing an element in an array by its index?",
    "options": [
      "O(n)",
      "O(log n)",
      "O(n log n)",
      "O(1)"
    ],
    "answer": "O(1)",
    "explanation": "Arrays allow random access, meaning any element can be retrieved directly using its index in constant time, regardless of the array's size. This is because arrays utilize contiguous memory allocation.",
    "difficulty": "Beginner"
  },
  {
    "id": 3,
    "question": "Which condition is strictly required for a Binary Search algorithm to function correctly?",
    "options": [
      "The input list must contain only integers",
      "The input list must be sorted in ascending or descending order",
      "The input list must be implemented as a linked list",
      "The size of the input list must be a power of two"
    ],
    "answer": "The input list must be sorted in ascending or descending order",
    "explanation": "Binary search relies on the order of elements to repeatedly divide the search interval in half. If the list is unsorted, the algorithm cannot determine which half to discard, leading to incorrect results.",
    "difficulty": "Beginner"
  },
  {
    "id": 4,
    "question": "What is the worst-case time complexity of the Linear Search algorithm?",
    "options": [
      "O(1)",
      "O(log n)",
      "O(n)",
      "O(n²)"
    ],
    "answer": "O(n)",
    "explanation": "In the worst-case scenario, the target element is the last element in the list or not present at all, requiring the algorithm to check every single element once. This results in a linear relationship between time and input size.",
    "difficulty": "Beginner"
  },
  {
    "id": 5,
    "question": "Which data structure operates on the Last-In, First-Out (LIFO) principle?",
    "options": [
      "Queue",
      "Stack",
      "Linked List",
      "Priority Queue"
    ],
    "answer": "Stack",
    "explanation": "A Stack processes elements where the last element added is the first one to be removed. Operations are typically push (add to top) and pop (remove from top).",
    "difficulty": "Beginner"
  },
  {
    "id": 6,
    "question": "What distinguishes a Queue from a Stack regarding element removal?",
    "options": [
      "A Queue removes elements based on priority",
      "A Queue removes the most recently added element",
      "A Queue removes the least recently added element (First-In, First-Out)",
      "A Queue removes elements from the middle of the structure"
    ],
    "answer": "A Queue removes the least recently added element (First-In, First-Out)",
    "explanation": "Queues follow the FIFO principle, meaning elements are dequeued in the order they were enqueued. This is opposite to a Stack, which follows LIFO.",
    "difficulty": "Beginner"
  },
  {
    "id": 7,
    "question": "In the context of sorting algorithms, what does it mean for an algorithm to be 'stable'?",
    "options": [
      "It uses O(1) memory space",
      "It always finishes in O(n log n) time",
      "It preserves the relative order of records with equal keys",
      "It does not crash if the input list contains duplicates"
    ],
    "answer": "It preserves the relative order of records with equal keys",
    "explanation": "A stable sort maintains the original relative order of elements that compare as equal. For example, if two people have the same name, a stable sort keeps them in the same order they were in before sorting.",
    "difficulty": "Beginner"
  },
  {
    "id": 8,
    "question": "Which sorting algorithm has a worst-case time complexity of O(n²) but is considered efficient for small or nearly sorted datasets?",
    "options": [
      "Merge Sort",
      "Quick Sort",
      "Insertion Sort",
      "Heap Sort"
    ],
    "answer": "Insertion Sort",
    "explanation": "Insertion sort builds the final sorted array one item at a time. It is inefficient for large lists (O(n²)), but performs very well on small lists or lists that are already partially sorted.",
    "difficulty": "Beginner"
  },
  {
    "id": 9,
    "question": "What is the primary mechanism of Bubble Sort?",
    "options": [
      "Selecting the smallest element and swapping it to the front",
      "Dividing the array into halves and merging them",
      "Repeatedly swapping adjacent elements if they are in the wrong order",
      "Building a heap structure from the input data"
    ],
    "answer": "Repeatedly swapping adjacent elements if they are in the wrong order",
    "explanation": "Bubble sort works by repeatedly stepping through the list, comparing adjacent elements, and swapping them if they are in the wrong order. This pass through the list is repeated until the list is sorted.",
    "difficulty": "Beginner"
  },
  {
    "id": 10,
    "question": "Which algorithm design technique involves breaking a problem into subproblems, solving them recursively, and combining their solutions?",
    "options": [
      "Greedy Algorithms",
      "Dynamic Programming",
      "Divide and Conquer",
      "Backtracking"
    ],
    "answer": "Divide and Conquer",
    "explanation": "The Divide and Conquer strategy recursively breaks down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly. Merge Sort and Quick Sort are classic examples.",
    "difficulty": "Beginner"
  },
  {
    "id": 11,
    "question": "What is the time complexity of Merge Sort in the average and worst cases?",
    "options": [
      "O(n)",
      "O(n log n)",
      "O(n²)",
      "O(2ⁿ)"
    ],
    "answer": "O(n log n)",
    "explanation": "Merge Sort consistently divides the array in half (log n) and merges the halves (n), resulting in a time complexity of O(n log n) regardless of the initial order of the data.",
    "difficulty": "Beginner"
  },
  {
    "id": 12,
    "question": "Why is a Hash Map generally faster than a Binary Search Tree for data retrieval?",
    "options": [
      "It uses less memory",
      "It allows keys to be sorted",
      "It provides average O(1) access time using a hash function",
      "It does not handle collisions"
    ],
    "answer": "It provides average O(1) access time using a hash function",
    "explanation": "A Hash Map computes an index into an array of buckets using a hash function, allowing for near-constant time retrieval on average. Trees generally require O(log n) time for traversal.",
    "difficulty": "Beginner"
  },
  {
    "id": 13,
    "question": "What is a 'collision' in the context of Hash Tables?",
    "options": [
      "Two different keys hashing to the same index",
      "The hash table running out of memory",
      "Two identical keys being inserted",
      "The hash function returning a negative value"
    ],
    "answer": "Two different keys hashing to the same index",
    "explanation": "A collision occurs when the hash function generates the same index for two different keys. Handling collisions (via chaining or open addressing) is a critical part of hash table implementation.",
    "difficulty": "Beginner"
  },
  {
    "id": 14,
    "question": "Which of the following operations is NOT typically supported efficiently by a standard Singly Linked List?",
    "options": [
      "Insertion at the head",
      "Deletion of a node given a pointer to it",
      "Accessing the k-th element by index",
      "Traversal of all elements"
    ],
    "answer": "Accessing the k-th element by index",
    "explanation": "Linked lists do not support random access; to find the k-th element, one must traverse from the head node sequentially. Arrays are superior for index-based access.",
    "difficulty": "Beginner"
  },
  {
    "id": 15,
    "question": "What is the 'pivot' element in the Quick Sort algorithm?",
    "options": [
      "The first element of the array",
      "The element that divides the array into partitions for sorting",
      "The median value of the entire array",
      "The element that is already in its final sorted position"
    ],
    "answer": "The element that divides the array into partitions for sorting",
    "explanation": "The pivot is a chosen element used to partition the array; elements smaller than the pivot go left, and larger go right. The pivot's position is then finalized before the algorithm recurses on the sub-arrays.",
    "difficulty": "Beginner"
  },
  {
    "id": 16,
    "question": "Which graph traversal algorithm uses a Queue to explore nodes?",
    "options": [
      "Depth-First Search (DFS)",
      "Breadth-First Search (BFS)",
      "Dijkstra's Algorithm",
      "A* Search"
    ],
    "answer": "Breadth-First Search (BFS)",
    "explanation": "BFS explores all neighbors at the present depth prior to moving on to the nodes at the next depth level. This level-by-level approach requires a FIFO Queue data structure.",
    "difficulty": "Beginner"
  },
  {
    "id": 17,
    "question": "Which graph traversal algorithm uses a Stack (or recursion) to explore nodes?",
    "options": [
      "Breadth-First Search (BFS)",
      "Depth-First Search (DFS)",
      "Prim's Algorithm",
      "Kruskal's Algorithm"
    ],
    "answer": "Depth-First Search (DFS)",
    "explanation": "DFS explores as far as possible along each branch before backtracking. This LIFO behavior is naturally implemented using a Stack or the system's call stack via recursion.",
    "difficulty": "Beginner"
  },
  {
    "id": 18,
    "question": "What is the base case in a recursive algorithm?",
    "options": [
      "The step where the function calls itself",
      "The condition that stops the recursion to prevent infinite loops",
      "The initial input to the algorithm",
      "The final return value of the algorithm"
    ],
    "answer": "The condition that stops the recursion to prevent infinite loops",
    "explanation": "The base case is the condition under which the recursive function returns a value without calling itself again. Without it, the recursion would continue indefinitely until causing a stack overflow.",
    "difficulty": "Beginner"
  },
  {
    "id": 19,
    "question": "What is Space Complexity?",
    "options": [
      "The number of lines of code written",
      "The amount of memory space required by an algorithm to run",
      "The time taken to execute the code",
      "The size of the input file"
    ],
    "answer": "The amount of memory space required by an algorithm to run",
    "explanation": "Space complexity measures the total amount of memory space an algorithm needs relative to the input size. It includes both fixed space (code) and variable space (dynamic allocation/stack space).",
    "difficulty": "Beginner"
  },
  {
    "id": 20,
    "question": "Which sorting algorithm selects the smallest element from the unsorted portion and places it at the beginning?",
    "options": [
      "Bubble Sort",
      "Selection Sort",
      "Insertion Sort",
      "Quick Sort"
    ],
    "answer": "Selection Sort",
    "explanation": "Selection Sort divides the list into two parts: sorted and unsorted. It repeatedly selects the minimum element from the unsorted sublist and moves it to the end of the sorted sublist.",
    "difficulty": "Beginner"
  },
  {
    "id": 21,
    "question": "What is the defining characteristic of a Greedy Algorithm?",
    "options": [
      "It explores all possible paths to find the optimal solution",
      "It makes the locally optimal choice at each step with the hope of finding a global optimum",
      "It uses memoization to speed up calculations",
      "It requires a sorted input array"
    ],
    "answer": "It makes the locally optimal choice at each step with the hope of finding a global optimum",
    "explanation": "Greedy algorithms make the best choice at the current local moment without considering the bigger picture. While efficient, they do not always guarantee the globally optimal solution for all problems.",
    "difficulty": "Beginner"
  },
  {
    "id": 22,
    "question": "What is a Directed Acyclic Graph (DAG)?",
    "options": [
      "A graph with cycles that can be traversed in any direction",
      "A graph with directed edges and no cycles",
      "A tree where every node has two children",
      "A graph with no edges"
    ],
    "answer": "A graph with directed edges and no cycles",
    "explanation": "A DAG is a finite directed graph with no directed cycles. This means it is impossible to start at one vertex and follow a consistent direction that eventually loops back to that vertex.",
    "difficulty": "Beginner"
  },
  {
    "id": 23,
    "question": "Which data structure is typically used to implement a recursive algorithm iteratively?",
    "options": [
      "Queue",
      "Hash Table",
      "Stack",
      "Set"
    ],
    "answer": "Stack",
    "explanation": "Recursion relies on the system call stack to manage execution context. To convert this to an iterative solution, an explicit Stack data structure is required to manually track the state and sequence of operations.",
    "difficulty": "Beginner"
  },
  {
    "id": 24,
    "question": "What is a 'Leaf Node' in a tree data structure?",
    "options": [
      "A node with no children",
      "The topmost node of the tree",
      "A node with exactly one child",
      "A node that contains the maximum value"
    ],
    "answer": "A node with no children",
    "explanation": "A leaf node (or external node) is a node that has no child nodes. In contrast, an internal node is a node that has at least one child.",
    "difficulty": "Beginner"
  },
  {
    "id": 25,
    "question": "What is the worst-case time complexity of Quick Sort?",
    "options": [
      "O(n)",
      "O(n log n)",
      "O(n²)",
      "O(log n)"
    ],
    "answer": "O(n²)",
    "explanation": "Quick Sort degrades to O(n²) when the pivot selection results in highly unbalanced partitions (e.g., the smallest or largest element is consistently picked as the pivot in a sorted list).",
    "difficulty": "Beginner"
  },
  {
    "id": 26,
    "question": "In algorithmic complexity, what does 'log n' represent?",
    "options": [
      "Linear growth",
      "Logarithmic growth",
      "Exponential growth",
      "Factorial growth"
    ],
    "answer": "Logarithmic growth",
    "explanation": "Logarithmic complexity means the time taken grows very slowly as the input size increases. Algorithms that halve the input at each step (like Binary Search) typically exhibit O(log n) complexity.",
    "difficulty": "Beginner"
  },
  {
    "id": 27,
    "question": "What is Dynamic Programming primarily used to optimize?",
    "options": [
      "Algorithms that are too slow due to recursion on overlapping subproblems",
      "Algorithms that use too much disk space",
      "Network latency in distributed systems",
      "Database query syntax"
    ],
    "answer": "Algorithms that are too slow due to recursion on overlapping subproblems",
    "explanation": "Dynamic programming optimizes algorithms by storing the results of expensive function calls (memoization) and reusing them when the same inputs occur again, avoiding redundant calculations.",
    "difficulty": "Beginner"
  },
  {
    "id": 28,
    "question": "Which of the following data structures is Non-Linear?",
    "options": [
      "Array",
      "Stack",
      "Tree",
      "Queue"
    ],
    "answer": "Tree",
    "explanation": "Non-linear data structures do not store data in a sequential sequence. Trees and Graphs are non-linear because elements are arranged in a hierarchical or networked relationship, unlike Arrays, Stacks, or Queues.",
    "difficulty": "Beginner"
  },
  {
    "id": 29,
    "question": "What is the time complexity of inserting an element at the beginning of a standard Singly Linked List (assuming we have a head pointer)?",
    "options": [
      "O(n)",
      "O(log n)",
      "O(n²)",
      "O(1)"
    ],
    "answer": "O(1)",
    "explanation": "Inserting at the head of a linked list involves creating a new node and pointing its 'next' reference to the current head, then updating the head pointer. This operation requires a constant amount of time regardless of list length.",
    "difficulty": "Beginner"
  },
  {
    "id": 30,
    "question": "What is a 'key' in the context of data structures like Maps or Dictionaries?",
    "options": [
      "The value returned by the search function",
      "The unique identifier used to map to a specific value",
      "The encryption password for the structure",
      "The index of the array in the underlying implementation"
    ],
    "answer": "The unique identifier used to map to a specific value",
    "explanation": "In associative arrays, the key is the input field used to look up the associated value. Keys must be unique within the map to ensure consistent data retrieval.",
    "difficulty": "Beginner"
  },
  {
    "id": 31,
    "question": "Which sorting algorithm is considered 'in-place' and requires only O(1) additional memory?",
    "options": [
      "Merge Sort",
      "Quick Sort (standard implementation)",
      "Radix Sort",
      "Counting Sort"
    ],
    "answer": "Quick Sort (standard implementation)",
    "explanation": "In-place sorting algorithms transform the input data structure using only O(1) extra memory. Quick Sort typically sorts by partitioning within the existing array space, unlike Merge Sort which requires auxiliary arrays.",
    "difficulty": "Beginner"
  },
  {
    "id": 32,
    "question": "What is the primary disadvantage of using an Adjacency Matrix to represent a graph?",
    "options": [
      "It cannot represent weighted edges",
      "It uses O(V²) space regardless of the number of edges",
      "Checking if two nodes are connected is too slow",
      "It is difficult to implement"
    ],
    "answer": "It uses O(V²) space regardless of the number of edges",
    "explanation": "An adjacency matrix stores a value for every possible pair of vertices. If the graph has few edges (sparse graph), this results in significant wasted memory compared to an adjacency list.",
    "difficulty": "Beginner"
  },
  {
    "id": 33,
    "question": "What is an 'iteration' in programming?",
    "options": [
      "A recursive function call",
      "The single execution of a loop body",
      "The initialization of a variable",
      "The compilation process of code"
    ],
    "answer": "The single execution of a loop body",
    "explanation": "An iteration refers to one cycle of a loop (such as a for or while loop). In each iteration, the statements within the loop body are executed once.",
    "difficulty": "Beginner"
  },
  {
    "id": 34,
    "question": "Which scenario best describes the use of a 'Sentinel' value in searching?",
    "options": [
      "Searching a sorted list using binary search",
      "Placing a target value at the end of an unsorted list to avoid bounds checking",
      "Using a variable to count the number of comparisons",
      "Encrypting the data before searching"
    ],
    "answer": "Placing a target value at the end of an unsorted list to avoid bounds checking",
    "explanation": "A sentinel linear search appends the target to the end of the list. This guarantees the search will eventually find the target, eliminating the need to check if the index has exceeded the array bounds within the loop.",
    "difficulty": "Beginner"
  },
  {
    "id": 35,
    "question": "Why is 'Modulo Arithmetic' frequently used in Hash functions?",
    "options": [
      "To encrypt the key",
      "To ensure the resulting index is within the bounds of the array",
      "To sort the keys alphabetically",
      "To increase the collision rate"
    ],
    "answer": "To ensure the resulting index is within the bounds of the array",
    "explanation": "Hash functions generate potentially large integers. Using the modulo operator (`hash_code % array_size`) maps these large integers to a valid index range (0 to array_size - 1) for the storage array.",
    "difficulty": "Beginner"
  },
  {
    "id": 36,
    "question": "Which sorting algorithm is characterized by a worst-case time complexity of O(n^2) but is often preferred for small datasets or nearly sorted data due to low overhead and cache efficiency?",
    "options": [
      "Merge Sort",
      "Insertion Sort",
      "Quick Sort",
      "Heap Sort"
    ],
    "answer": "Insertion Sort",
    "explanation": "Insertion sort has O(n^2) worst-case complexity but performs linearly on nearly sorted data. Its in-place nature and lack of recursive overhead make it faster than O(n log n) algorithms for small inputs.",
    "difficulty": "Intermediate"
  },
  {
    "id": 37,
    "question": "In graph algorithms, why does Dijkstra's algorithm fail to correctly compute shortest paths when negative edge weights are present?",
    "options": [
      "The greedy approach assumes that once a node is processed, its distance is finalized",
      "Negative weights cause the priority queue to enter an infinite loop",
      "The relaxation step cannot handle subtraction operations",
      "The algorithm requires the graph to be a Directed Acyclic Graph (DAG)"
    ],
    "answer": "The greedy approach assumes that once a node is processed, its distance is finalized",
    "explanation": "Dijkstra's greedy strategy extracts the minimum distance node and assumes it is optimal. A negative edge leading to a 'processed' node could yield a shorter path, invalidating this assumption.",
    "difficulty": "Intermediate"
  },
  {
    "id": 38,
    "question": "What is the primary time complexity advantage of using a Disjoint Set Union (DSU) data structure with path compression and union by rank over a naive implementation?",
    "options": [
      "Reduced time complexity from O(V^2) to O(V log V)",
      "Amortized constant time O(α(n)) per operation, where α is the inverse Ackermann function",
      "Guaranteed logarithmic time O(log n) for all operations",
      "Elimination of the need to initialize the parent array"
    ],
    "answer": "Amortized constant time O(α(n)) per operation, where α is the inverse Ackermann function",
    "explanation": "While a naive DSU takes O(n) per find operation, path compression and union by rank optimize the structure so efficiently that the amortized cost per operation is effectively constant.",
    "difficulty": "Intermediate"
  },
  {
    "id": 39,
    "question": "When applying the Master Theorem to solve the recurrence T(n) = aT(n/b) + f(n), what condition must be met for Case 3 to apply, assuming regularity holds?",
    "options": [
      "f(n) is O(n^(log_b a - ε)) for some ε > 0",
      "f(n) is Θ(n^(log_b a) * log^k n)",
      "f(n) is Ω(n^(log_b a + ε)) for some ε > 0",
      "f(n) grows strictly slower than n^(log_b a)"
    ],
    "answer": "f(n) is Ω(n^(log_b a + ε)) for some ε > 0",
    "explanation": "Case 3 applies when the cost of the work outside the recursive calls dominates the cost inside the recursion (f(n) is polynomially larger than n^(log_b a)).",
    "difficulty": "Intermediate"
  },
  {
    "id": 40,
    "question": "In the context of string matching algorithms, what is the primary purpose of the 'prefix function' (or failure function) in the Knuth-Morris-Pratt (KMP) algorithm?",
    "options": [
      "To calculate the hash value of the pattern for rolling comparison",
      "To determine the longest proper prefix of the pattern that is also a suffix for every sub-pattern",
      "To identify the starting indices of all occurrences in linear time",
      "To build a suffix automaton for the input text"
    ],
    "answer": "To determine the longest proper prefix of the pattern that is also a suffix for every sub-pattern",
    "explanation": "The prefix function allows the algorithm to skip unnecessary comparisons by shifting the pattern based on previously matched characters, avoiding backtracking in the text.",
    "difficulty": "Intermediate"
  },
  {
    "id": 41,
    "question": "Which property of the Red-Black Tree guarantees that the longest path from the root to a leaf is no more than twice the length of the shortest path?",
    "options": [
      "The root is always black",
      "Red nodes cannot have red children (no double red)",
      "Every leaf (NIL) is black",
      "Both the root and leaves must be red"
    ],
    "answer": "Red nodes cannot have red children (no double red)",
    "explanation": "This property ensures that red nodes act as 'shortcuts' or markers between black nodes, limiting the imbalance and ensuring the tree height remains logarithmic.",
    "difficulty": "Intermediate"
  },
  {
    "id": 42,
    "question": "To prove that a problem X is NP-Complete, which of the following steps is logically required?",
    "options": [
      "Prove X can be solved in polynomial time and reduce X to a known NP-Complete problem",
      "Prove X is in NP and reduce a known NP-Complete problem to X",
      "Prove X is in NP and reduce X to P",
      "Show that X is harder than P and is undecidable"
    ],
    "answer": "Prove X is in NP and reduce a known NP-Complete problem to X",
    "explanation": "To prove NP-Completeness, you must show the problem is in NP (verifiable in poly-time) and that every problem in NP reduces to it (usually by reducing a known NP-Complete problem to it).",
    "difficulty": "Intermediate"
  },
  {
    "id": 43,
    "question": "In the Floyd-Warshall algorithm for finding all-pairs shortest paths, what is the specific role of the intermediate vertex 'k' in the triple loop structure?",
    "options": [
      "It represents the destination vertex being relaxed",
      "It limits the path considered to vertices with an index less than or equal to k",
      "It acts as the source node for the current iteration",
      "It resets the distance matrix to prevent negative cycles"
    ],
    "answer": "It limits the path considered to vertices with an index less than or equal to k",
    "explanation": "The DP state `dist[i][j]` is updated to consider paths that go through vertex `k` only if `{1, ..., k-1}` was allowed previously, gradually expanding the set of allowed intermediate nodes.",
    "difficulty": "Intermediate"
  },
  {
    "id": 44,
    "question": "Why is the pivot selection strategy crucial for the performance of the QuickSort algorithm?",
    "options": [
      "It determines whether the algorithm uses recursion or iteration",
      "It impacts the space complexity of the auxiliary array",
      "A bad pivot can lead to O(n^2) time complexity in the worst case",
      "The pivot defines the stability of the sorting algorithm"
    ],
    "answer": "A bad pivot can lead to O(n^2) time complexity in the worst case",
    "explanation": "If the pivot is consistently the smallest or largest element (e.g., in a sorted array with a poor pivot choice), the partition degrades to 1 vs n-1, resulting in quadratic time.",
    "difficulty": "Intermediate"
  },
  {
    "id": 45,
    "question": "What distinguishes a 'Greedy' algorithm from 'Dynamic Programming' when solving optimization problems?",
    "options": [
      "Greedy algorithms work on sorted inputs, while DP does not",
      "Greedy algorithms make the locally optimal choice at each step hoping for a global optimum; DP explores all subproblems",
      "Greedy algorithms have O(n) complexity, while DP is always O(n^2)",
      "Greedy algorithms require a top-down approach, while DP is strictly bottom-up"
    ],
    "answer": "Greedy algorithms make the locally optimal choice at each step hoping for a global optimum; DP explores all subproblems",
    "explanation": "Greedy algorithms commit to a path immediately based on local criteria, whereas DP calculates the solution to every subproblem to ensure global optimality.",
    "difficulty": "Intermediate"
  },
  {
    "id": 46,
    "question": "Which graph traversal algorithm is guaranteed to find the shortest path in terms of the number of edges in an unweighted, unconnected graph?",
    "options": [
      "Depth-First Search (DFS)",
      "Breadth-First Search (BFS)",
      "Prim's Algorithm",
      "Dijkstra's Algorithm"
    ],
    "answer": "Breadth-First Search (BFS)",
    "explanation": "BFS explores nodes layer by layer (level-order). The first time a node is discovered, the path taken is guaranteed to be the shortest in terms of edge count.",
    "difficulty": "Intermediate"
  },
  {
    "id": 47,
    "question": "In the context of Minimum Spanning Trees (MST), what does the 'Cut Property' state?",
    "options": [
      "The heaviest edge crossing any cut must be included in the MST",
      "For any cut of the graph, the minimum weight edge crossing that cut is part of the MST",
      "A cut must divide the graph into two sets of equal vertices",
      "The sum of weights of edges crossing a cut is zero"
    ],
    "answer": "For any cut of the graph, the minimum weight edge crossing that cut is part of the MST",
    "explanation": "This property is the basis for correctness in algorithms like Kruskal's and Prim's: safely adding the lightest edge crossing a cut cannot create a cycle.",
    "difficulty": "Intermediate"
  },
  {
    "id": 48,
    "question": "Which technique is used to solve the 'Longest Increasing Subsequence' problem in O(n log n) time?",
    "options": [
      "Dynamic Programming with a 2D state array",
      "Depth-First Search with memoization",
      "Maintaining a dynamic array of the smallest possible tail value for all increasing subsequences of a given length",
      "Using a Segment Tree to query range maximums"
    ],
    "answer": "Maintaining a dynamic array of the smallest possible tail value for all increasing subsequences of a given length",
    "explanation": "By keeping track of the smallest tail of active sequences of length `i`, we can use binary search to replace elements, reducing the complexity from O(n^2) to O(n log n).",
    "difficulty": "Intermediate"
  },
  {
    "id": 49,
    "question": "What is the primary space complexity disadvantage of using Merge Sort over Heap Sort for large datasets stored in memory?",
    "options": [
      "Merge Sort is not a stable sort",
      "Merge Sort requires O(n) auxiliary space to merge subarrays",
      "Merge Sort has a worse time complexity of O(n^2)",
      "Merge Sort cannot be implemented iteratively"
    ],
    "answer": "Merge Sort requires O(n) auxiliary space to merge subarrays",
    "explanation": "Standard Merge Sort requires an auxiliary array of size n to hold the merged results during the divide-and-conquer process, whereas Heap Sort is strictly in-place O(1).",
    "difficulty": "Intermediate"
  },
  {
    "id": 50,
    "question": "In the Rabin-Karp string matching algorithm, what technique is used to update the hash value of the window in O(1) time?",
    "options": [
      "Recomputing the hash from scratch for every new position",
      "Using a rolling hash that subtracts the leading character and adds the trailing character",
      "Applying the Knuth-Morris-Pratt failure function",
      "Storing hash values in a binary search tree"
    ],
    "answer": "Using a rolling hash that subtracts the leading character and adds the trailing character",
    "explanation": "The rolling hash uses modular arithmetic to remove the contribution of the outgoing character and add the incoming character, allowing constant-time updates.",
    "difficulty": "Intermediate"
  },
  {
    "id": 51,
    "question": "When performing a Depth-First Search (DFS) on a graph to detect cycles, what is the distinguishing feature of a 'back edge' in a Directed Acyclic Graph (DAG)?",
    "options": [
      "An edge connecting a vertex to an ancestor of itself in the DFS tree",
      "An edge connecting two vertices in the same DFS tree level",
      "An edge connecting a vertex to a disconnected component",
      "An edge connecting a vertex to a leaf node"
    ],
    "answer": "An edge connecting a vertex to an ancestor of itself in the DFS tree",
    "explanation": "In a directed graph, encountering an edge that points to an ancestor currently in the recursion stack indicates a cycle. This edge is known as a back edge.",
    "difficulty": "Intermediate"
  },
  {
    "id": 52,
    "question": "Which of the following correctly describes the time complexity of building a Heap from an unordered array of n elements?",
    "options": [
      "O(n log n)",
      "O(n)",
      "O(log n)",
      "O(n^2)"
    ],
    "answer": "O(n)",
    "explanation": "While building a heap via individual insertion takes O(n log n), using the 'heapify' procedure (sift down) on all non-leaf nodes starting from the bottom up achieves O(n) linear time complexity.",
    "difficulty": "Intermediate"
  },
  {
    "id": 53,
    "question": "In the context of NP-Completeness, what is the relationship between the 'Clique' problem and the 'Independent Set' problem?",
    "options": [
      "They are complements; an Independent Set in a graph G corresponds to a Clique in the complement of G",
      "They are identical; a clique is just an independent set with directed edges",
      "A clique is a matching problem, while an independent set is a flow problem",
      "A clique exists only in bipartite graphs, while an independent set exists in complete graphs"
    ],
    "answer": "They are complements; an Independent Set in a graph G corresponds to a Clique in the complement of G",
    "explanation": "In the complement graph, edges become non-edges and vice versa. Therefore, a set of mutually adjacent vertices (Clique) in the original graph becomes a set of mutually non-adjacent vertices (Independent Set) in the complement.",
    "difficulty": "Intermediate"
  },
  {
    "id": 54,
    "question": "What is the 'Exchange Argument' used to prove in the context of Greedy Algorithms?",
    "options": [
      "That the problem can be solved using a sorting step",
      "That exchanging a component of a greedy solution with a component of an optimal solution does not worsen the result",
      "That the memory usage can be exchanged for CPU time",
      "That the algorithm converges in logarithmic time"
    ],
    "answer": "That exchanging a component of a greedy solution with a component of an optimal solution does not worsen the result",
    "explanation": "The exchange argument shows that if you take an optimal solution and modify it to look more like the greedy solution, the cost does not increase, proving the greedy solution is also optimal.",
    "difficulty": "Intermediate"
  },
  {
    "id": 55,
    "question": "Which algorithm is most efficient for finding the strongly connected components (SCCs) of a directed graph in linear time O(V + E)?",
    "options": [
      "Prim's Algorithm",
      "Kosaraju's Algorithm",
      "Bellman-Ford Algorithm",
      "Floyd-Warshall Algorithm"
    ],
    "answer": "Kosaraju's Algorithm",
    "explanation": "Kosaraju's algorithm performs two DFS passes (one on the original graph, one on the transpose) to identify SCCs in linear time. Tarjan's algorithm is another linear-time alternative.",
    "difficulty": "Intermediate"
  },
  {
    "id": 56,
    "question": "What is the time complexity of finding the minimum spanning tree (MST) of a dense graph using Prim's algorithm with an adjacency matrix and no priority queue optimization?",
    "options": [
      "O(E log V)",
      "O(V^2)",
      "O(E + V log V)",
      "O(V^3)"
    ],
    "answer": "O(V^2)",
    "explanation": "In the unoptimized version with an adjacency matrix, finding the minimum weight edge connecting the tree to a non-tree vertex takes O(V) time, repeated V times, resulting in O(V^2).",
    "difficulty": "Intermediate"
  },
  {
    "id": 57,
    "question": "In the context of segment trees, what operation allows a node to store information about its children without explicitly traversing to the leaves during a range query?",
    "options": [
      "Path compression",
      "Lazy propagation",
      "Binary search",
      "Hashing"
    ],
    "answer": "Lazy propagation",
    "explanation": "Lazy propagation allows updates to be applied to a node and deferred to its children only when necessary, significantly speeding up range updates and queries.",
    "difficulty": "Intermediate"
  },
  {
    "id": 58,
    "question": "Which method is used by the Counting Sort algorithm to achieve O(n) time complexity, and why is it not a comparison-based sort?",
    "options": [
      "It uses a hash map to store elements",
      "It counts the frequency of each distinct key and uses prefix sums to place elements",
      "It divides the array and merges sorted halves",
      "It selects a pivot and partitions the array"
    ],
    "answer": "It counts the frequency of each distinct key and uses prefix sums to place elements",
    "explanation": "Counting sort operates by determining the integer range of input keys and using arithmetic to calculate positions, bypassing the O(n log n) lower bound of comparison sorts.",
    "difficulty": "Intermediate"
  },
  {
    "id": 59,
    "question": "In the context of the Knapsack problem, what is the defining constraint that separates the 0/1 Knapsack from the Fractional Knapsack?",
    "options": [
      "The weight limit of the knapsack",
      "Whether items can be broken into fractions or must be taken whole",
      "The number of items available",
      "The value-to-weight ratio of the items"
    ],
    "answer": "Whether items can be broken into fractions or must be taken whole",
    "explanation": "0/1 Knapsack requires dynamic programming because taking an item is an indivisible binary choice, whereas Fractional Knapsack can be solved greedily by taking parts of items.",
    "difficulty": "Intermediate"
  },
  {
    "id": 60,
    "question": "What distinguishes a 'Bipartite Graph' from other graphs?",
    "options": [
      "All vertices have the same degree",
      "The vertex set can be partitioned into two disjoint sets such that every edge connects a vertex in one set to a vertex in the other",
      "It contains exactly two connected components",
      "It can be colored using only two colors such that no adjacent vertices share the same color"
    ],
    "answer": "The vertex set can be partitioned into two disjoint sets such that every edge connects a vertex in one set to a vertex in the other",
    "explanation": "This structural definition is equivalent to being 2-colorable. It is crucial for matching problems like the Hopcroft-Karp algorithm.",
    "difficulty": "Intermediate"
  },
  {
    "id": 61,
    "question": "When solving the 'Traveling Salesman Problem' (TSP) using Dynamic Programming with a bitmask, what does the state dp[mask][i] represent?",
    "options": [
      "The minimum distance from node i to node 0",
      "The minimum cost to visit all nodes represented in 'mask' ending at node 'i'",
      "The number of paths starting at 'i' that cover the nodes in 'mask'",
      "The maximum value node visited in the subset 'mask'"
    ],
    "answer": "The minimum cost to visit all nodes represented in 'mask' ending at node 'i'",
    "explanation": "The bitmask tracks the subset of visited cities, and 'i' tracks the current endpoint. This state allows the recursion to build up the shortest Hamiltonian cycle.",
    "difficulty": "Intermediate"
  },
  {
    "id": 62,
    "question": "What is the worst-case time complexity of searching for an element in a standard Chaining Hash Table where n is the number of elements and m is the table size (bucket count)?",
    "options": [
      "O(1)",
      "O(log n)",
      "O(n)",
      "O(n/m)"
    ],
    "answer": "O(n)",
    "explanation": "In the worst case (e.g., a poor hash function), all elements collide into a single bucket, degrading the structure into a linked list requiring O(n) time to traverse.",
    "difficulty": "Intermediate"
  },
  {
    "id": 63,
    "question": "Which algorithm is specifically designed to find the shortest path from a single source to all other nodes in a graph that contains negative weight edges but no negative cycles?",
    "options": [
      "Dijkstra's Algorithm",
      "Bellman-Ford Algorithm",
      "Prim's Algorithm",
      "A* Search"
    ],
    "answer": "Bellman-Ford Algorithm",
    "explanation": "Unlike Dijkstra's, Bellman-Ford relaxes all edges V-1 times, allowing it to handle negative weights by propagating distance improvements through the graph.",
    "difficulty": "Intermediate"
  },
  {
    "id": 64,
    "question": "What is the role of the 'Residual Graph' in the Ford-Fulkerson algorithm for computing maximum flow?",
    "options": [
      "It stores the initial capacities of the graph",
      "It represents the remaining capacity of edges and allows the algorithm to 'undo' flow by sending it back",
      "It filters out all edges that are already saturated",
      "It converts the directed graph into an undirected graph"
    ],
    "answer": "It represents the remaining capacity of edges and allows the algorithm to 'undo' flow by sending it back",
    "explanation": "Residual edges allow the algorithm to redirect flow. If flow is sent along a path that turns out to be suboptimal, residual edges permit reducing that flow to find a better augmenting path.",
    "difficulty": "Intermediate"
  },
  {
    "id": 65,
    "question": "In the context of bitwise algorithms, how does the XOR operation help find the unique number in an array where every other number appears twice?",
    "options": [
      "XOR of a number with itself is 1, and XOR with 0 is the number itself",
      "XOR of a number with itself is 0, and XOR is commutative/associative, making pairs cancel out",
      "XOR acts as a bitwise AND to filter matching bits",
      "XOR shifts bits to the left, isolating the odd one out"
    ],
    "answer": "XOR of a number with itself is 0, and XOR is commutative/associative, making pairs cancel out",
    "explanation": "Since a ^ a = 0 and 0 ^ b = b, XORing all elements in the array will cancel out the pairs, leaving only the unique element.",
    "difficulty": "Intermediate"
  },
  {
    "id": 66,
    "question": "What is the 'Time Complexity' of the Sieve of Eratosthenes algorithm for finding all prime numbers up to an integer n?",
    "options": [
      "O(n log n)",
      "O(n log log n)",
      "O(n)",
      "O(n^2)"
    ],
    "answer": "O(n log log n)",
    "explanation": "The complexity derives from the harmonic series of primes (1/2 + 1/3 + 1/5 + ...), which converges to log log n. It is nearly linear but not quite.",
    "difficulty": "Intermediate"
  },
  {
    "id": 67,
    "question": "Which data structure is typically used to implement a 'Priority Queue' to achieve O(1) access to the maximum (or minimum) element and O(log n) insertion/deletion?",
    "options": [
      "Binary Search Tree (BST)",
      "Linked List",
      "Binary Heap",
      "Hash Map"
    ],
    "answer": "Binary Heap",
    "explanation": "A Binary Heap maintains the heap property where the root is the max/min, allowing O(1) peek and O(log n) insert/delete due to the height of the complete binary tree.",
    "difficulty": "Intermediate"
  },
  {
    "id": 68,
    "question": "What is the primary limitation of the 'Naive' string matching algorithm compared to KMP or Rabin-Karp?",
    "options": [
      "It cannot find overlapping patterns",
      "It has a worst-case time complexity of O(mn) where m is pattern length and n is text length",
      "It requires O(n) extra space",
      "It only works on binary strings"
    ],
    "answer": "It has a worst-case time complexity of O(mn) where m is pattern length and n is text length",
    "explanation": "The naive algorithm slides the pattern one by one and checks every character. In the worst case (e.g., text 'AAAA...' and pattern 'AAAB'), it performs O(mn) comparisons.",
    "difficulty": "Intermediate"
  },
  {
    "id": 69,
    "question": "In algorithm analysis, what does 'Amortized Analysis' account for that 'Worst-Case Analysis' does not?",
    "options": [
      "The average cost across all possible inputs",
      "The total cost of a sequence of operations, spreading the cost of expensive rare operations over frequent cheap ones",
      "The best-case scenario for a specific input",
      "The overhead of memory allocation"
    ],
    "answer": "The total cost of a sequence of operations, spreading the cost of expensive rare operations over frequent cheap ones",
    "explanation": "Amortized analysis guarantees the average performance of each operation in the *worst-case* sequence, distinguishing it from average-case analysis which relies on probability.",
    "difficulty": "Intermediate"
  },
  {
    "id": 70,
    "question": "The 'Mo's Algorithm' is used to answer range queries on an array offline. What technique does it employ to minimize the total cost of moving the query boundaries?",
    "options": [
      "Processing queries in the order they appear in the input",
      "Sorting queries based on the block number of the left endpoint and the right endpoint (odd-even optimization)",
      "Using a segment tree for every query",
      "Precomputing prefix sums for all possible ranges"
    ],
    "answer": "Sorting queries based on the block number of the left endpoint and the right endpoint (odd-even optimization)",
    "explanation": "Mo's algorithm orders queries to minimize the distance the current range pointers [L, R] must move, typically reducing the complexity from O(N * Q) to O((N * Q) ^ 0.5) or O(N * Q ^ 0.5).",
    "difficulty": "Intermediate"
  },
  {
    "id": 71,
    "question": "In the context of amortized analysis using the potential method, what condition must the potential function Φ satisfy to ensure that the total amortized cost is an upper bound on the total actual cost?",
    "options": [
      "Φ(D_i) must always be equal to zero for the initial state D_0",
      "Φ(D_i) must always be non-negative for all states D_i",
      "Φ(D_i) must be a decreasing function of the number of operations",
      "Φ(D_i) must represent the exact runtime of the i-th operation"
    ],
    "answer": "Φ(D_i) must always be non-negative for all states D_i",
    "explanation": "If the potential is always non-negative, the total potential drop cannot exceed the initial potential, ensuring total amortized cost ≥ total actual cost.",
    "difficulty": "Advanced"
  },
  {
    "id": 72,
    "question": "Which data structure modification is required to augment a standard Fenwick Tree (Binary Indexed Tree) to support range updates and range queries?",
    "options": [
      "Use two separate Fenwick Trees to handle the coefficients of the linear equation formed by the range update",
      "Implement the Fenwick Tree using a segment tree under the hood to store intermediate sums",
      "Replace the binary indexing with a B-Tree structure to handle larger ranges",
      "Store the difference array (Delta) implicitly within the nodes of a single Fenwick Tree"
    ],
    "answer": "Use two separate Fenwick Trees to handle the coefficients of the linear equation formed by the range update",
    "explanation": "Range update and query requires maintaining two BITs, B1 and B2, such that the range sum can be reconstructed using the formula: Sum = query(B2, r)*r + query(B1, r) - (query(B2, l-1)*(l-1) + query(B1, l-1)).",
    "difficulty": "Advanced"
  },
  {
    "id": 73,
    "question": "What is the time complexity of finding the Maximum Flow in a network using Dinic's algorithm on a unit capacity graph?",
    "options": [
      "O(V * E^2)",
      "O(min(V^(2/3), sqrt(E)) * E)",
      "O(E * sqrt(V))",
      "O(V^2 * E)"
    ],
    "answer": "O(min(V^(2/3), sqrt(E)) * E)",
    "explanation": "In unit capacity networks, Dinic's algorithm runs in O(min(V^(2/3), sqrt(E)) * E) because each blocking flow can be found in O(E) time and the number of phases is bounded by the distance to the sink.",
    "difficulty": "Advanced"
  },
  {
    "id": 74,
    "question": "In the implementation of a \"Treap\" (Cartesian Tree), what property ensures that the tree remains balanced with high probability?",
    "options": [
      "Explicitly storing the height of the subtree at every node and rotating if the difference exceeds 1",
      "Assigning a random priority key to each node and maintaining the heap property on this priority",
      "Splitting the tree based on the median of the inorder traversal during every insertion",
      "Coloring nodes red or black and enforcing that no path has more than two consecutive red nodes"
    ],
    "answer": "Assigning a random priority key to each node and maintaining the heap property on this priority",
    "explanation": "A Treap combines BST properties (by key) with Heap properties (by random priority). The randomness ensures the expected height is O(log n), analogous to Quicksort.",
    "difficulty": "Advanced"
  },
  {
    "id": 75,
    "question": "What is the primary application of the \"Sieve of Eratosthenes\" when optimized with a linear complexity (O(N)) implementation?",
    "options": [
      "Finding the shortest path in a weighted graph",
      "Computing the totient function for all numbers up to N using a modified sieve loop",
      "Determining the longest increasing subsequence in an array",
      "Performing range minimum queries on a static array"
    ],
    "answer": "Computing the totient function for all numbers up to N using a modified sieve loop",
    "explanation": "The linear sieve allows for the calculation of multiplicative functions (like Euler's Totient φ(n) or the Möbius function) for all numbers up to N in O(N) by ensuring each composite is processed only once by its lowest prime factor.",
    "difficulty": "Advanced"
  },
  {
    "id": 76,
    "question": "In \"Heavy-Light Decomposition\" (HLD) of a tree, how is a \"heavy\" child defined for a given node?",
    "options": [
      "The child with the largest depth relative to the root",
      "The child whose subtree has the greatest number of nodes",
      "The child connected to the parent by the edge with the highest weight",
      "The child that appears first in the preorder traversal of the tree"
    ],
    "answer": "The child whose subtree has the greatest number of nodes",
    "explanation": "HLD identifies the heavy child as the one with the maximum subtree size. This ensures that any path from the root to a leaf crosses O(log N) light edges, keeping path queries efficient.",
    "difficulty": "Advanced"
  },
  {
    "id": 77,
    "question": "What is the worst-case time complexity of the \"Smoothsort\" algorithm, and how does it compare to Heapsort?",
    "options": [
      "Smoothsort is O(N log N) worst-case, identical to Heapsort",
      "Smoothsort is O(N) worst-case, which is faster than Heapsort",
      "Smoothsort is O(N^2) worst-case, making it slower than Heapsort",
      "Smoothsort is O(N log log N) worst-case, making it strictly superior"
    ],
    "answer": "Smoothsort is O(N log N) worst-case, identical to Heapsort",
    "explanation": "Smoothsort has the same O(N log N) worst-case bounds as Heapsort. However, it is adaptive and can approach O(N) best-case behavior for nearly sorted data, unlike standard Heapsort.",
    "difficulty": "Advanced"
  },
  {
    "id": 78,
    "question": "Which operation in a \"Link-Cut Tree\" exposes the path from a node to the root by manipulating preferred paths and splay operations?",
    "options": [
      "The access(v) operation",
      "The link(u, v) operation",
      "The find_root(v) operation",
      "The cut(v) operation"
    ],
    "answer": "The access(v) operation",
    "explanation": "The access(v) operation exposes the path from the root to node v by splaying v to the top of its auxiliary tree and reversing preferred child pointers from the root to v.",
    "difficulty": "Advanced"
  },
  {
    "id": 79,
    "question": "In the context of string algorithms, what does the \"Z-Algorithm\" compute in linear time?",
    "options": [
      "The longest palindromic substring centered at every position",
      "The longest prefix of the string that is also a suffix for every prefix",
      "The length of the longest substring starting at each position i that matches the prefix of the string",
      "The edit distance between the string and its reverse"
    ],
    "answer": "The length of the longest substring starting at each position i that matches the prefix of the string",
    "explanation": "The Z-Algorithm produces a Z-array where Z[i] is the length of the longest substring starting from i that matches the prefix of the string S.",
    "difficulty": "Advanced"
  },
  {
    "id": 80,
    "question": "When using \"Johnson's Algorithm\" for All-Pairs Shortest Paths, what is the initial step required to handle negative weight edges without negative cycles?",
    "options": [
      "Applying the Floyd-Warshall algorithm to detect negative cycles",
      "Adding a new vertex connected by zero-weight edges to all existing vertices and running Bellman-Ford",
      "Transforming the graph into a Directed Acyclic Graph (DAG)",
      "Running Dijkstra's algorithm from every node using a Fibonacci Heap"
    ],
    "answer": "Adding a new vertex connected by zero-weight edges to all existing vertices and running Bellman-Ford",
    "explanation": "Johnson's algorithm adds a dummy node connected to all others with 0 weight edges, runs Bellman-Ford to calculate h(v) (potential), then reweights edges to be non-negative, allowing Dijkstra to be run for every vertex.",
    "difficulty": "Advanced"
  },
  {
    "id": 81,
    "question": "What specific condition must hold true for the \"Greedy Algorithm\" to correctly solve the \"Activity Selection Problem\" (selecting the maximum number of non-overlapping intervals)?",
    "options": [
      "The intervals must be sorted by their start time in ascending order",
      "The intervals must be sorted by their duration (shortest first)",
      "The intervals must be sorted by their finish time in ascending order",
      "The intervals must be weighted equally"
    ],
    "answer": "The intervals must be sorted by their finish time in ascending order",
    "explanation": "The greedy choice is to always pick the interval with the earliest finish time that doesn't conflict with previously selected intervals. This requires sorting by finish time.",
    "difficulty": "Advanced"
  },
  {
    "id": 82,
    "question": "In the \"Knuth-Morris-Pratt\" (KMP) algorithm, what is the purpose of the \"Partial Match\" table (often called the \"failure function\")?",
    "options": [
      "It stores the indices where the pattern matches the text exactly",
      "It indicates the length of the longest proper prefix of the pattern that is also a suffix for every sub-pattern",
      "It calculates the Levenshtein distance between the pattern and the text",
      "It determines the number of occurrences of each character in the pattern"
    ],
    "answer": "It indicates the length of the longest proper prefix of the pattern that is also a suffix for every sub-pattern",
    "explanation": "The failure function allows the algorithm to skip redundant comparisons by shifting the pattern to a position where the prefix matches the suffix of the current matched segment.",
    "difficulty": "Advanced"
  },
  {
    "id": 83,
    "question": "What is the primary limitation of the \"Bellman-Ford\" algorithm compared to \"Dijkstra's\" algorithm?",
    "options": [
      "Bellman-Ford cannot handle graphs with negative weight edges",
      "Bellman-Ford has a worse time complexity (O(VE)) compared to Dijkstra's (O(E + V log V))",
      "Bellman-Ford only works on Directed Acyclic Graphs (DAGs)",
      "Bellman-Ford requires the graph to be connected"
    ],
    "answer": "Bellman-Ford has a worse time complexity (O(VE)) compared to Dijkstra's (O(E + V log V))",
    "explanation": "While Bellman-Ford is more versatile (handling negative weights), its O(VE) complexity makes it significantly slower than Dijkstra's O(E + V log V) for large graphs with non-negative weights.",
    "difficulty": "Advanced"
  },
  {
    "id": 84,
    "question": "In \"Suffix Automata\" construction, what is the asymptotic size of the resulting automaton (number of states and transitions) for a string of length N?",
    "options": [
      "States: O(N), Transitions: O(N^2)",
      "States: O(2^N), Transitions: O(N)",
      "States: O(N), Transitions: O(N)",
      "States: O(N log N), Transitions: O(N log N)"
    ],
    "answer": "States: O(N), Transitions: O(N)",
    "explanation": "A Suffix Automaton for a string of length N has at most 2N - 1 states and at most 3N - 4 transitions, making it linear in space complexity.",
    "difficulty": "Advanced"
  },
  {
    "id": 85,
    "question": "What is the \"Convex Hull Trick\" (CHT) primarily used to optimize in Dynamic Programming?",
    "options": [
      "DP transitions where the cost function is additive and monotonic",
      "DP transitions of the form dp[i] = min(dp[j] + C[j]) where C[j] involves a linear function of j",
      "DP problems involving bitmask subsets",
      "DP problems on trees requiring rerooting"
    ],
    "answer": "DP transitions of the form dp[i] = min(dp[j] + C[j]) where C[j] involves a linear function of j",
    "explanation": "CHT optimizes DP where the recurrence is dp[i] = min(m[j] * x[i] + c[j] + dp[j]), allowing the query of the minimum/maximum value among several lines at a specific x-coordinate.",
    "difficulty": "Advanced"
  },
  {
    "id": 86,
    "question": "What is the \"Master Theorem\" used for?",
    "options": [
      "Determining the maximum flow in a network",
      "Solving recurrence relations of the form T(n) = aT(n/b) + f(n)",
      "Finding the longest common subsequence between two strings",
      "Balancing a binary search tree"
    ],
    "answer": "Solving recurrence relations of the form T(n) = aT(n/b) + f(n)",
    "explanation": "The Master Theorem provides a cookbook solution for asymptotic analysis of divide-and-conquer recurrences where subproblems are of equal size.",
    "difficulty": "Advanced"
  },
  {
    "id": 87,
    "question": "In the context of NP-Completeness, what is the \"Clique Problem\"?",
    "options": [
      "Finding the shortest path between two nodes in a graph",
      "Determining if a graph contains a subgraph of size k that is a complete graph",
      "Partitioning a graph into two sets such that no edge exists within a set",
      "Finding the minimum number of colors needed to color a graph"
    ],
    "answer": "Determining if a graph contains a subgraph of size k that is a complete graph",
    "explanation": "The Clique problem asks whether an undirected graph contains a clique (a subset of vertices, all adjacent to each other) of at least size k.",
    "difficulty": "Advanced"
  },
  {
    "id": 88,
    "question": "What is the key difference between \"Prim's Algorithm\" and \"Kruskal's Algorithm\" for finding a Minimum Spanning Tree (MST)?",
    "options": [
      "Prim's grows a single tree from a start node, while Kruskal's grows a forest and merges trees",
      "Prim's uses a Union-Find data structure, while Kruskal's uses a Priority Queue",
      "Prim's only works on directed graphs, while Kruskal's only works on undirected graphs",
      "Prim's has a time complexity of O(E log V), whereas Kruskal's is O(V^2)"
    ],
    "answer": "Prim's grows a single tree from a start node, while Kruskal's grows a forest and merges trees",
    "explanation": "Prim's algorithm is a vertex-based approach that expands one tree, whereas Kruskal's is an edge-based approach that merges components until only one tree remains.",
    "difficulty": "Advanced"
  },
  {
    "id": 89,
    "question": "Which data structure is best suited to implement a \"Priority Queue\" that supports both \"Extract-Min\" and \"Decrease-Key\" operations efficiently (e.g., for Dijkstra's algorithm)?",
    "options": [
      "Hash Table",
      "Fibonacci Heap",
      "Unsorted Array",
      "Stack"
    ],
    "answer": "Fibonacci Heap",
    "explanation": "Fibonacci Heaps offer amortized O(1) time for both Insert and Decrease-Key, and O(log n) for Extract-Min, making them theoretically superior to Binary Heaps for algorithms like Dijkstra's.",
    "difficulty": "Advanced"
  },
  {
    "id": 90,
    "question": "What is the result of \"XORing\" a number with itself?",
    "options": [
      "The number itself",
      "Zero",
      "One",
      "The bitwise complement of the number"
    ],
    "answer": "Zero",
    "explanation": "The XOR operation has the property that A ⊕ A = 0. This is frequently used in algorithms to find the single non-duplicate number in a list where every other number appears twice.",
    "difficulty": "Advanced"
  },
  {
    "id": 91,
    "question": "What is the space-time trade-off technique used in \"Mo's Algorithm\" to answer range queries offline?",
    "options": [
      "Dividing the array into blocks of size N and sorting queries by their right endpoint",
      "Dividing the array into blocks of size √N and sorting queries by the block of their left endpoint, then by right endpoint",
      "Using a segment tree to process queries in the order they are received",
      "Storing all possible subarrays in a hash table"
    ],
    "answer": "Dividing the array into blocks of size √N and sorting queries by the block of their left endpoint, then by right endpoint",
    "explanation": "Mo's algorithm orders queries to minimize the pointer movement distance. The block size of √N ensures the complexity is O((N+Q)√N) or O(N√N).",
    "difficulty": "Advanced"
  },
  {
    "id": 92,
    "question": "What is \"Kadane's Algorithm\" used to find?",
    "options": [
      "The longest path in a Directed Acyclic Graph (DAG)",
      "The maximum sum subarray within a one-dimensional array of numbers",
      "The shortest substring containing all characters of a set",
      "The minimum spanning tree of a dense graph"
    ],
    "answer": "The maximum sum subarray within a one-dimensional array of numbers",
    "explanation": "Kadane's algorithm scans the array, calculating the maximum sum ending at each position. It resets the current sum to 0 if it becomes negative, finding the global maximum in O(N).",
    "difficulty": "Advanced"
  },
  {
    "id": 93,
    "question": "In ",
    "options": [
      "O(K)",
      "O(N)",
      "O(log K)",
      "O(1)"
    ],
    "answer": "O(log K)",
    "explanation": "Binary Lifting preprocesses ancestors at powers of 2 (1, 2, 4, 8...). The K-th ancestor is found by decomposing K into a sum of powers of 2 and jumping in O(log K) steps.",
    "difficulty": "Advanced"
  },
  {
    "id": 94,
    "question": "Which algorithm is used to find the \"Strongly Connected Components\" (SCC) in a Directed Graph in linear time?",
    "options": [
      "Dijkstra's Algorithm",
      "Kosaraju's Algorithm",
      "Prim's Algorithm",
      "The Hungarian Algorithm"
    ],
    "answer": "Kosaraju's Algorithm",
    "explanation": "Kosaraju's algorithm performs two DFS passes: one on the original graph to determine finishing order, and one on the transposed graph (reversed edges) to identify SCCs.",
    "difficulty": "Advanced"
  },
  {
    "id": 95,
    "question": "In ",
    "options": [
      "To increase the security of the data",
      "To enable the use of array-based data structures (like Segment Trees or Fenwick Trees) when values are sparse or large",
      "To sort the data in O(1) time",
      "To convert the problem from a graph problem to a tree problem"
    ],
    "answer": "To enable the use of array-based data structures (like Segment Trees or Fenwick Trees) when values are sparse or large",
    "explanation": "Coordinate compression preserves the relative order of elements while mapping them to a dense index space, making it feasible to use structures that require O(N) memory.",
    "difficulty": "Advanced"
  },
  {
    "id": 96,
    "question": "What is the \"Traveling Salesman Problem\" (TSP) classified as in complexity theory?",
    "options": [
      "P (Polynomial time)",
      "NP-Hard",
      "PSPACE-Complete",
      "Undecidable"
    ],
    "answer": "NP-Hard",
    "explanation": "TSP is NP-Hard because there is no known polynomial-time solution to find the optimal path. The decision version of TSP is NP-Complete.",
    "difficulty": "Advanced"
  },
  {
    "id": 97,
    "question": "What is the \"Bitmask\" technique commonly used for in Dynamic Programming?",
    "options": [
      "To efficiently sort floating-point numbers",
      "To represent subsets of a small set (N ≤ 20) as integers to iterate over all possible subsets",
      "To compress the ASCII values of strings",
      "To replace the recursion stack in divide-and-conquer algorithms"
    ],
    "answer": "To represent subsets of a small set (N ≤ 20) as integers to iterate over all possible subsets",
    "explanation": "Bitmask DP uses the bits of an integer to represent the presence or absence of elements in a subset, allowing for efficient state representation and iteration.",
    "difficulty": "Advanced"
  },
  {
    "id": 98,
    "question": "What is the distinguishing feature of a \"B-Tree\" compared to a standard Binary Search Tree (BST)?",
    "options": [
      "A B-Tree is always perfectly balanced, whereas a BST can be skewed",
      "A B-Tree can have more than two children per node, making it optimized for disk block access",
      "A B-Tree stores keys only in the leaf nodes",
      "A B-Tree is a graph, not a tree"
    ],
    "answer": "A B-Tree can have more than two children per node, making it optimized for disk block access",
    "explanation": "B-Trees are generalized search trees where nodes can have many keys and children (order M). This reduces tree height and the number of disk I/Os required, which is crucial for database indexing.",
    "difficulty": "Advanced"
  },
  {
    "id": 99,
    "question": "In the \"Meet-in-the-Middle\" algorithm, how is the problem size typically reduced?",
    "options": [
      "By sorting the input and discarding half",
      "By splitting the input set into two halves, solving for each half independently, and combining the results",
      "By applying binary search three times",
      "By converting the problem to a graph and using BFS from both ends"
    ],
    "answer": "By splitting the input set into two halves, solving for each half independently, and combining the results",
    "explanation": "Meet-in-the-middle splits a problem of size N into two halves of size N/2, solving each in O(2^(N/2)) and combining results in O(2^(N/2)), reducing complexity from O(2^N).",
    "difficulty": "Advanced"
  }
]