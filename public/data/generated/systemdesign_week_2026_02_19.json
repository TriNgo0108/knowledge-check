[
  {
    "id": 1,
    "question": "Which scaling strategy involves adding more power (CPU, RAM) to an existing single server?",
    "options": [
      "Horizontal scaling",
      "Vertical scaling",
      "Elastic scaling",
      "Database sharding"
    ],
    "answer": "Vertical scaling",
    "explanation": "Vertical scaling (scale-up) increases the capacity of a single machine. Horizontal scaling (scale-out) involves adding more nodes to the system.",
    "difficulty": "Beginner"
  },
  {
    "id": 2,
    "question": "What is the primary function of a Load Balancer in a distributed system?",
    "options": [
      "To encrypt data packets during transmission",
      "To distribute incoming network traffic across multiple servers",
      "To store frequently accessed data in memory",
      "To convert database schemas into API endpoints"
    ],
    "answer": "To distribute incoming network traffic across multiple servers",
    "explanation": "Load balancers act as the reverse proxy, distributing network or application traffic across multiple servers to ensure reliability and performance.",
    "difficulty": "Beginner"
  },
  {
    "id": 3,
    "question": "In a Microservices architecture, how do services typically communicate with each other?",
    "options": [
      "Through direct memory access",
      "Via well-defined APIs (REST, gRPC, or message queues)",
      "By sharing a single large codebase",
      "By modifying a centralized configuration file"
    ],
    "answer": "Via well-defined APIs (REST, gRPC, or message queues)",
    "explanation": "Microservices are loosely coupled and communicate via lightweight protocols, typically HTTP/REST or asynchronous messaging, over a network.",
    "difficulty": "Beginner"
  },
  {
    "id": 4,
    "question": "Which caching strategy involves checking the cache first, and on a miss, fetching the data from the database and updating the cache?",
    "options": [
      "Write-through caching",
      "Write-back caching",
      "Cache-aside or Lazy Loading",
      "Write-around caching"
    ],
    "answer": "Cache-aside or Lazy Loading",
    "explanation": "In the Cache-aside pattern, the application looks for data in the cache first. If data is not present (miss), it queries the database and populates the cache.",
    "difficulty": "Beginner"
  },
  {
    "id": 5,
    "question": "What is the primary trade-off associated with SQL databases compared to NoSQL databases?",
    "options": [
      "SQL databases do not support transactions",
      "SQL databases offer less strict consistency and data integrity",
      "SQL databases generally offer less flexibility for unstructured data and scale horizontally with more complexity",
      "SQL databases cannot handle indexing"
    ],
    "answer": "SQL databases generally offer less flexibility for unstructured data and scale horizontally with more complexity",
    "explanation": "SQL databases prioritize ACID properties and structured schemas (relational models), making horizontal scaling harder compared to the flexible schema and design of NoSQL databases.",
    "difficulty": "Beginner"
  },
  {
    "id": 6,
    "question": "Which database replication method provides the highest read availability but risks serving stale data?",
    "options": [
      "Synchronous replication",
      "Asynchronous replication",
      "Single-node replication",
      "Master-only replication"
    ],
    "answer": "Asynchronous replication",
    "explanation": "Asynchronous replication writes to the master first and updates replicas later. This offers higher availability and lower latency but risks data loss if the master fails before propagation.",
    "difficulty": "Beginner"
  },
  {
    "id": 7,
    "question": "What is the main purpose of 'Sharding' a database?",
    "options": [
      "To create exact copies of the database for backup purposes",
      "To store data in a flat file system instead of tables",
      "To distribute a single large dataset across multiple database instances",
      "To encrypt sensitive data at rest"
    ],
    "answer": "To distribute a single large dataset across multiple database instances",
    "explanation": "Sharding is a horizontal scaling technique where data is partitioned into smaller chunks and spread across multiple machines to handle larger datasets and throughput.",
    "difficulty": "Beginner"
  },
  {
    "id": 8,
    "question": "In the CAP Theorem, what does the 'A' stand for?",
    "options": [
      "Atomicity",
      "Authentication",
      "Availability",
      "Asynchronous processing"
    ],
    "answer": "Availability",
    "explanation": "The CAP Theorem states that a distributed system can only simultaneously provide two out of three guarantees: Consistency, Availability, and Partition Tolerance.",
    "difficulty": "Beginner"
  },
  {
    "id": 9,
    "question": "Which load balancing algorithm assigns requests to servers based on the client's IP address?",
    "options": [
      "Round Robin",
      "Least Connections",
      "IP Hash",
      "Random"
    ],
    "answer": "IP Hash",
    "explanation": "IP Hash uses a hash of the client's IP address to determine which server receives the request, ensuring that a specific client consistently hits the same backend server.",
    "difficulty": "Beginner"
  },
  {
    "id": 10,
    "question": "What is a 'Reverse Proxy'?",
    "options": [
      "A server that sits in front of web servers and forwards client requests to them",
      "A database backup located in a different region",
      "A client-side script used to mask IP addresses",
      "A type of firewall that blocks outgoing traffic"
    ],
    "answer": "A server that sits in front of web servers and forwards client requests to them",
    "explanation": "A reverse proxy accepts requests from clients and forwards them to backend servers, providing security, load balancing, and caching capabilities.",
    "difficulty": "Beginner"
  },
  {
    "id": 11,
    "question": "Which of the following best describes 'Eventual Consistency'?",
    "options": [
      "Data is guaranteed to be identical on all nodes immediately after a write",
      "The system will return an error if data is not consistent",
      "The system guarantees that if no new updates are made, eventually all accesses will return the last updated value",
      "Data is only consistent when the system is offline"
    ],
    "answer": "The system guarantees that if no new updates are made, eventually all accesses will return the last updated value",
    "explanation": "Eventual consistency is a consistency model used in distributed systems where updates propagate asynchronously; given enough time, all replicas converge to the same state.",
    "difficulty": "Beginner"
  },
  {
    "id": 12,
    "question": "What is the primary role of a Message Queue in system architecture?",
    "options": [
      "To store user passwords securely",
      "To enable asynchronous communication and decouple services",
      "To synchronize database writes across regions",
      "To compress HTTP headers"
    ],
    "answer": "To enable asynchronous communication and decouple services",
    "explanation": "Message queues allow services to communicate asynchronously, buffering requests until they are processed, which helps manage load and decouple components.",
    "difficulty": "Beginner"
  },
  {
    "id": 13,
    "question": "What is the term for breaking a large database into smaller chunks based on a specific key, such as User ID?",
    "options": [
      "Vertical Partitioning",
      "Horizontal Partitioning (Sharding)",
      "Database Indexing",
      "Schema Normalization"
    ],
    "answer": "Horizontal Partitioning (Sharding)",
    "explanation": "Sharding involves splitting rows of a large database table into smaller, more manageable tables (partitions) distributed across different servers, usually based on a shard key.",
    "difficulty": "Beginner"
  },
  {
    "id": 14,
    "question": "Which mechanism allows a system to maintain a mapping of database partitions to physical servers to efficiently route queries during scaling?",
    "options": [
      "Connection Pooling",
      "Consistent Hashing",
      "Database Indexing",
      "Two-Phase Commit"
    ],
    "answer": "Consistent Hashing",
    "explanation": "Consistent hashing minimizes the remapping of keys when servers are added or removed, ensuring only a fraction of data is relocated during scaling events.",
    "difficulty": "Beginner"
  },
  {
    "id": 15,
    "question": "Why are 'Stateless' services preferred in scalable web architectures?",
    "options": [
      "They require more memory to function",
      "They do not require client context to be stored between requests, allowing any server to handle any request",
      "They store all user data in the database exclusively",
      "They are easier to hack"
    ],
    "answer": "They do not require client context to be stored between requests, allowing any server to handle any request",
    "explanation": "Stateless services treat every request independently, which allows horizontal scaling because any instance can serve any request without session affinity requirements.",
    "difficulty": "Beginner"
  },
  {
    "id": 16,
    "question": "What is the purpose of a Content Delivery Network (CDN)?",
    "options": [
      "To execute server-side code for complex calculations",
      "To store and serve static content (images, CSS, JS) from geographically distributed edge locations",
      "To replace the primary database for transaction processing",
      "To secure the network layer from DDoS attacks exclusively"
    ],
    "answer": "To store and serve static content (images, CSS, JS) from geographically distributed edge locations",
    "explanation": "CDNs cache static assets in edge servers closer to users, reducing latency and load on the origin server.",
    "difficulty": "Beginner"
  },
  {
    "id": 17,
    "question": "What is a 'Read Replica' in database architecture?",
    "options": [
      "A backup copy used only for disaster recovery",
      "A live copy of the primary database that handles only read traffic",
      "The main database where all write operations occur",
      "A tool for analyzing SQL query syntax"
    ],
    "answer": "A live copy of the primary database that handles only read traffic",
    "explanation": "Read replicas are synchronized copies of the main database used to offload read queries, improving performance and availability for read-heavy workloads.",
    "difficulty": "Beginner"
  },
  {
    "id": 18,
    "question": "Which ACID property ensures that a transaction is treated as a single unit, which either succeeds completely or fails completely?",
    "options": [
      "Atomicity",
      "Consistency",
      "Isolation",
      "Durability"
    ],
    "answer": "Atomicity",
    "explanation": "Atomicity guarantees that all steps in a transaction are completed successfully; if any part fails, the entire transaction is rolled back.",
    "difficulty": "Beginner"
  },
  {
    "id": 19,
    "question": "What is the primary disadvantage of a Monolithic architecture?",
    "options": [
      "It is difficult to deploy to a single server",
      "It tightly couples all modules, making the codebase harder to scale, maintain, and deploy independently",
      "It uses too many different programming languages",
      "It requires a load balancer to function"
    ],
    "answer": "It tightly couples all modules, making the codebase harder to scale, maintain, and deploy independently",
    "explanation": "In a monolith, all components share the same memory space and deployment cycle; a bug in one module can crash the entire system, and scaling requires scaling the whole app.",
    "difficulty": "Beginner"
  },
  {
    "id": 20,
    "question": "What does 'Rate Limiting' protect a system from?",
    "options": [
      "SQL injection attacks",
      "Cross-site scripting (XSS)",
      "Traffic spikes and brute-force attacks by limiting the number of requests a user can make",
      "Data loss due to hardware failure"
    ],
    "answer": "Traffic spikes and brute-force attacks by limiting the number of requests a user can make",
    "explanation": "Rate limiting controls the rate of incoming traffic to prevent resource exhaustion, ensure fair usage, and mitigate denial-of-service attacks.",
    "difficulty": "Beginner"
  },
  {
    "id": 21,
    "question": "Which pattern separates the read and write operations of a system into different models?",
    "options": [
      "Master-Slave Replication",
      "Command Query Responsibility Segregation (CQRS)",
      "Sharding",
      "Polyglot Persistence"
    ],
    "answer": "Command Query Responsibility Segregation (CQRS)",
    "explanation": "CQRS splits the application into two parts: Command (write/update) and Query (read), allowing them to be optimized and scaled separately.",
    "difficulty": "Beginner"
  },
  {
    "id": 22,
    "question": "What is the 'Cold Start' problem in serverless architectures?",
    "options": [
      "The inability of the system to start when the network is down",
      "The latency experienced when a function is invoked for the first time or after being idle",
      "The freezing of the server due to low temperatures",
      "The process of manually starting a database server"
    ],
    "answer": "The latency experienced when a function is invoked for the first time or after being idle",
    "explanation": "Cold starts occur when a cloud provider allocates resources and initializes the runtime environment for a function, causing a delay in execution.",
    "difficulty": "Beginner"
  },
  {
    "id": 23,
    "question": "Which storage system is optimized for storing and retrieving large unstructured files like images and videos?",
    "options": [
      "Relational Database",
      "Object Storage (e.g., S3)",
      "Graph Database",
      "In-Memory Cache"
    ],
    "answer": "Object Storage (e.g., S3)",
    "explanation": "Object storage treats data as objects (files, metadata) rather than blocks or files in a hierarchy, making it ideal for unstructured data like media.",
    "difficulty": "Beginner"
  },
  {
    "id": 24,
    "question": "What is 'Connection Pooling'?",
    "options": [
      "A technique to open a new database connection for every user request",
      "A cache of maintained database connections so connections can be reused when future requests to the database are required",
      "A security mechanism to block unauthorized IPs",
      "A way to merge two databases into one"
    ],
    "answer": "A cache of maintained database connections so connections can be reused when future requests to the database are required",
    "explanation": "Creating connections is expensive. Pooling maintains a set of open connections to be reused, significantly improving performance.",
    "difficulty": "Beginner"
  },
  {
    "id": 25,
    "question": "In the context of CAP Theorem, what does the 'P' stand for?",
    "options": [
      "Performance",
      "Persistence",
      "Partition Tolerance",
      "Privacy"
    ],
    "answer": "Partition Tolerance",
    "explanation": "Partition Tolerance refers to the system's ability to continue operating despite arbitrary message loss or failure of part of the network.",
    "difficulty": "Beginner"
  },
  {
    "id": 26,
    "question": "What is the primary benefit of an 'Event-Driven Architecture'?",
    "options": [
      "It creates a linear execution flow that is easy to debug",
      "It enables loose coupling and asynchronous reactions to state changes",
      "It eliminates the need for a database",
      "It guarantees immediate consistency across all nodes"
    ],
    "answer": "It enables loose coupling and asynchronous reactions to state changes",
    "explanation": "Services emit events when changes happen, and other services react to them. This decouples the producer from the consumer and improves scalability.",
    "difficulty": "Beginner"
  },
  {
    "id": 27,
    "question": "What is a 'Cache Stampede'?",
    "options": [
      "A DoS attack targeting the cache server",
      "When multiple clients request the same stale data simultaneously, causing a flood of requests to the origin",
      "The process of clearing the entire cache",
      "A type of cache warming strategy"
    ],
    "answer": "When multiple clients request the same stale data simultaneously, causing a flood of requests to the origin",
    "explanation": "A cache stampede occurs when a cached item expires, and numerous concurrent requests miss the cache and hit the backend simultaneously, potentially overwhelming it.",
    "difficulty": "Beginner"
  },
  {
    "id": 28,
    "question": "Which tool is commonly used to route traffic from the public internet to internal microservices, often handling SSL termination and authentication?",
    "options": [
      "API Gateway",
      "Load Balancer (Layer 4)",
      "Switch",
      "Database Router"
    ],
    "answer": "API Gateway",
    "explanation": "An API Gateway is the single entry point for all clients, handling cross-cutting concerns like routing, authentication, rate limiting, and SSL before requests reach microservices.",
    "difficulty": "Beginner"
  },
  {
    "id": 29,
    "question": "What is 'Write-Through' caching?",
    "options": [
      "Writing data only to the cache and asynchronously to the database",
      "Writing data to the cache and the database simultaneously",
      "Writing data only to the database",
      "Writing data to the cache after a user requests it"
    ],
    "answer": "Writing data to the cache and the database simultaneously",
    "explanation": "In write-through caching, data is written to the cache and the backing store at the same time, ensuring strong consistency but increasing write latency.",
    "difficulty": "Beginner"
  },
  {
    "id": 30,
    "question": "What does 'TTL' (Time To Live) represent in the context of DNS or Caching?",
    "options": [
      "The total time a server takes to load",
      "The duration for which a record is considered valid before it must be refreshed or discarded",
      "The time taken for data to travel across the Atlantic",
      "The total traffic limit for a website"
    ],
    "answer": "The duration for which a record is considered valid before it must be refreshed or discarded",
    "explanation": "TTL dictates how long a piece of data (like a DNS record or cached object) remains stored before it expires and needs to be fetched again from the source.",
    "difficulty": "Beginner"
  },
  {
    "id": 31,
    "question": "What is a 'Hotspot' in a sharded database system?",
    "options": [
      "A physical server that is overheating",
      "A specific shard key receiving a disproportionate amount of read/write traffic",
      "A redundant backup server",
      "A public-facing website URL"
    ],
    "answer": "A specific shard key receiving a disproportionate amount of read/write traffic",
    "explanation": "Hotspots occur when a specific partition (shard) receives significantly more traffic than others due to uneven distribution of access patterns, degrading performance.",
    "difficulty": "Beginner"
  },
  {
    "id": 32,
    "question": "What is the purpose of a 'Circuit Breaker' pattern?",
    "options": [
      "To stop electrical current in data centers",
      "To detect failures and prevent an application from attempting an operation that is likely to fail",
      "To break database connections after a timeout",
      "To route traffic to the nearest server"
    ],
    "answer": "To detect failures and prevent an application from attempting an operation that is likely to fail",
    "explanation": "The Circuit Breaker pattern stops cascading failures by failing fast if a downstream service is unresponsive, allowing the system to handle the error gracefully.",
    "difficulty": "Beginner"
  },
  {
    "id": 33,
    "question": "Which design pattern defines an object that encapsulates how a set of objects interact, promoting loose coupling by preventing objects from referring to each other explicitly?",
    "options": [
      "Singleton Pattern",
      "Observer Pattern",
      "Mediator Pattern",
      "Factory Pattern"
    ],
    "answer": "Mediator Pattern",
    "explanation": "In system design, a Message Broker or Mediator centralizes communication between services, reducing dependencies and making the system easier to maintain.",
    "difficulty": "Beginner"
  },
  {
    "id": 34,
    "question": "What is the primary benefit of 'Database Indexing'?",
    "options": [
      "It increases the storage size of the database",
      "It speeds up data retrieval operations at the cost of slower writes and increased storage",
      "It encrypts the data for security",
      "It allows the database to connect to the internet"
    ],
    "answer": "It speeds up data retrieval operations at the cost of slower writes and increased storage",
    "explanation": "Indexes create a lookup structure (like a B-Tree) to find rows quickly, but maintaining this structure overhead on INSERT/UPDATE operations.",
    "difficulty": "Beginner"
  },
  {
    "id": 35,
    "question": "In distributed systems, what is 'Idempotency'?",
    "options": [
      "The ability of a system to process requests concurrently",
      "The property where an operation can be applied multiple times without changing the result beyond the initial application",
      "The ability of a system to encrypt data automatically",
      "The process of verifying user identity"
    ],
    "answer": "The property where an operation can be applied multiple times without changing the result beyond the initial application",
    "explanation": "Idempotency ensures that retrying a network request (e.g., payment processing) due to a failure does not result in duplicate transactions or inconsistent states.",
    "difficulty": "Beginner"
  },
  {
    "id": 36,
    "question": "In a distributed database using asynchronous replication, what is the primary trade-off compared to synchronous replication?",
    "options": [
      "Increased latency for all write operations",
      "Higher risk of data loss if the primary node fails before replication completes",
      "Inability to scale read operations to replica nodes",
      "Stronger data consistency guarantees across all nodes"
    ],
    "answer": "Higher risk of data loss if the primary node fails before replication completes",
    "explanation": "Asynchronous replication acknowledges writes immediately, improving performance but creating a window where data exists only on the primary. Synchronous replication waits for replicas, offering better durability but higher latency.",
    "difficulty": "Intermediate"
  },
  {
    "id": 37,
    "question": "Which load balancing algorithm is most effective for ensuring that a specific client always interacts with the same backend server, facilitating session persistence?",
    "options": [
      "Round Robin",
      "Least Connections",
      "IP Hash",
      "Random"
    ],
    "answer": "IP Hash",
    "explanation": "IP Hash uses the client's IP address to compute a hash, mapping the client to a specific server. This ensures all requests from that client go to the same server, maintaining session state without needing a distributed cache.",
    "difficulty": "Intermediate"
  },
  {
    "id": 38,
    "question": "What is the primary function of a 'Bloom Filter' in a database read path?",
    "options": [
      "To compress data before it is written to disk",
      "To quickly determine if an element is definitely not in a set, avoiding unnecessary disk reads",
      "To encrypt sensitive data at rest",
      "To sort query results before returning them to the client"
    ],
    "answer": "To quickly determine if an element is definitely not in a set, avoiding unnecessary disk reads",
    "explanation": "A Bloom Filter is a space-efficient probabilistic data structure. If it says an item is absent, it is definitely absent; if present, it is probably present. This saves disk I/O for non-existent keys.",
    "difficulty": "Intermediate"
  },
  {
    "id": 39,
    "question": "In the context of the CAP Theorem, which property is sacrificed when a distributed system chooses 'Availability' and 'Partition Tolerance' (AP)?",
    "options": [
      "Consistency",
      "Latency",
      "Scalability",
      "Durability"
    ],
    "answer": "Consistency",
    "explanation": "In an AP system, nodes remain accessible during a partition (Availability) but may return stale data because they cannot synchronize with other nodes (Sacrificing Consistency).",
    "difficulty": "Intermediate"
  },
  {
    "id": 40,
    "question": "When designing a Key-Value store, what is the main advantage of using Consistent Hashing over Modulo Hashing for data distribution?",
    "options": [
      "Guarantees that all keys are sorted lexicographically",
      "Minimizes data movement when nodes are added or removed from the cluster",
      "Ensures that the distribution of keys is perfectly even across all nodes",
      "Eliminates the need for replication"
    ],
    "answer": "Minimizes data movement when nodes are added or removed from the cluster",
    "explanation": "Consistent hashing maps both data and servers to a ring, ensuring that adding or removing a server only affects the data immediately adjacent to it, unlike modulo hashing which disrupts almost the entire cluster.",
    "difficulty": "Intermediate"
  },
  {
    "id": 41,
    "question": "Which caching strategy updates the cache only when the data in the database is modified, ensuring the cache is never stale?",
    "options": [
      "Cache-aside (Lazy Loading)",
      "Write-through",
      "Write-back (Write-behind)",
      "Refresh-ahead"
    ],
    "answer": "Write-through",
    "explanation": "In a Write-through cache, data is written to the cache and the backing database simultaneously. This ensures the cache always contains the most up-to-date data, though write latency is higher.",
    "difficulty": "Intermediate"
  },
  {
    "id": 42,
    "question": "What is a 'Hotspot' in the context of database sharding, and how does it occur?",
    "options": [
      "A server failure that causes traffic to spike on remaining nodes",
      "A specific shard key receiving a disproportionate amount of read/write traffic due to uneven distribution",
      "A network congestion point between the load balancer and the database",
      "A security vulnerability caused by high connection counts"
    ],
    "answer": "A specific shard key receiving a disproportionate amount of read/write traffic due to uneven distribution",
    "explanation": "Hotspots occur when a sharding scheme (e.g., hashing by a low-cardinality attribute like 'Country') directs too much traffic to a single shard, overwhelming that specific node.",
    "difficulty": "Intermediate"
  },
  {
    "id": 43,
    "question": "In a Microservices architecture, what is the primary role of an 'API Gateway'?",
    "options": [
      "To act as a database for all service state",
      "To serve static assets like HTML and CSS",
      "To provide a single entry point for request routing, composition, and cross-cutting concerns like auth",
      "To compile code for individual microservices"
    ],
    "answer": "To provide a single entry point for request routing, composition, and cross-cutting concerns like auth",
    "explanation": "The API Gateway handles external traffic, routing requests to specific services, aggregating responses, and managing SSL termination and authentication, abstracting the backend complexity.",
    "difficulty": "Intermediate"
  },
  {
    "id": 44,
    "question": "Which of the following best describes 'Write Skew' anomaly in database transactions?",
    "options": [
      "A transaction reads uncommitted data written by another concurrent transaction",
      "Two transactions simultaneously update the same row, causing one update to be lost",
      "Two transactions read overlapping data sets and concurrently make disjoint updates that violate a constraint when combined",
      "A transaction reads the same row twice and finds different values"
    ],
    "answer": "Two transactions read overlapping data sets and concurrently make disjoint updates that violate a constraint when combined",
    "explanation": "Write Skew occurs in Snapshot Isolation when transactions read the same consistent snapshot but modify disjoint sets of data based on that read, resulting in an inconsistent state (e.g., two on-call doctors both resigning simultaneously).",
    "difficulty": "Intermediate"
  },
  {
    "id": 45,
    "question": "Why is the 'Two-Phase Commit' (2PC) protocol considered a blocking protocol?",
    "options": [
      "It blocks all read operations while writes are processed",
      "If the coordinator fails permanently, participants may remain locked indefinitely waiting for a decision",
      "It requires a shared memory architecture",
      "It blocks network traffic to prevent congestion"
    ],
    "answer": "If the coordinator fails permanently, participants may remain locked indefinitely waiting for a decision",
    "explanation": "In Phase 1, participants vote to commit and lock resources. If the coordinator crashes before sending the final commit/rollback message in Phase 2, participants cannot release locks, causing the system to halt.",
    "difficulty": "Intermediate"
  },
  {
    "id": 46,
    "question": "What distinguishes a 'Chord' protocol from standard consistent hashing?",
    "options": [
      "Chord does not use hashing",
      "Chord implements a specific lookup protocol using a finger table to find keys in O(log N) hops",
      "Chord stores data on a single centralized node",
      "Chord requires all nodes to know the location of every other node"
    ],
    "answer": "Chord implements a specific lookup protocol using a finger table to find keys in O(log N) hops",
    "explanation": "While Chord uses consistent hashing, its defining feature is the routing protocol utilizing 'finger tables' that allow nodes to locate keys efficiently without querying every node.",
    "difficulty": "Intermediate"
  },
  {
    "id": 47,
    "question": "In the context of messaging systems, what is the primary difference between 'Message Queues' and 'Publish/Subscribe' (Pub/Sub) models?",
    "options": [
      "Queues use UDP while Pub/Sub uses TCP",
      "Queues typically send a message to one consumer, while Pub/Sub broadcasts to multiple subscribers",
      "Queues store data permanently while Pub/Sub is ephemeral",
      "Pub/Sub supports request-reply patterns while Queues do not"
    ],
    "answer": "Queues typically send a message to one consumer, while Pub/Sub broadcasts to multiple subscribers",
    "explanation": "Message Queues follow the point-to-point model where a message is consumed by a single worker (competing consumers). Pub/Sub pushes the same message to all interested subscribers.",
    "difficulty": "Intermediate"
  },
  {
    "id": 48,
    "question": "What is the purpose of 'Forward Secrecy' in the context of TLS/SSL communication?",
    "options": [
      "To ensure the server identity is verified",
      "To guarantee that past session keys cannot be compromised even if the long-term private key is compromised later",
      "To compress data during transmission",
      "To allow the client to remain anonymous"
    ],
    "answer": "To guarantee that past session keys cannot be compromised even if the long-term private key is compromised later",
    "explanation": "Forward Secrecy (Perfect Forward Secrecy) generates a unique session key for every exchange. If the server's private key is stolen later, an attacker cannot decrypt previously captured traffic.",
    "difficulty": "Intermediate"
  },
  {
    "id": 49,
    "question": "In a distributed system, what is 'Split Brain' syndrome?",
    "options": [
      "A database query that joins tables incorrectly",
      "A failure of the network partition tolerance mechanism causing two separate groups of nodes to believe they are the leaders",
      "A security attack where SQL code is injected",
      "A memory leak in the application logic"
    ],
    "answer": "A failure of the network partition tolerance mechanism causing two separate groups of nodes to believe they are the leaders",
    "explanation": "Split Brain occurs when a network partition isolates nodes, and multiple nodes or groups assume 'Primary' status. This leads to data conflicts as divergent writes are accepted on different 'active' leaders.",
    "difficulty": "Intermediate"
  },
  {
    "id": 50,
    "question": "What is the primary benefit of using a 'WAL' (Write-Ahead Logging) in database systems?",
    "options": [
      "It enables faster read performance by indexing logs",
      "It ensures atomicity and durability by writing changes to a log before applying them to the actual storage",
      "It reduces the storage footprint by compressing data",
      "It allows users to undo changes made by other users"
    ],
    "answer": "It ensures atomicity and durability by writing changes to a log before applying them to the actual storage",
    "explanation": "WAL records changes in a sequential log before modifying the database pages. In the event of a crash, the database can 'replay' the log to restore committed transactions and undo uncommitted ones.",
    "difficulty": "Intermediate"
  },
  {
    "id": 51,
    "question": "How does a 'Leaky Bucket' algorithm differ from a 'Token Bucket' algorithm for rate limiting?",
    "options": [
      "Leaky Bucket bursts immediately; Token Bucket smooths traffic",
      "Leaky Bucket enforces a strict processing rate regardless of burst size; Token Bucket allows bursts up to accumulated tokens",
      "Leaky Bucket uses UDP; Token Bucket uses TCP",
      "Leaky Bucket is only used for ingress traffic"
    ],
    "answer": "Leaky Bucket enforces a strict processing rate regardless of burst size; Token Bucket allows bursts up to accumulated tokens",
    "explanation": "The Leaky Bucket acts like a queue with a fixed outflow rate, smoothing bursty traffic. The Token Bucket saves up 'tokens' to allow for temporary bursts of traffic while maintaining the long-term rate.",
    "difficulty": "Intermediate"
  },
  {
    "id": 52,
    "question": "In a RESTful API, what is the standard HTTP status code returned when a client sends a request that is syntactically correct but semantically erroneous (e.g., creating a user with an invalid email format)?",
    "options": [
      "500 Internal Server Error",
      "200 OK",
      "422 Unprocessable Entity",
      "301 Moved Permanently"
    ],
    "answer": "422 Unprocessable Entity",
    "explanation": "While 400 Bad Request is generic, 422 is specific for WebDAV/REST semantics indicating the server understands the content type but cannot process the contained instructions (semantic errors).",
    "difficulty": "Intermediate"
  },
  {
    "id": 53,
    "question": "What is 'Event Sourcing'?",
    "options": [
      "Storing only the current state of an entity in the database",
      "Persisting a sequence of state-changing events rather than just the current state",
      "Using message queues to source data from external APIs",
      "Triggering functions based on cron schedules"
    ],
    "answer": "Persisting a sequence of state-changing events rather than just the current state",
    "explanation": "Event Sourcing ensures all changes to application state are stored as a sequence of immutable events. This allows for auditing, replaying events to rebuild state, and temporal queries.",
    "difficulty": "Intermediate"
  },
  {
    "id": 54,
    "question": "What is the 'Read Repair' mechanism in distributed databases like Cassandra or DynamoDB?",
    "options": [
      "A process that stops read requests to failing nodes",
      "A background anti-entropy mechanism that updates stale replicas during a read operation",
      "A tool to fix corrupted SQL syntax",
      "A method of compressing data on disk"
    ],
    "answer": "A background anti-entropy mechanism that updates stale replicas during a read operation",
    "explanation": "When a read request returns data from multiple replicas, the system compares versions. If versions differ, the most recent version is sent to the client, and the system asynchronously pushes the updated data to the stale replicas.",
    "difficulty": "Intermediate"
  },
  {
    "id": 55,
    "question": "Which of the following best describes 'Blue-Green Deployment'?",
    "options": [
      "Deploying updates to all servers simultaneously",
      "Running two identical production environments and switching traffic to the new one to enable instant rollback",
      "Deploying updates to a subset of users first (Canary)",
      "Keeping the application in a monolithic structure"
    ],
    "answer": "Running two identical production environments and switching traffic to the new one to enable instant rollback",
    "explanation": "Blue-Green Deployment minimizes downtime by having a current 'Blue' environment and an idle 'Green' environment with the new version. Traffic is routed to Green once validated.",
    "difficulty": "Intermediate"
  },
  {
    "id": 56,
    "question": "What is the main disadvantage of using 'Long Polling' compared to WebSockets for real-time updates?",
    "options": [
      "Long Polling cannot run over HTTP",
      "Long Polling has higher latency because each request requires a new HTTP connection and handshake",
      "Long Polling does not work with JavaScript",
      "Long Polling requires a persistent TCP connection"
    ],
    "answer": "Long Polling has higher latency because each request requires a new HTTP connection and handshake",
    "explanation": "Long Polling holds the connection open until data arrives, then closes and requires the client to reconnect. This overhead causes latency and resource consumption compared to the single, full-duplex connection of WebSockets.",
    "difficulty": "Intermediate"
  },
  {
    "id": 57,
    "question": "What is 'Quorum' in the context of distributed consensus (e.g., Raft, Paxos)?",
    "options": [
      "A simple majority of nodes required to agree on a value",
      "A timeout mechanism for leader election",
      "The act of dividing the network into sub-networks",
      "A specific type of encryption key"
    ],
    "answer": "A simple majority of nodes required to agree on a value",
    "explanation": "A quorum ensures that a cluster can only make progress if a majority (N/2 + 1) of nodes are reachable and agree. This prevents split-brain by ensuring two minorities cannot form separate majorities.",
    "difficulty": "Intermediate"
  },
  {
    "id": 58,
    "question": "In database indexing, what is a 'Covering Index'?",
    "options": [
      "An index that is used for all queries in the system",
      "An index that contains all the columns required by a specific query, allowing the data to be fetched without accessing the table rows",
      "An index that covers the entire disk sector",
      "A backup of the primary index"
    ],
    "answer": "An index that contains all the columns required by a specific query, allowing the data to be fetched without accessing the table rows",
    "explanation": "If a query's SELECT and WHERE clauses only involve columns present in the index, the database engine can satisfy the query purely from the index structure, avoiding expensive lookups in the main data table.",
    "difficulty": "Intermediate"
  },
  {
    "id": 59,
    "question": "What is 'Idempotency' in the context of API design?",
    "options": [
      "The ability of an API to handle multiple users at once",
      "The property where making the same request multiple times has the same effect as making it once",
      "The ability to cache responses automatically",
      "The requirement that all API methods must be POST requests"
    ],
    "answer": "The property where making the same request multiple times has the same effect as making it once",
    "explanation": "Idempotency is crucial for reliability in distributed systems. If a network failure causes a client to retry a request (e.g., charging a credit card), idempotency ensures the charge is applied only once.",
    "difficulty": "Intermediate"
  },
  {
    "id": 60,
    "question": "Which consistency model allows reads to return any value (stale or fresh) but ensures that writes are eventually propagated to all replicas?",
    "options": [
      "Strong Consistency",
      "Eventual Consistency",
      "Causal Consistency",
      "Read Your Writes"
    ],
    "answer": "Eventual Consistency",
    "explanation": "Eventual consistency guarantees that if no new updates are made to a given data item, eventually all accesses to that item will return the last updated value.",
    "difficulty": "Intermediate"
  },
  {
    "id": 61,
    "question": "What is the 'Sidecar Pattern' in microservices architecture?",
    "options": [
      "Deploying two identical applications for load balancing",
      "Attaching a helper process/service to the main application to abstract away functionality like logging or monitoring",
      "Using a single database for all services",
      "A database backup strategy"
    ],
    "answer": "Attaching a helper process/service to the main application to abstract away functionality like logging or monitoring",
    "explanation": "The Sidecar pattern deploys a utility container alongside the main service container in the same pod/VM. It shares the lifecycle and resources, handling cross-cutting concerns like networking, observability, or sync.",
    "difficulty": "Intermediate"
  },
  {
    "id": 62,
    "question": "What is the primary reason for using 'gRPC' over REST for internal microservice communication?",
    "options": [
      "gRPC uses JSON which is human-readable",
      "gRPC utilizes HTTP/2 and Protocol Buffers for lower latency and smaller message sizes",
      "gRPC does not require a schema definition",
      "gRPC is natively supported by all web browsers"
    ],
    "answer": "gRPC utilizes HTTP/2 and Protocol Buffers for lower latency and smaller message sizes",
    "explanation": "gRPC uses Protocol Buffers (binary serialization) which is faster and lighter than JSON, and leverages HTTP/2 for multiplexing. This makes it ideal for efficient service-to-service communication.",
    "difficulty": "Intermediate"
  },
  {
    "id": 63,
    "question": "In the context of storage systems, what is 'Erasure Coding'?",
    "options": [
      "A method for compressing files",
      "A data protection method that divides data into fragments, expands and encodes them with redundant data, and stores them across different locations",
      "A way to delete data permanently",
      "An encryption algorithm"
    ],
    "answer": "A data protection method that divides data into fragments, expands and encodes them with redundant data, and stores them across different locations",
    "explanation": "Unlike simple replication (mirroring), Erasure Coding breaks data into chunks with parity information. It offers significantly higher durability for the same storage overhead (e.g., surviving 3 drive failures with 1.5x overhead).",
    "difficulty": "Intermediate"
  },
  {
    "id": 64,
    "question": "What is the 'Circuit Breaker' pattern used for?",
    "options": [
      "To stop the flow of electricity in a data center",
      "To detect failures and prevent a cascading failure by wrapping remote calls and stopping requests to a failing service",
      "To split a database into shards",
      "To cache data in memory"
    ],
    "answer": "To detect failures and prevent a cascading failure by wrapping remote calls and stopping requests to a failing service",
    "explanation": "When a service dependency fails repeatedly, the Circuit Breaker 'trips' (opens) and blocks calls to that service for a duration. This prevents the system from hanging on timeouts and allows resources to recover.",
    "difficulty": "Intermediate"
  },
  {
    "id": 65,
    "question": "What is the primary limitation of vertical scaling (Scale-up)?",
    "options": [
      "It increases network latency",
      "There is a finite hardware limit (CPU/RAM) beyond which a single machine cannot be upgraded",
      "It requires partitioning the database",
      "It creates more single points of failure than horizontal scaling"
    ],
    "answer": "There is a finite hardware limit (CPU/RAM) beyond which a single machine cannot be upgraded",
    "explanation": "Vertical scaling is bound by the maximum capacity of the most powerful server available. Once that limit is reached, scaling further requires architectural changes to horizontal scaling.",
    "difficulty": "Intermediate"
  },
  {
    "id": 66,
    "question": "What is a 'Zero Downtime Deployment'?",
    "options": [
      "A deployment that happens on public holidays",
      "Updating a system without causing an interruption in service availability",
      "A deployment that ignores error logs",
      "A deployment that reverts changes immediately"
    ],
    "answer": "Updating a system without causing an interruption in service availability",
    "explanation": "Zero downtime deployment strategies (like rolling updates or blue-green) ensure that the application remains accessible to users throughout the update process, often by keeping old instances running until new ones are healthy.",
    "difficulty": "Intermediate"
  },
  {
    "id": 67,
    "question": "Which property of a distributed system ensures that 'every read receives the most recent write or an error'?",
    "options": [
      "Availability",
      "Partition Tolerance",
      "Linearizability (Strong Consistency)",
      "Eventual Consistency"
    ],
    "answer": "Linearizability (Strong Consistency)",
    "explanation": "Linearizability is the strongest consistency model. It guarantees that once a write completes, all subsequent reads (from any client) will see that write, appearing as if there is only a single copy of the data.",
    "difficulty": "Intermediate"
  },
  {
    "id": 68,
    "question": "What is the main purpose of a 'Message Broker' (e.g., RabbitMQ, Kafka) in an event-driven architecture?",
    "options": [
      "To format HTML responses for the browser",
      "To translate SQL queries into NoSQL",
      "To decouple producers and consumers by buffering and asynchronously transmitting messages",
      "To act as the primary database"
    ],
    "answer": "To decouple producers and consumers by buffering and asynchronously transmitting messages",
    "explanation": "Message brokers manage the routing of messages between services. They handle persistence, retries, and flow control, allowing services to communicate without being online at the same time.",
    "difficulty": "Intermediate"
  },
  {
    "id": 69,
    "question": "What is 'Sharding' in the context of databases?",
    "options": [
      "Replicating data to multiple servers for read availability",
      "Horizontal partitioning of data rows across multiple independent database instances",
      "Backing up data to a tape drive",
      "Compressing data to save space"
    ],
    "answer": "Horizontal partitioning of data rows across multiple independent database instances",
    "explanation": "Sharding distributes a large dataset across multiple distinct machines (shards) based on a shard key. Unlike replication, each shard holds a unique subset of the data, enabling scale-out for massive write loads.",
    "difficulty": "Intermediate"
  },
  {
    "id": 70,
    "question": "In the context of distributed databases, how does the PACELC theorem extend the CAP theorem?",
    "options": [
      "It states that Partition tolerance is optional in cloud environments due to advanced networking.",
      "In case of Partition (P), trade off between Availability (A) and Consistency (C); Else (E), trade off between Latency (L) and Consistency (C).",
      "It replaces Consistency with Durability as a primary requirement for financial systems.",
      "It suggests that Availability and Consistency can be simultaneously achieved if the network latency is zero."
    ],
    "answer": "In case of Partition (P), trade off between Availability (A) and Consistency (C); Else (E), trade off between Latency (L) and Consistency (C).",
    "explanation": "PACELC dictates that during a partition, one must choose Availability or Consistency; otherwise, during normal operation, one must choose between lower Latency and Consistency.",
    "difficulty": "Advanced"
  },
  {
    "id": 71,
    "question": "What is the primary advantage of using a Log-Structured Merge-tree (LSM tree) over a B+ Tree for a write-heavy database workload?",
    "options": [
      "LSM trees provide faster read performance by keeping all data in a sorted in-memory structure.",
      "LSM trees turn random writes into sequential writes, significantly reducing write amplification and disk seek costs.",
      "LSM trees eliminate the need for write-ahead logging (WAL) by ensuring data is immutable on disk.",
      "LSM trees allow for range queries without needing to merge multiple sorted files."
    ],
    "answer": "LSM trees turn random writes into sequential writes, significantly reducing write amplification and disk seek costs.",
    "explanation": "LSM trees buffer writes in memory (MemTable) and flush them as sorted immutable files (SSTables), transforming random disk I/O into sequential I/O, which is faster for spinning disks and SSDs.",
    "difficulty": "Advanced"
  },
  {
    "id": 72,
    "question": "When designing a globally distributed system, what is the main benefit of employing vector clocks for conflict detection?",
    "options": [
      "They guarantee strict serializability across all database shards without requiring distributed locks.",
      "They allow the system to determine causality between events and detect concurrent updates without relying on a global synchronized clock.",
      "They eliminate network latency by compressing timestamps into a binary vector format.",
      "They ensure that all nodes in the cluster agree on the order of transactions using a quorum-based approach."
    ],
    "answer": "They allow the system to determine causality between events and detect concurrent updates without relying on a global synchronized clock.",
    "explanation": "Vector clocks track the version history of data per node, allowing the system to distinguish if an update is causally related (happened after) or concurrent (happened at the same time) to another update.",
    "difficulty": "Advanced"
  },
  {
    "id": 73,
    "question": "Why might a system architect choose a two-phase commit (2PC) protocol over the Saga pattern for distributed transactions?",
    "options": [
      "2PC provides strong atomicity and isolation guarantees, ensuring all participants commit or abort together, unlike Sagas which offer eventual consistency.",
      "2PC is non-blocking and allows transactions to complete even if the coordinator node fails.",
      "2PC requires significantly fewer database round-trips than the Saga pattern.",
      "2PC supports long-running transactions (hours or days) efficiently without holding database locks."
    ],
    "answer": "2PC provides strong atomicity and isolation guarantees, ensuring all participants commit or abort together, unlike Sagas which offer eventual consistency.",
    "explanation": "2PC ensures ACID properties across distributed resources (atomic commitment), whereas Sagas break transactions into a sequence of local transactions managed by compensation logic, resulting in eventual consistency.",
    "difficulty": "Advanced"
  },
  {
    "id": 74,
    "question": "How does the 'Lease' mechanism improve upon standard 'Heartbeats' in distributed leader election?",
    "options": [
      "Leases use a cryptographic signature to verify the identity of the leader.",
      "Leases guarantee that a leader cannot fail over to a replica until a timeout expires, preventing split-brain.",
      "Leases enforce a timeout that guarantees a node has exclusive rights to a resource for a duration, handling network partitions gracefully.",
      "Leases allow multiple leaders to exist simultaneously to handle high availability requirements."
    ],
    "answer": "Leases enforce a timeout that guarantees a node has exclusive rights to a resource for a duration, handling network partitions gracefully.",
    "explanation": "A lease grants a node authority for a specific time window. If the node cannot renew the lease (due to failure or partition), it loses authority automatically, preventing split-brain scenarios better than simple liveness heartbeats.",
    "difficulty": "Advanced"
  },
  {
    "id": 75,
    "question": "In the context of consistent hashing, what is the primary purpose of adding 'virtual nodes' to the hash ring?",
    "options": [
      "To encrypt the data keys as they are mapped to the physical servers.",
      "To ensure a more uniform distribution of data and minimize data rebalancing when physical nodes are added or removed.",
      "To replicate data across different geographical regions automatically.",
      "To reduce the computational complexity of the hash function from O(N) to O(1)."
    ],
    "answer": "To ensure a more uniform distribution of data and minimize data rebalancing when physical nodes are added or removed.",
    "explanation": "Virtual nodes map multiple points on the ring to a single physical server. This smooths out the distribution of keys, preventing 'hot spots' and ensuring that when a node fails, its load is dispersed evenly across the remaining nodes.",
    "difficulty": "Advanced"
  },
  {
    "id": 76,
    "question": "What specific problem does the 'Write Skew' anomaly represent in database isolation levels?",
    "options": [
      "A transaction reads a value that was written by a concurrent transaction that has not yet committed.",
      "Two transactions concurrently read overlapping data sets and then make disjoint updates based on the read, violating a constraint.",
      "A transaction reads the same row twice and finds the data has changed by another transaction.",
      "Data is modified in non-serializable order, leading to phantom reads within a range query."
    ],
    "answer": "Two transactions concurrently read overlapping data sets and then make disjoint updates based on the read, violating a constraint.",
    "explanation": "Write skew occurs in Snapshot Isolation where two transactions read the same consistent snapshot but modify disjoint sets of items based on that read, resulting in a state that could not have happened serially (e.g., two on-call doctors both resigning simultaneously).",
    "difficulty": "Advanced"
  },
  {
    "id": 77,
    "question": "When implementing a rate limiter, what is a key functional difference between the 'Token Bucket' and 'Leaky Bucket' algorithms?",
    "options": [
      "Token Bucket discards packets when the bucket is full, whereas Leaky Bucket throttles the transmission rate.",
      "Leaky Bucket allows bursts up to the bucket capacity, while Token Bucket enforces a strict steady rate.",
      "Token Bucket allows bursts to continue as long as tokens are available, while Leaky Bucket smoothes traffic into a constant rate.",
      "Token Bucket is only suitable for network hardware, while Leaky Bucket is designed for software API gateways."
    ],
    "answer": "Token Bucket allows bursts to continue as long as tokens are available, while Leaky Bucket smoothes traffic into a constant rate.",
    "explanation": "Token Bucket adds tokens at a fixed rate but allows consumption of all accumulated tokens at once (burst), whereas Leaky Bucket releases data at a fixed rate, effectively smoothing out any traffic bursts.",
    "difficulty": "Advanced"
  },
  {
    "id": 78,
    "question": "What is the 'Write Amplification' factor in SSD storage, and why is minimizing it critical for system longevity?",
    "options": [
      "It is the ratio of logical data written to physical data written; high amplification wears out flash memory cells faster.",
      "It is the multiplication of data required for erasure coding; minimizing it saves storage space.",
      "It is the increase in latency when writing to multiple database shards; reducing it improves write throughput.",
      "It is the number of copies made by the replication layer; reducing it minimizes network bandwidth usage."
    ],
    "answer": "It is the ratio of logical data written to physical data written; high amplification wears out flash memory cells faster.",
    "explanation": "SSDs cannot overwrite data directly; they must erase blocks before writing. If 4KB of logical data requires a 256KB block erase and rewrite, the write amplification is 64x, reducing SSD lifespan and performance.",
    "difficulty": "Advanced"
  },
  {
    "id": 79,
    "question": "In a distributed message queue like Apache Kafka, why are messages typically partitioned within a topic?",
    "options": [
      "To ensure that all messages are delivered to every consumer group for backup purposes.",
      "To allow parallel processing and scalability by distributing the load across multiple broker servers and consumer instances.",
      "To automatically compress messages using a proprietary algorithm to save network bandwidth.",
      "To enforce a strict order of messages globally across the entire cluster."
    ],
    "answer": "To allow parallel processing and scalability by distributing the load across multiple broker servers and consumer instances.",
    "explanation": "Partitions enable parallelism. A single topic's throughput is limited by one server, but partitioning allows multiple producers to write to different partitions and multiple consumers to read in parallel.",
    "difficulty": "Advanced"
  },
  {
    "id": 80,
    "question": "What is the 'Sidecar' pattern in microservices architecture, and what is its primary benefit?",
    "options": [
      "Deploying a secondary instance of the service to handle read requests separately from write requests.",
      "Running utility components (logging, monitoring, networking) in a separate process alongside the main service to abstract away infrastructure logic.",
      "Chaining multiple services together in a linear sequence to process a request.",
      "Using a dedicated database server that sits alongside the application server to cache frequent queries."
    ],
    "answer": "Running utility components (logging, monitoring, networking) in a separate process alongside the main service to abstract away infrastructure logic.",
    "explanation": "The sidecar pattern deploys helper features (like service mesh proxies) as a separate container/pod sharing the lifecycle with the main app, keeping the application code language-agnostic and decoupled from platform-specific logic.",
    "difficulty": "Advanced"
  },
  {
    "id": 81,
    "question": "How does 'Hierarchical Timing Wheels' (like in Netty or Kafka timer) optimize the management of delayed operations?",
    "options": [
      "They use a priority queue that sorts tasks by execution time, ensuring O(1) insertions.",
      " They structure time in buckets (e.g., hours, minutes, milliseconds), allowing task scheduling and expiration in O(1) time.",
      "They rely on a single background thread that sleeps for the exact duration of the next task.",
      "They use a binary search tree to balance the load of timer tasks across CPU cores."
    ],
    "answer": " They structure time in buckets (e.g., hours, minutes, milliseconds), allowing task scheduling and expiration in O(1) time.",
    "explanation": "Timing wheels approximate time into discrete buckets. 'Ticking' the wheel to the next bucket expires all tasks in that bucket efficiently, avoiding the O(log N) cost of inserting into a priority queue for every tick.",
    "difficulty": "Advanced"
  },
  {
    "id": 82,
    "question": "In the context of Content Delivery Networks (CDNs), what is the primary function of an 'Edge Include' or 'Edge Side Includes' (ESI)?",
    "options": [
      "To compress static assets at the edge to reduce bandwidth consumption.",
      "To assemble dynamic web pages by assembling cached fragments of HTML from different edge locations.",
      "To filter out malicious traffic at the edge before it reaches the origin server.",
      "To route traffic to the nearest geographically located server using anycast IP."
    ],
    "answer": "To assemble dynamic web pages by assembling cached fragments of HTML from different edge locations.",
    "explanation": "ESI allows a page to be defined as a collection of fragments. The edge server can cache these fragments independently and assemble them for the user, allowing parts of a dynamic page (like a header) to be cached while other parts are personalized.",
    "difficulty": "Advanced"
  },
  {
    "id": 83,
    "question": "What is the 'Theta-Membership' (or similar approximation) protocol used for in large-scale distributed systems?",
    "options": [
      "Synchronizing the system clock across all nodes to within 10 milliseconds.",
      "Efficiently detecting the arrival or departure of members in a cluster with minimal message complexity.",
      "Compressing large log files before they are shipped to a central analytics server.",
      "Calculating the exact number of distinct users visiting a website in real-time."
    ],
    "answer": "Efficiently detecting the arrival or departure of members in a cluster with minimal message complexity.",
    "explanation": "Scalable failure detectors often use gossip or phi-accrual (statistical approaches) to suspect failures, but protocols like SWIM (Scalable Weakly-consistent Infection-style Process Group Membership) use suspicion and dissemination to minimize network traffic while maintaining member lists.",
    "difficulty": "Advanced"
  },
  {
    "id": 84,
    "question": "What is the primary drawback of using 'Write-Through' caching compared to 'Write-Back' (Write-Behind) caching?",
    "options": [
      "Write-Through caches suffer from the 'thundering herd' problem during cache misses.",
      "Write-Through guarantees lower write latency because data is only written to the faster cache memory.",
      "Write-Through has higher write latency because data must be written to both the cache and the backing store synchronously.",
      "Write-Through can lead to data inconsistency if the cache crashes before writing to the database."
    ],
    "answer": "Write-Through has higher write latency because data must be written to both the cache and the backing store synchronously.",
    "explanation": "Write-Through ensures data consistency by writing to cache and DB immediately. However, the application must wait for the slower DB write to complete, whereas Write-Back only writes to cache and syncs to DB asynchronously.",
    "difficulty": "Advanced"
  },
  {
    "id": 85,
    "question": "In distributed consensus algorithms like Raft or Paxos, what is the specific purpose of the 'Log Replication' phase?",
    "options": [
      "To elect a new leader candidate after the previous leader fails.",
      "To serialize client commands and ensure a majority of nodes agree on the order of state machine commands.",
      "To take a snapshot of the current state to compact the log.",
      "To detect network partitions using heartbeat messages."
    ],
    "answer": "To serialize client commands and ensure a majority of nodes agree on the order of state machine commands.",
    "explanation": "Once a leader is established, it accepts commands from clients, appends them to its log, and sends AppendEntries RPCs to followers. A command is considered 'committed' once it is safely stored on a majority of nodes.",
    "difficulty": "Advanced"
  },
  {
    "id": 86,
    "question": "What is 'Backpressure' in reactive programming and stream processing?",
    "options": [
      "A mechanism where a slow consumer signals the producer to slow down the rate of data emission, preventing memory exhaustion.",
      "The process of compressing data packets to fit within the network MTU size.",
      "A security mechanism that blocks requests originating from suspicious IP addresses.",
      "The retry logic applied when a database connection fails during a transaction."
    ],
    "answer": "A mechanism where a slow consumer signals the producer to slow down the rate of data emission, preventing memory exhaustion.",
    "explanation": "Without backpressure, a fast producer can overwhelm a slow consumer, causing the consumer to buffer unbounded data leading to OutOfMemoryErrors. Reactive streams implement protocols to manage this flow control.",
    "difficulty": "Advanced"
  },
  {
    "id": 87,
    "question": "Why are Bloom Filters commonly used in database engines (like Cassandra or RocksDB) read paths?",
    "options": [
      "To encrypt the data stored on disk to prevent unauthorized access.",
      "To quickly determine if an element is definitely not in a set, avoiding expensive disk I/O for non-existent keys.",
      "To sort the data before it is written to disk, optimizing range scans.",
      "To compress the data by removing duplicate values before storage."
    ],
    "answer": "To quickly determine if an element is definitely not in a set, avoiding expensive disk I/O for non-existent keys.",
    "explanation": "A Bloom Filter is a probabilistic memory-efficient data structure. If it says 'No', the key is definitely not on disk. If it says 'Yes', it *might* be there, preventing unnecessary disk reads for keys that don't exist.",
    "difficulty": "Advanced"
  },
  {
    "id": 88,
    "question": "What is the 'Split-Brain' problem in distributed high-availability systems?",
    "options": [
      "When a database query is split across multiple shards to improve performance.",
      "When a network partition causes two distinct subsets of the cluster to independently believe they are the active leaders.",
      "When a process enters an infinite loop due to a recursive programming error.",
      "When the load balancer distributes traffic unevenly, causing some servers to crash."
    ],
    "answer": "When a network partition causes two distinct subsets of the cluster to independently believe they are the active leaders.",
    "explanation": "Split-Brain occurs when the network links between nodes fail. If both sides can still achieve a quorum (or if quorum isn't enforced), both may elect a leader and accept writes, leading to data conflicts that are hard to reconcile.",
    "difficulty": "Advanced"
  },
  {
    "id": 89,
    "question": "In the context of API Gateway patterns, what is the purpose of 'BFF' (Backend for Frontend)?",
    "options": [
      "To serve as a single entry point for all backend microservices, handling authentication and rate limiting globally.",
      "To create specialized API layers tailored to the specific needs of different client interfaces (e.g., mobile vs. desktop) to avoid over-fetching.",
      "To cache all responses permanently at the edge to reduce origin load.",
      "To provide a backup server that takes over if the primary backend fails."
    ],
    "answer": "To create specialized API layers tailored to the specific needs of different client interfaces (e.g., mobile vs. desktop) to avoid over-fetching.",
    "explanation": "A generic API gateway often returns a data model designed for the backend, leading to over-fetching on mobile. A BFF creates a dedicated backend layer per client type, aggregating data specifically for that UI.",
    "difficulty": "Advanced"
  },
  {
    "id": 90,
    "question": "What is the 'Watermark' or 'High Water Mark' in a distributed commit log (like Kafka or Pulsar)?",
    "options": [
      "The maximum amount of disk space a topic can utilize before old messages are deleted.",
      "The offset of the last message that has been successfully replicated to all in-sync replicas.",
      "The speed at which consumers are draining messages from the topic.",
      "The timestamp of the oldest message currently available in the log."
    ],
    "answer": "The offset of the last message that has been successfully replicated to all in-sync replicas.",
    "explanation": "The high watermark tracks the point up to which all replicas have confirmed they have replicated the data. Consumers can only read up to this point to ensure they don't read data that might be lost if a leader fails.",
    "difficulty": "Advanced"
  },
  {
    "id": 91,
    "question": "How does 'QUIC' (Quick UDP Internet Connections) protocol improve performance over TCP for HTTP/3?",
    "options": [
      "QUIC eliminates the need for handshakes by using pre-shared public keys.",
      "QUIC runs over UDP, avoiding Head-of-Line (HOL) blocking and providing faster connection establishment (0-RTT).",
      "QUIC compresses HTTP headers more aggressively than HTTP/2.",
      "QUIC routes packets through the internet using a priority flag that bypasses standard router queues."
    ],
    "answer": "QUIC runs over UDP, avoiding Head-of-Line (HOL) blocking and providing faster connection establishment (0-RTT).",
    "explanation": "In TCP, if one packet is lost, all subsequent packets stall (HOL blocking). QUIC multiplexes streams over UDP independently; losing a packet in one stream only affects that specific stream, not the connection.",
    "difficulty": "Advanced"
  },
  {
    "id": 92,
    "question": "What is the significance of the 'SSTable' (Sorted String Table) file structure in NoSQL stores like Bigtable or Cassandra?",
    "options": [
      "It allows random updates to specific rows within the file without rewriting the whole file.",
      "It is an immutable, sorted file on disk that allows for efficient merging and fast sequential reads during compaction.",
      "It stores data in a B-Tree format specifically optimized for in-memory operations.",
      "It encrypts data at rest using a sorted list of keys to improve lookup security."
    ],
    "answer": "It is an immutable, sorted file on disk that allows for efficient merging and fast sequential reads during compaction.",
    "explanation": "SSTables are immutable once written. This simplifies concurrency (no locks for writes) and allows the background process to merge and compact old SSTables into larger ones efficiently, maintaining sort order.",
    "difficulty": "Advanced"
  },
  {
    "id": 93,
    "question": "When implementing a 'Strangler Fig' pattern for migrating a monolith to microservices, what is the primary mechanism?",
    "options": [
      "Rewriting the entire monolith from scratch in a new language before deploying it.",
      "Placing a proxy (or Facade) in front of the monolith to route specific URLs to new services, gradually strangling the old system.",
      "Deploying the new microservices inside the same process as the monolith to share memory.",
      "Converting the monolith's database into a single SQL view for all microservices to use."
    ],
    "answer": "Placing a proxy (or Facade) in front of the monolith to route specific URLs to new services, gradually strangling the old system.",
    "explanation": "The Strangler Fig pattern uses a reverse proxy to intercept requests. If a request corresponds to new functionality, the proxy routes it to the new service; otherwise, it goes to the legacy monolith, allowing for incremental replacement.",
    "difficulty": "Advanced"
  },
  {
    "id": 94,
    "question": "What is the trade-off of using 'Event Sourcing' instead of a traditional CRUD database model?",
    "options": [
      "Event Sourcing makes it impossible to query the current state of an object efficiently.",
      "Event Sourcing uses significantly more storage because it stores every state change rather than just the current state.",
      "Event Sourcing cannot handle high write throughput due to locking constraints.",
      "Event Sourcing automatically loses historical data once an event is processed."
    ],
    "answer": "Event Sourcing uses significantly more storage because it stores every state change rather than just the current state.",
    "explanation": "In CRUD, you overwrite the current state. In Event Sourcing, you append immutable events representing state changes. This creates a history log, increasing storage volume and complexity (requires snapshots/replays) but providing a perfect audit trail.",
    "difficulty": "Advanced"
  },
  {
    "id": 95,
    "question": "How does 'Erasure Coding' differ from 'Replication' in distributed storage systems (like Ceph or AWS S3)?",
    "options": [
      "Erasure Coding requires 3 copies of every object, while Replication requires only 2.",
      "Erasure Coding fragments data into shards and calculates parity blocks, offering higher durability with lower storage overhead than replication.",
      "Replication uses compression to save space, while Erasure Coding expands data size.",
      "Erasure Coding is strictly faster for writing data, while Replication is faster for reading."
    ],
    "answer": "Erasure Coding fragments data into shards and calculates parity blocks, offering higher durability with lower storage overhead than replication.",
    "explanation": "Replication (e.g., 3x) wastes 200% space. Erasure coding (e.g., 6+3) splits data into 6 chunks and adds 3 parity chunks; it can tolerate 3 failures with only 50% overhead, offering better storage efficiency at the cost of CPU calculation.",
    "difficulty": "Advanced"
  },
  {
    "id": 96,
    "question": "What is 'Write Amplification' in the context of database compaction (specifically in LSM trees)?",
    "options": [
      "The phenomenon where a single logical write results in multiple physical writes to disk during MemTable flushes and SSTable compactions.",
      "The process of amplifying write requests to multiple data centers simultaneously.",
      "The increase in data size when moving data from a hot storage tier to cold storage.",
      "The delay experienced by a write operation due to network latency."
    ],
    "answer": "The phenomenon where a single logical write results in multiple physical writes to disk during MemTable flushes and SSTable compactions.",
    "explanation": "In LSM trees, data is rewritten multiple times: from MemTable to L0 SSTable, then merged into L1, then L2, etc. A single update might be written 3-4 times over its lifetime, consuming disk bandwidth.",
    "difficulty": "Advanced"
  },
  {
    "id": 97,
    "question": "In a message consumer group, what behavior ensures that a message is processed at least once?",
    "options": [
      "The consumer commits the offset to the broker only after successfully processing the message.",
      "The consumer acknowledges the message immediately upon receipt from the broker.",
      "The broker deletes the message as soon as it is sent over the network.",
      "The consumer processes the message idempotently using a unique transaction ID."
    ],
    "answer": "The consumer commits the offset to the broker only after successfully processing the message.",
    "explanation": "If the consumer fails after processing but before committing, the broker will redeliver the message upon restart. While this guarantees 'at-least-once' delivery, it requires idempotency handling to prevent duplicates.",
    "difficulty": "Advanced"
  },
  {
    "id": 98,
    "question": "What is the primary advantage of a 'Chord' Distributed Hash Table (DHT) over a simple 'Consistent Hashing' ring?",
    "options": [
      "Chord guarantees that no two nodes will ever hold the same data key.",
      "Chord provides a routing protocol (finger tables) that allows lookups in O(log N) hops rather than O(N) linear scanning.",
      "Chord eliminates the need for virtual nodes by using physical node IDs.",
      "Chord uses a centralized directory to store the location of all keys."
    ],
    "answer": "Chord provides a routing protocol (finger tables) that allows lookups in O(log N) hops rather than O(N) linear scanning.",
    "explanation": "Standard consistent hashing requires a node to know about all other nodes (or linear search) to find data. Chord maintains 'finger tables' (routing shortcuts) so any node can find a key in logarithmic time.",
    "difficulty": "Advanced"
  },
  {
    "id": 99,
    "question": "Why is 'Monotonic Reads' an important consistency model for certain user-facing applications?",
    "options": [
      "It ensures that once a user reads a value, they never see an older value subsequently.",
      "It ensures that all users across the globe see the data at the exact same time.",
      "It ensures that write operations occur in the order they were received by the leader.",
      "It prevents two users from modifying the same record at the same time."
    ],
    "answer": "It ensures that once a user reads a value, they never see an older value subsequently.",
    "explanation": "In systems with eventual consistency (e.g., multiple replicas), a user hitting different servers might read 'New' then 'Old'. Monotonic Reads binds a user session to a state progression, preventing time-travel anomalies.",
    "difficulty": "Advanced"
  }
]