[
  {
    "id": 1,
    "question": "What is the primary purpose of Big-O notation in algorithm analysis?",
    "options": [
      "To measure the exact execution time in milliseconds",
      "To quantify the worst-case growth rate of an algorithm's resource usage as input size increases",
      "To calculate the average memory consumed by the CPU cache",
      "To determine the number of lines of code required for implementation"
    ],
    "answer": "To quantify the worst-case growth rate of an algorithm's resource usage as input size increases",
    "explanation": "Big-O notation describes the upper bound of complexity, focusing on scalability rather than precise execution time. It abstracts hardware constants to analyze efficiency limits.",
    "difficulty": "Beginner"
  },
  {
    "id": 2,
    "question": "Which time complexity class represents the most efficient performance for searching a sorted array using a binary search algorithm?",
    "options": [
      "O(n)",
      "O(1)",
      "O(n²)",
      "O(log n)"
    ],
    "answer": "O(log n)",
    "explanation": "Binary search halves the search space at each step, resulting in logarithmic time complexity. O(1) is faster but not applicable to standard binary search implementations.",
    "difficulty": "Beginner"
  },
  {
    "id": 3,
    "question": "In the context of data structures, what is the defining characteristic of a Stack?",
    "options": [
      "First-In, First-Out (FIFO)",
      "Last-In, First-Out (LIFO)",
      "Random access via index",
      "Priority-based retrieval"
    ],
    "answer": "Last-In, First-Out (LIFO)",
    "explanation": "A Stack operates on LIFO principles, where the most recently added element is the first to be removed. FIFO is the characteristic of a Queue.",
    "difficulty": "Beginner"
  },
  {
    "id": 4,
    "question": "What is the worst-case time complexity of the Bubble Sort algorithm?",
    "options": [
      "O(n log n)",
      "O(n)",
      "O(n²)",
      "O(2^n)"
    ],
    "answer": "O(n²)",
    "explanation": "Bubble Sort involves nested loops iterating over the list, resulting in quadratic time complexity in the worst and average cases. O(n log n) is typical of efficient sorts like Merge Sort.",
    "difficulty": "Beginner"
  },
  {
    "id": 5,
    "question": "Which data structure is best suited for implementing a LRU (Least Recently Used) Cache?",
    "options": [
      "Singly Linked List",
      "Hash Map combined with a Doubly Linked List",
      "Array",
      "Binary Search Tree"
    ],
    "answer": "Hash Map combined with a Doubly Linked List",
    "explanation": "A Hash Map provides O(1) access, while a Doubly Linked List maintains the usage order for O(1) updates. Arrays require O(n) shifts for insertion/deletion.",
    "difficulty": "Beginner"
  },
  {
    "id": 6,
    "question": "What is a 'collision' in the context of Hash Tables?",
    "options": [
      "When the hash function returns an error",
      "When two different keys hash to the same index",
      "When the table runs out of memory",
      "When two keys are identical"
    ],
    "answer": "When two different keys hash to the same index",
    "explanation": "A collision occurs when the hash function maps distinct inputs to the same bucket. Resolving collisions is usually handled via chaining or open addressing.",
    "difficulty": "Beginner"
  },
  {
    "id": 7,
    "question": "What is the time complexity of accessing an element in an array by its index?",
    "options": [
      "O(1)",
      "O(log n)",
      "O(n)",
      "O(n log n)"
    ],
    "answer": "O(1)",
    "explanation": "Arrays allow direct random access to elements via pointer arithmetic and offset calculation in constant time.",
    "difficulty": "Beginner"
  },
  {
    "id": 8,
    "question": "Which traversal method visits nodes in a Binary Tree in the order: Left Subtree, Root, Right Subtree?",
    "options": [
      "Pre-order",
      "Post-order",
      "In-order",
      "Level-order"
    ],
    "answer": "In-order",
    "explanation": "In-order traversal follows the sequence Left-Root-Right. Pre-order is Root-Left-Right, and Post-order is Left-Right-Root.",
    "difficulty": "Beginner"
  },
  {
    "id": 9,
    "question": "In dynamic programming, what is the primary technique used to avoid redundant calculations?",
    "options": [
      "Greedy selection",
      "Memoization or Tabulation",
      "Randomized pivoting",
      "Loop unrolling"
    ],
    "answer": "Memoization or Tabulation",
    "explanation": "Dynamic programming optimizes recursive solutions by storing results of subproblems (Memoization) or filling a table iteratively (Tabulation). Greedy selection does not guarantee overlap handling.",
    "difficulty": "Beginner"
  },
  {
    "id": 10,
    "question": "What is the space complexity of a recursive algorithm with a recursion depth of 'n'?",
    "options": [
      "O(1)",
      "O(n)",
      "O(log n)",
      "O(n²)"
    ],
    "answer": "O(n)",
    "explanation": "Recursion uses stack frames to store state; 'n' depth requires O(n) memory on the call stack.",
    "difficulty": "Beginner"
  },
  {
    "id": 11,
    "question": "Which sorting algorithm is considered an example of the 'Divide and Conquer' strategy?",
    "options": [
      "Bubble Sort",
      "Insertion Sort",
      "Selection Sort",
      "Merge Sort"
    ],
    "answer": "Merge Sort",
    "explanation": "Merge Sort recursively divides the array, sorts the halves, and merges them. Bubble, Insertion, and Selection sorts are iterative comparison sorts.",
    "difficulty": "Beginner"
  },
  {
    "id": 12,
    "question": "What distinguishes a Linked List from an Array regarding memory usage?",
    "options": [
      "Linked Lists require contiguous memory blocks",
      "Linked Lists have non-contiguous memory allocation via pointers",
      "Arrays allow dynamic resizing without cost",
      "Linked Lists have better cache locality"
    ],
    "answer": "Linked Lists have non-contiguous memory allocation via pointers",
    "explanation": "Linked List nodes are scattered in memory and linked by references, whereas Arrays require contiguous blocks. Arrays generally have better cache locality.",
    "difficulty": "Beginner"
  },
  {
    "id": 13,
    "question": "In a Min-Heap data structure, where is the minimum element located?",
    "options": [
      "At one of the leaf nodes",
      "At the root node",
      "In the leftmost child",
      "It varies depending on insertion order"
    ],
    "answer": "At the root node",
    "explanation": "The heap property ensures the root element is the minimum (in a Min-Heap) or maximum (in a Max-Heap).",
    "difficulty": "Beginner"
  },
  {
    "id": 14,
    "question": "What is the primary disadvantage of using a Hash Map compared to a Balanced Binary Search Tree?",
    "options": [
      "Slower average access time",
      "Lack of ordering of elements",
      "Higher space complexity",
      "Inability to handle collisions"
    ],
    "answer": "Lack of ordering of elements",
    "explanation": "Hash Maps do not maintain sorted order, whereas BSTs allow traversal in sorted order. Hash Maps typically offer faster O(1) access.",
    "difficulty": "Beginner"
  },
  {
    "id": 15,
    "question": "Which of the following best describes a 'Greedy Algorithm'?",
    "options": [
      "It explores all possible paths to find the optimal solution",
      "It makes the locally optimal choice at each stage hoping for a global optimum",
      "It uses memoization to optimize recursive calls",
      "It divides the problem into independent subproblems"
    ],
    "answer": "It makes the locally optimal choice at each stage hoping for a global optimum",
    "explanation": "Greedy algorithms are heuristic, making immediate local gains without backtracking or exhaustive search. They do not guarantee global optimality unless the problem has matroid structure.",
    "difficulty": "Beginner"
  },
  {
    "id": 16,
    "question": "What is the worst-case time complexity of Quicksort?",
    "options": [
      "O(n log n)",
      "O(n)",
      "O(n²)",
      "O(log n)"
    ],
    "answer": "O(n²)",
    "explanation": "Quicksort degrades to O(n²) if the pivot selection consistently results in unbalanced partitions (e.g., already sorted array with bad pivot). The average case is O(n log n).",
    "difficulty": "Beginner"
  },
  {
    "id": 17,
    "question": "Which graph traversal algorithm uses a Queue data structure?",
    "options": [
      "Depth-First Search (DFS)",
      "Breadth-First Search (BFS)",
      "Dijkstra's Algorithm",
      "A* Search"
    ],
    "answer": "Breadth-First Search (BFS)",
    "explanation": "BFS uses a Queue to process nodes level-by-level. DFS typically uses a Stack (or recursion) to go as deep as possible before backtracking.",
    "difficulty": "Beginner"
  },
  {
    "id": 18,
    "question": "What is 'Amortized Analysis' used for?",
    "options": [
      "Analyzing the worst-case runtime of a single operation",
      "Calculating the average time per operation over a sequence of operations",
      "Measuring the memory usage of the CPU",
      "Comparing two different algorithms"
    ],
    "answer": "Calculating the average time per operation over a sequence of operations",
    "explanation": "Amortized analysis smooths out the cost of rare, expensive operations (like array resizing) over many cheap operations to determine total cost.",
    "difficulty": "Beginner"
  },
  {
    "id": 19,
    "question": "In a Singly Linked List, how is the end of the list identified?",
    "options": [
      "The node points to the head",
      "The node's 'next' pointer is null",
      "The node's data is zero",
      "The node points to itself"
    ],
    "answer": "The node's 'next' pointer is null",
    "explanation": "By convention, the 'next' reference of the tail node points to null (or nil), indicating the termination of the list.",
    "difficulty": "Beginner"
  },
  {
    "id": 20,
    "question": "Which of the following is a characteristic of a 'Stable' sorting algorithm?",
    "options": [
      "It always runs in O(n log n) time",
      "It preserves the relative order of equal elements",
      "It uses no additional memory space",
      "It sorts data without using comparisons"
    ],
    "answer": "It preserves the relative order of equal elements",
    "explanation": "Stability ensures that if two elements compare as equal, they remain in their original relative order in the sorted output.",
    "difficulty": "Beginner"
  },
  {
    "id": 21,
    "question": "What is the base case in a recursive function?",
    "options": [
      "The step where the function calls itself",
      "The condition that stops the recursion to prevent infinite loops",
      "The initial call to the function",
      "The final returned value"
    ],
    "answer": "The condition that stops the recursion to prevent infinite loops",
    "explanation": "The base case is the termination condition that returns a value directly without further recursion, allowing the stack to unwind.",
    "difficulty": "Beginner"
  },
  {
    "id": 22,
    "question": "Which data structure is typically used to implement a recursive solution iteratively?",
    "options": [
      "Queue",
      "Hash Table",
      "Stack",
      "Set"
    ],
    "answer": "Stack",
    "explanation": "The call stack in recursion manages execution context; an explicit stack mimics this behavior in an iterative implementation.",
    "difficulty": "Beginner"
  },
  {
    "id": 23,
    "question": "What is the time complexity of inserting an element at the beginning of a Doubly Linked List?",
    "options": [
      "O(n)",
      "O(log n)",
      "O(1)",
      "O(n²)"
    ],
    "answer": "O(1)",
    "explanation": "Inserting at the head only requires updating the head pointer and the new node's pointers, which is a constant-time operation.",
    "difficulty": "Beginner"
  },
  {
    "id": 24,
    "question": "In algorithm design, what does 'Overlapping Subproblems' indicate?",
    "options": [
      "The problem is too large for memory",
      "The same sub-problems are solved multiple times (suggesting Dynamic Programming)",
      "The problem can be split into independent parts",
      "The algorithm requires divide and conquer"
    ],
    "answer": "The same sub-problems are solved multiple times (suggesting Dynamic Programming)",
    "explanation": "Overlapping subproblems are a hallmark of problems suitable for Dynamic Programming (like Fibonacci), distinguishing them from Divide and Conquer.",
    "difficulty": "Beginner"
  },
  {
    "id": 25,
    "question": "What is the primary function of Dijkstra's algorithm?",
    "options": [
      "To detect cycles in a graph",
      "To find the shortest path between nodes in a graph with non-negative weights",
      "To sort a graph's vertices",
      "To check if a graph is bipartite"
    ],
    "answer": "To find the shortest path between nodes in a graph with non-negative weights",
    "explanation": "Dijkstra's algorithm is a greedy search for the shortest path in graphs with positive edge weights. It fails (or behaves differently) with negative weights.",
    "difficulty": "Beginner"
  },
  {
    "id": 26,
    "question": "Which algorithm technique involves repeatedly choosing a random element as a pivot?",
    "options": [
      "Merge Sort",
      "Randomized Quicksort",
      "Binary Search",
      "Radix Sort"
    ],
    "answer": "Randomized Quicksort",
    "explanation": "Randomized Quicksort selects a pivot randomly to statistically avoid the worst-case O(n²) scenario that occurs with deterministic poor pivots.",
    "difficulty": "Beginner"
  },
  {
    "id": 27,
    "question": "What does a 'Topological Sort' of a Directed Acyclic Graph (DAG) produce?",
    "options": [
      "A list of nodes sorted by value",
      "A linear ordering of vertices where for every edge u->v, u comes before v",
      "A list of edges sorted by weight",
      "A tree structure representing the graph"
    ],
    "answer": "A linear ordering of vertices where for every edge u->v, u comes before v",
    "explanation": "Topological sorting arranges nodes such that dependencies (edges) point forward. It is only possible for DAGs.",
    "difficulty": "Beginner"
  },
  {
    "id": 28,
    "question": "Which data structure is most efficient for checking if a specific value exists in a set of items?",
    "options": [
      "Linked List",
      "Array",
      "Hash Set",
      "Stack"
    ],
    "answer": "Hash Set",
    "explanation": "A Hash Set provides average O(1) time complexity for lookups, whereas Linked Lists and Arrays require O(n) linear scans.",
    "difficulty": "Beginner"
  },
  {
    "id": 29,
    "question": "What is 'Backtracking' primarily used for in algorithm design?",
    "options": [
      "Finding the shortest path in a weighted graph",
      "Systematically searching for solutions by abandoning partial failures (Constraint Satisfaction)",
      "Sorting large datasets",
      "Reducing memory footprint"
    ],
    "answer": "Systematically searching for solutions by abandoning partial failures (Constraint Satisfaction)",
    "explanation": "Backtracking builds candidates incrementally and abandons a candidate ('backtracks') as soon as it determines it cannot lead to a valid solution.",
    "difficulty": "Beginner"
  },
  {
    "id": 30,
    "question": "In a 0-indexed array of length 'n', what is the valid range of indices?",
    "options": [
      "1 to n",
      "0 to n-1",
      "0 to n",
      "1 to n-1"
    ],
    "answer": "0 to n-1",
    "explanation": "0-indexing means the first element is at index 0 and the last element is at index length-1.",
    "difficulty": "Beginner"
  },
  {
    "id": 31,
    "question": "What is the relationship between a Tree and a Graph?",
    "options": [
      "A Tree is a Graph with cycles",
      "A Graph is a Tree with weighted edges",
      "A Tree is a connected, acyclic Graph",
      "They are unrelated data structures"
    ],
    "answer": "A Tree is a connected, acyclic Graph",
    "explanation": "All trees are graphs, but not all graphs are trees. Specifically, a tree is a connected graph with no cycles.",
    "difficulty": "Beginner"
  },
  {
    "id": 32,
    "question": "Which of the following is NOT a primitive data type in most high-level programming languages?",
    "options": [
      "Integer",
      "Boolean",
      "Array",
      "Character"
    ],
    "answer": "Array",
    "explanation": "Arrays are composite (collection) data types built from primitives, whereas Integer, Boolean, and Character are considered primitive types.",
    "difficulty": "Beginner"
  },
  {
    "id": 33,
    "question": "What is the result of applying the modulo operator (e.g., `x % 2`) to determine parity?",
    "options": [
      "It returns 1 for even numbers",
      "It returns 0 for odd numbers",
      "It returns 0 for even numbers",
      "It returns -1 for odd numbers"
    ],
    "answer": "It returns 0 for even numbers",
    "explanation": "If `x % 2 == 0`, the number is even (divisible by 2). If `x % 2 == 1` (or -1), the number is odd.",
    "difficulty": "Beginner"
  },
  {
    "id": 34,
    "question": "What is the 'Two Pointers' technique typically used for?",
    "options": [
      "Searching in a hash map",
      "Iterating through a sorted array or linked list from both ends to find pairs",
      "Balancing a tree",
      "Managing memory allocation"
    ],
    "answer": "Iterating through a sorted array or linked list from both ends to find pairs",
    "explanation": "Two Pointers use two references (often slow and fast, or left and right) to scan data in a single pass, often used for pair-sum problems.",
    "difficulty": "Beginner"
  },
  {
    "id": 35,
    "question": "Which complexity class is generally considered 'intractable' for inputs of moderate size (n > 30)?",
    "options": [
      "O(n²)",
      "O(2^n)",
      "O(n log n)",
      "O(n)"
    ],
    "answer": "O(2^n)",
    "explanation": "Exponential complexity (O(2^n)) grows explosively, making it unsolvable for moderate input sizes within reasonable time frames. Polynomial (O(n²)) is tractable.",
    "difficulty": "Beginner"
  },
  {
    "id": 36,
    "question": "Which specific condition on the cost function C(i, j) must be satisfied to apply Knuth's Optimization to a Dynamic Programming transition?",
    "options": [
      "The Quadrangle Inequality: C(a, c) + C(b, d) ≤ C(a, d) + C(b, c)",
      "The Monotonicity Condition: C(i, j) ≤ C(i, j+1)",
      "The Triangle Inequality: C(i, k) ≤ C(i, j) + C(j, k)",
      "The Convex Hull Property: C(i, j) is linear with respect to j"
    ],
    "answer": "The Quadrangle Inequality: C(a, c) + C(b, d) ≤ C(a, d) + C(b, c)",
    "explanation": "Knuth's Optimization requires the cost function to satisfy the Quadrangle Inequality (and monotonicity) to guarantee that the optimal splitting point satisfies the monotonicity condition $opt(i, j-1) \\le opt(i, j) \\le opt(i+1, j)$. Monotonicity alone is insufficient to prove the optimization holds.",
    "difficulty": "Intermediate"
  },
  {
    "id": 37,
    "question": "In the context of Divide and Conquer DP Optimization (not Knuth's), what is the strict requirement on the optimal splitting point $opt(i, j)$?",
    "options": [
      "$opt(i, j)$ must be equal to $\\lfloor (i+j) / 2 \\rfloor$ for all valid ranges",
      "$opt(i, j)$ must satisfy $opt(i, j) \\le opt(i, j+1)$ (monotonicity)",
      "$opt(i, j)$ must lie outside the interval $[i, j]$",
      "The cost function $C$ must be multiplicative"
    ],
    "answer": "$opt(i, j)$ must satisfy $opt(i, j) \\le opt(i, j+1)$ (monotonicity)",
    "explanation": "Divide and Conquer DP optimization relies on the monotonicity of the optimal splitting point argument, specifically that the optimal point for a range does not decrease as the range's end increases. Unlike Knuth's, it does not require the Quadrangle Inequality.",
    "difficulty": "Intermediate"
  },
  {
    "id": 38,
    "question": "What is the primary time complexity improvement when applying Knuth's Optimization to a Range DP problem typically calculated in $O(N^3)$?",
    "options": [
      "Reduces complexity to $O(N^2 \\log N)$",
      "Reduces complexity to $O(N^2)$",
      "Reduces complexity to $O(N \\log N)$",
      "Reduces complexity to $O(N)$"
    ],
    "answer": "Reduces complexity to $O(N^2)$",
    "explanation": "Standard Range DP is $O(N^3)$ because for every state $(i, j)$, we iterate $k$ from $i$ to $j$. Knuth's optimization limits the search space for $k$ using the monotonicity property $opt(i, j-1) \\le k \\le opt(i+1, j)$, reducing the total complexity to $O(N^2)$.",
    "difficulty": "Intermediate"
  },
  {
    "id": 39,
    "question": "When implementing a Segment Tree for range sum queries, what is the minimum safe array size required for a tree representing an input array of size $N$ if using 1-based indexing?",
    "options": [
      "$2N - 1$",
      "$2^{\\lceil \\log_2 N \\rceil + 1}$",
      "$4N$",
      "$N \\log_2 N$"
    ],
    "answer": "$4N$",
    "explanation": "While a full binary tree has $2N-1$ nodes, a 1-based indexed array implementation typically allocates $4N$ space to safely handle cases where $N$ is not a power of two without causing index overflow during recursion or child node calculation ($2x$ and $2x+1$).",
    "difficulty": "Intermediate"
  },
  {
    "id": 40,
    "question": "In a Segment Tree, what is the specific purpose of the 'Lazy Propagation' technique?",
    "options": [
      "To reduce the memory footprint of the tree by pruning unused leaves",
      "To defer updates to internal nodes until they are explicitly queried",
      "To balance the height of the tree during dynamic insertions",
      "To compress the tree path during range queries"
    ],
    "answer": "To defer updates to internal nodes until they are explicitly queried",
    "explanation": "Lazy propagation ensures range updates remain $O(\\log N)$ by marking nodes with a pending update (a 'lazy' value) and only propagating this update to children when necessary (i.e., when a query or further update accesses those children).",
    "difficulty": "Intermediate"
  },
  {
    "id": 41,
    "question": "What is the worst-case time complexity of a Disjoint Set Union (DSU) operation using Path Compression and Union by Rank?",
    "options": [
      "$O(\\log N)$",
      "$O(\\alpha(N))$",
      "$O(1)$",
      "$O(N)$"
    ],
    "answer": "$O(\\alpha(N))$",
    "explanation": "The combination of Path Compression and Union by Rank results in an amortized time complexity of $O(\\alpha(N))$, where $\\alpha$ is the Inverse Ackermann function, which grows so slowly it is effectively constant (less than 5 for any realistic $N$).",
    "difficulty": "Intermediate"
  },
  {
    "id": 42,
    "question": "In Dijkstra's algorithm, why is it strictly incorrect to use a standard Queue (FIFO) instead of a Priority Queue for the unvisited set?",
    "options": [
      "A standard Queue does not support removal of arbitrary elements",
      "It violates the greedy property required for shortest path extraction",
      "The algorithm's time complexity becomes $O(V^2)$",
      "A standard Queue does not allow duplicate node entries"
    ],
    "answer": "It violates the greedy property required for shortest path extraction",
    "explanation": "Dijkstra's algorithm relies on always extracting the vertex with the minimum tentative distance. A Priority Queue provides this in $O(\\log V)$. A standard FIFO Queue processes nodes in insertion order, not distance order, leading to incorrect results.",
    "difficulty": "Intermediate"
  },
  {
    "id": 43,
    "question": "Which property of the cost function allows the 'Divide and Conquer DP Optimization' to be valid?",
    "options": [
      "The quadrangle inequality",
      "The monotonicity of the argmin: $opt(i, j) \\le opt(i, j+1)$",
      "The linearity of the cost function",
      "The commutative property of the transition"
    ],
    "answer": "The monotonicity of the argmin: $opt(i, j) \\le opt(i, j+1)$",
    "explanation": "Divide and Conquer DP optimization specifically relies on the monotonicity of the optimal partition point. If $opt(i, j)$ is not monotonic with respect to $i$ or $j$, the search space cannot be recursively divided to achieve $O(N \\log N)$ or $O(N)$ reduction.",
    "difficulty": "Intermediate"
  },
  {
    "id": 44,
    "question": "What is the result of the bitwise operation $x \\p\\text{lowbit} x$ (where $\\p\\text{lowbit}$ extracts the lowest set bit) if $x = 12$ (binary 1100)?",
    "options": [
      "8 (1000)",
      "4 (0100)",
      "16 (10000)",
      "0"
    ],
    "answer": "4 (0100)",
    "explanation": "The lowest set bit in 12 (1100) is the bit representing $2^2 = 4$. The operation $x \\& -x$ isolates this specific bit, resulting in 4.",
    "difficulty": "Intermediate"
  },
  {
    "id": 45,
    "question": "In a Fenwick Tree (Binary Indexed Tree), which index is updated first when performing a point update at index $i$?",
    "options": [
      "Index $i - (i \\& -i)$",
      "Index $i + (i \\& -i)$",
      "Index $i / 2$",
      "Index $i + 1$"
    ],
    "answer": "Index $i + (i \\& -i)$",
    "explanation": "In a Fenwick tree, to update or add a value, one climbs up the tree by adding the lowest set bit (LSB) to the current index. The query operation (prefix sum) moves down by subtracting the LSB.",
    "difficulty": "Intermediate"
  },
  {
    "id": 46,
    "question": "When implementing the Floyd-Warshall algorithm for All-Pairs Shortest Paths, what is the critical order of the three nested loops?",
    "options": [
      "Source, Destination, Intermediate",
      "Intermediate, Source, Destination",
      "Destination, Source, Intermediate",
      "Intermediate, Destination, Source"
    ],
    "answer": "Intermediate, Source, Destination",
    "explanation": "The outermost loop must iterate through the 'intermediate' vertex $k$. The inner loops then iterate through source $u$ and destination $v$. If $u$ or $v$ were outer loops, the DP state transitions relying on $k$ as an intermediate step would not be correctly computed in a single pass.",
    "difficulty": "Intermediate"
  },
  {
    "id": 47,
    "question": "What is the space complexity of a Sparse Table data structure for answering Range Minimum Queries (RMQ) on an array of size $N$?",
    "options": [
      "$O(N)$",
      "$O(N \\log N)$",
      "$O(N^2)$",
      "$O(\\log N)$"
    ],
    "answer": "$O(N \\log N)$",
    "explanation": "A Sparse Table precomputes the minimum for all ranges of length $2^k$. Since there are $N$ starting positions and $\\log N$ possible lengths ($2^k \\le N$), the total storage space required is $O(N \\log N)$.",
    "difficulty": "Intermediate"
  },
  {
    "id": 48,
    "question": "Under what specific condition does the Bellman-Ford algorithm fail to produce the correct shortest paths?",
    "options": [
      "When the graph contains negative weight edges",
      "When the graph is not connected",
      "When the graph contains a negative weight cycle reachable from the source",
      "When the graph contains a zero weight cycle"
    ],
    "answer": "When the graph contains a negative weight cycle reachable from the source",
    "explanation": "Bellman-Ford can handle negative edges (unlike Dijkstra), but it fails if a negative cycle exists in the graph that is reachable from the source vertex, as the path length can decrease infinitely.",
    "difficulty": "Intermediate"
  },
  {
    "id": 49,
    "question": "In the context of bit manipulation, what does the expression `(n & (n - 1)) == 0` check for?",
    "options": [
      "If $n$ is a prime number",
      "If $n$ is a power of two",
      "If $n$ is an odd number",
      "If $n$ is a palindrome"
    ],
    "answer": "If $n$ is a power of two",
    "explanation": "Subtracting 1 from a power of two flips all the bits after the leading 1 (e.g., 1000 becomes 0111). Performing a bitwise AND between $n$ and $n-1$ results in 0 only if $n$ is a power of two.",
    "difficulty": "Intermediate"
  },
  {
    "id": 50,
    "question": "Which algorithm is most efficient for finding the Strongly Connected Components (SCC) in a directed graph?",
    "options": [
      "Dijkstra's Algorithm",
      "Prim's Algorithm",
      "Kosaraju's Algorithm",
      "Huffman Coding"
    ],
    "answer": "Kosaraju's Algorithm",
    "explanation": "Kosaraju's algorithm (or Tarjan's) is designed to find SCCs. It involves running DFS to determine order, reversing the graph, and processing nodes in decreasing order of finishing times. Dijkstra and Prim are for shortest paths and MSTs respectively.",
    "difficulty": "Intermediate"
  },
  {
    "id": 51,
    "question": "In a Trie (Prefix Tree), what is the worst-case time complexity for inserting a string of length $L$?",
    "options": [
      "$O(L \\log N)$",
      "$O(L)$",
      "$O(N)$",
      "$O(L^2)$"
    ],
    "answer": "$O(L)$",
    "explanation": "Insertion requires traversing/creating one node for each character in the string. The operations at each node (array access or hash map) are considered $O(1)$, leading to a total linear time complexity relative to the string length.",
    "difficulty": "Intermediate"
  },
  {
    "id": 52,
    "question": "What distinguishes the A* (A-Star) search algorithm from Dijkstra's algorithm?",
    "options": [
      "A* uses a heuristic function to guide the search",
      "A* can only work on unweighted graphs",
      "A* has a worse time complexity than Dijkstra",
      "A* does not use a priority queue"
    ],
    "answer": "A* uses a heuristic function to guide the search",
    "explanation": "A* extends Dijkstra's by adding a heuristic function $h(n)$ that estimates the cost to reach the goal. This allows A* to search towards the goal more efficiently, provided the heuristic is admissible (never overestimates).",
    "difficulty": "Intermediate"
  },
  {
    "id": 53,
    "question": "Which sorting algorithm is generally preferred for sorting a Linked List in-place with $O(1)$ extra space?",
    "options": [
      "QuickSort",
      "Merge Sort",
      "Heap Sort",
      "Insertion Sort"
    ],
    "answer": "Merge Sort",
    "explanation": "Merge Sort is preferred for linked lists because it does not require random access to elements (unlike QuickSort or Heap Sort) and can be implemented to merge sequential data without requiring extra space for an auxiliary array (unlike array-based Merge Sort).",
    "difficulty": "Intermediate"
  },
  {
    "id": 54,
    "question": "In the context of the Boyer-Moore string matching algorithm, what is the primary role of the 'Bad Character' rule?",
    "options": [
      "It shifts the pattern to align the bad character in the text with a matching character in the pattern",
      "It resets the search index to the beginning of the text",
      "It identifies palindromic substrings within the pattern",
      "It constructs the Longest Prefix Suffix array"
    ],
    "answer": "It shifts the pattern to align the bad character in the text with a matching character in the pattern",
    "explanation": "When a mismatch occurs, the Bad Character rule shifts the pattern such that the mismatched character in the text aligns with the rightmost occurrence of that same character in the pattern. This allows for 'skipping' sections of the text.",
    "difficulty": "Intermediate"
  },
  {
    "id": 55,
    "question": "What is the time complexity of the Sieve of Eratosthenes for finding all prime numbers up to $N$?",
    "options": [
      "$O(N \\log \\log N)$",
      "$O(N \\log N)$",
      "$O(N)$",
      "$O(N^2)$"
    ],
    "answer": "$O(N \\log \\log N)$",
    "explanation": "The sieve marks multiples of each prime. The complexity is derived from the harmonic series of primes: $N/2 + N/3 + N/5 + \\dots$, which sums to $O(N \\log \\log N)$. Linear sieves exist but are optimizations on the base concept.",
    "difficulty": "Intermediate"
  },
  {
    "id": 56,
    "question": "What is the 'Convex Hull Trick' (CHT) used to optimize in Dynamic Programming?",
    "options": [
      "Transition costs that form a linear function of the state index",
      "Transitions involving matrix exponentiation",
      "Transitions based on graph connectivity",
      "Bitmask DP transitions"
    ],
    "answer": "Transition costs that form a linear function of the state index",
    "explanation": "CHT is used when the DP recurrence has the form $dp[i] = \\min (m \\cdot x_j + c + dp[j])$, where $m$ and $c$ are constants. This represents a line ($y = mx + c$), and CHT allows querying the minimum $y$ at $x$ in $O(\\log N)$ or $O(1)$.",
    "difficulty": "Intermediate"
  },
  {
    "id": 57,
    "question": "In a Binary Heap, what is the index of the parent of the node at index $i$ (using 0-based indexing)?",
    "options": [
      "$(i - 1) / 2$",
      "$(i / 2) - 1$",
      "$i / 2$",
      "$2i$"
    ],
    "answer": "$(i - 1) / 2$",
    "explanation": "In a 0-based array representation of a binary heap, for an element at index $i$, the left child is at $2i + 1$ and the right child is at $2i + 2$. Conversely, the parent is at floor($(i-1)/2$).",
    "difficulty": "Intermediate"
  },
  {
    "id": 58,
    "question": "Which algorithm guarantees finding a Maximum Flow in a flow network?",
    "options": [
      "Dijkstra's Algorithm",
      "Ford-Fulkerson Method",
      "Kruskal's Algorithm",
      "Bellman-Ford Algorithm"
    ],
    "answer": "Ford-Fulkerson Method",
    "explanation": "The Ford-Fulkerson method (along with its efficient implementation, Edmonds-Karp or Dinic's algorithm) is the standard approach for solving the Max-Flow problem by finding augmenting paths in the residual graph.",
    "difficulty": "Intermediate"
  },
  {
    "id": 59,
    "question": "What is the distinguishing feature of a 'Treap' (Tree + Heap)?",
    "options": [
      "It maintains both Binary Search Tree property and Heap property simultaneously",
      "It is a self-balancing tree that uses randomization",
      "It stores data only in leaf nodes",
      "It guarantees $O(1)$ search time"
    ],
    "answer": "It is a self-balancing tree that uses randomization",
    "explanation": "A Treap assigns a random priority (Heap property) to each key while maintaining the BST property. The random priorities ensure the tree remains balanced with high probability, making operations expected $O(\\log N)$.",
    "difficulty": "Intermediate"
  },
  {
    "id": 60,
    "question": "In the context of computational geometry, what is the primary algorithm used to find the convex hull of a set of 2D points?",
    "options": [
      "Graham Scan",
      "Rabin-Karp",
      "Floyd-Warshall",
      "Kadane's Algorithm"
    ],
    "answer": "Graham Scan",
    "explanation": "Graham Scan is an $O(N \\log N)$ algorithm that sorts points by polar angle and then uses a stack to remove points that create concave angles (right turns), leaving only the convex hull.",
    "difficulty": "Intermediate"
  },
  {
    "id": 61,
    "question": "What does the 'amortized' time complexity analysis account for that 'average' case analysis does not?",
    "options": [
      "The worst-case sequence of operations over time",
      "The probability distribution of input data",
      "The best-case scenario performance",
      "The constant factors in the implementation"
    ],
    "answer": "The worst-case sequence of operations over time",
    "explanation": "Amortized analysis guarantees the average performance of *each* operation in the *worst-case* sequence of operations. Unlike average-case analysis, it does not rely on probabilistic assumptions about the input.",
    "difficulty": "Intermediate"
  },
  {
    "id": 62,
    "question": "Which data structure is essential for implementing the 'Two Pointers' technique on a sorted array?",
    "options": [
      "Hash Map",
      "Linked List",
      "Array (Random Access)",
      "Priority Queue"
    ],
    "answer": "Array (Random Access)",
    "explanation": "The Two Pointers technique typically involves moving indices based on values. While a Linked List *can* work, it requires $O(N)$ access. The technique is most efficient ($O(N)$ total) when used on arrays supporting $O(1)$ random access.",
    "difficulty": "Intermediate"
  },
  {
    "id": 63,
    "question": "In the KMP (Knuth-Morris-Pratt) algorithm, what is stored in the 'LPS' (Longest Prefix Suffix) array?",
    "options": [
      "The length of the longest proper prefix which is also a suffix for every prefix of the pattern",
      "The index of the next character to match in the text",
      "The frequency of each character in the pattern",
      "The total number of matches found so far"
    ],
    "answer": "The length of the longest proper prefix which is also a suffix for every prefix of the pattern",
    "explanation": "The LPS array (also called the 'prefix function') stores the length of the longest proper prefix of the sub-pattern $pattern[0...i]$ that is also a suffix of this sub-pattern. This allows the algorithm to skip redundant comparisons.",
    "difficulty": "Intermediate"
  },
  {
    "id": 64,
    "question": "What is the primary advantage of using a 'Sparse Table' over a 'Segment Tree' for static Range Minimum Queries?",
    "options": [
      "Sparse Table supports point updates efficiently",
      "Sparse Table has faster query time ($O(1)$ vs $O(\\log N)$)",
      "Sparse Table uses less memory",
      "Sparse Table handles dynamic data changes"
    ],
    "answer": "Sparse Table has faster query time ($O(1)$ vs $O(\\log N)$)",
    "explanation": "A Sparse Table precomputes answers for all power-of-two length intervals, allowing any range query to be answered by combining two precomputed overlapping intervals in $O(1)$. Segment Trees answer in $O(\\log N)$. Sparse Tables cannot handle point updates efficiently.",
    "difficulty": "Intermediate"
  },
  {
    "id": 65,
    "question": "What is the time complexity of the Fast Fourier Transform (FFT)?",
    "options": [
      "$O(N^2)$",
      "$O(N \\log N)$",
      "$O(N)$",
      "$O(\\log N)$"
    ],
    "answer": "$O(N \\log N)$",
    "explanation": "FFT computes the Discrete Fourier Transform by dividing the polynomial into even and odd terms (Cooley-Tukey algorithm), recursively solving them, and combining the results. This divide-and-conquer approach reduces the naive $O(N^2)$ to $O(N \\log N)$.",
    "difficulty": "Intermediate"
  },
  {
    "id": 66,
    "question": "Which of the following algorithms uses a 'Bloom Filter' for probabilistic membership checking?",
    "options": [
      "Binary Search",
      "Spell Checker / Database caching",
      "Depth First Search",
      "Sorting"
    ],
    "answer": "Spell Checker / Database caching",
    "explanation": "A Bloom Filter is a space-efficient probabilistic data structure used to test whether an element is a member of a set. It is often used to avoid expensive disk lookups (e.g., checking if a word exists in a dictionary or a key in a database) at the cost of a small false positive rate.",
    "difficulty": "Intermediate"
  },
  {
    "id": 67,
    "question": "In the context of Graph Theory, what is the result of running a Topological Sort on a graph that contains a cycle?",
    "options": [
      "The algorithm will output the vertices in shortest path order",
      "The algorithm will enter an infinite loop",
      "The algorithm is undefined/impossible; Topological Sort only works on DAGs",
      "The algorithm will automatically ignore the edges forming the cycle"
    ],
    "answer": "The algorithm is undefined/impossible; Topological Sort only works on DAGs",
    "explanation": "Topological Sort produces a linear ordering of vertices such that for every directed edge $u \to v$, $u$ comes before $v$. This is impossible if a cycle exists, as no vertex in the cycle can come before another.",
    "difficulty": "Intermediate"
  },
  {
    "id": 68,
    "question": "When implementing a 'Persistent' data structure (e.g., Persistent Segment Tree), what is the main trade-off?",
    "options": [
      "Query time increases to $O(N)$",
      "Update time increases significantly due to copying the entire structure",
      "Space complexity increases to maintain versions, while query time remains logarithmic",
      "It can only store integers"
    ],
    "answer": "Space complexity increases to maintain versions, while query time remains logarithmic",
    "explanation": "Persistence involves creating new nodes for the path changed during an update, reusing old nodes for the rest of the tree. This allows querying historical versions, but increases memory usage ($O(M \\log N)$ for $M$ updates) compared to the non-persistent version.",
    "difficulty": "Intermediate"
  },
  {
    "id": 69,
    "question": "What is the 'Master Theorem' used for?",
    "options": [
      "Solving recurrence relations of the form $T(n) = aT(n/b) + f(n)$",
      "Finding the greatest common divisor of two numbers",
      "Determining if a number is prime",
      "Sorting arrays in linear time"
    ],
    "answer": "Solving recurrence relations of the form $T(n) = aT(n/b) + f(n)$",
    "explanation": "The Master Theorem provides a cookbook solution for asymptotic analysis (Big O) of divide-and-conquer recurrences where a problem of size $n$ is split into $a$ subproblems of size $n/b$ with a combine cost of $f(n)$.",
    "difficulty": "Intermediate"
  },
  {
    "id": 70,
    "question": "In Bitmask DP, what is the maximum reasonable size of $N$ (the number of elements) for a standard algorithm to run within time limits?",
    "options": [
      "$N \\le 10$",
      "$N \\le 20$",
      "$N \\le 50$",
      "$N \\le 100$"
    ],
    "answer": "$N \\le 20$",
    "explanation": "Bitmask DP typically has a complexity of $O(2^N \\cdot \\text{poly}(N))$. $2^{20}$ is roughly $10^6$, which fits within standard 1-second time limits. $2^{25}$ is roughly $33 \times 10^6$, which is often too slow without heavy optimization. $N=20$ is the standard 'safe' upper bound.",
    "difficulty": "Intermediate"
  }
]