[
  {
    "id": 1,
    "question": "Which data structure operates on the Last-In, First-Out (LIFO) principle?",
    "options": [
      "Queue",
      "Stack",
      "Linked List",
      "Array"
    ],
    "answer": "Stack",
    "explanation": "A Stack allows insertion and removal of elements only from one end (the top), resulting in LIFO behavior. Queues are FIFO, while Lists and Arrays allow random access.",
    "difficulty": "Beginner"
  },
  {
    "id": 2,
    "question": "What is the primary requirement for performing a Binary Search on an array?",
    "options": [
      "The array must be of integer type",
      "The array must be sorted",
      "The array size must be a power of two",
      "The array must contain unique elements"
    ],
    "answer": "The array must be sorted",
    "explanation": "Binary search relies on the order of elements to repeatedly divide the search interval in half. It fails or produces undefined results on unsorted data.",
    "difficulty": "Beginner"
  },
  {
    "id": 3,
    "question": "What is the worst-case time complexity of Bubble Sort?",
    "options": [
      "O(n)",
      "O(n log n)",
      "O(n^2)",
      "O(1)"
    ],
    "answer": "O(n^2)",
    "explanation": "Bubble Sort uses nested loops where each element may be compared with every other element. In the worst case (reverse sorted), this results in quadratic complexity.",
    "difficulty": "Beginner"
  },
  {
    "id": 4,
    "question": "Which traversal method visits the root node first, then the left subtree, and finally the right subtree?",
    "options": [
      "In-order Traversal",
      "Post-order Traversal",
      "Pre-order Traversal",
      "Level-order Traversal"
    ],
    "answer": "Pre-order Traversal",
    "explanation": "Pre-order traversal follows the specific sequence: Root -> Left -> Right. In-order is Left-Root-Right, and Post-order is Left-Right-Root.",
    "difficulty": "Beginner"
  },
  {
    "id": 5,
    "question": "In Big O notation, what does O(1) represent?",
    "options": [
      "Linear time complexity",
      "Logarithmic time complexity",
      "Constant time complexity",
      "Exponential time complexity"
    ],
    "answer": "Constant time complexity",
    "explanation": "O(1) indicates that the algorithm's execution time remains constant regardless of the input size. Accessing an array element by index is a classic example.",
    "difficulty": "Beginner"
  },
  {
    "id": 6,
    "question": "Which algorithm is typically implemented using a Queue data structure?",
    "options": [
      "Depth-First Search (DFS)",
      "Breadth-First Search (BFS)",
      "Binary Search",
      "Merge Sort"
    ],
    "answer": "Breadth-First Search (BFS)",
    "explanation": "BFS explores neighbors level by level, requiring a First-In-First-Out (FIFO) structure to manage the order of node visits. DFS uses a Stack or recursion.",
    "difficulty": "Beginner"
  },
  {
    "id": 7,
    "question": "What is the main disadvantage of using an Adjacency Matrix to represent a graph?",
    "options": [
      "It consumes more memory for sparse graphs",
      "It cannot represent weighted edges",
      "It is difficult to implement",
      "Edge lookup is slower than in lists"
    ],
    "answer": "It consumes more memory for sparse graphs",
    "explanation": "An adjacency matrix stores V x V entries regardless of the number of edges. If a graph has few edges (sparse), this wastes significant memory compared to an adjacency list.",
    "difficulty": "Beginner"
  },
  {
    "id": 8,
    "question": "Which sorting algorithm has the best asymptotic time complexity in the average case?",
    "options": [
      "Bubble Sort",
      "Insertion Sort",
      "Merge Sort",
      "Selection Sort"
    ],
    "answer": "Merge Sort",
    "explanation": "Merge Sort guarantees O(n log n) time complexity in the worst, average, and best cases. Bubble, Insertion, and Selection sorts generally have O(n^2) average cases.",
    "difficulty": "Beginner"
  },
  {
    "id": 9,
    "question": "What is the purpose of a 'base case' in a recursive function?",
    "options": [
      "To improve the algorithm's speed",
      "To stop the recursion and prevent infinite loops",
      "To increase memory usage",
      "To optimize the compiler output"
    ],
    "answer": "To stop the recursion and prevent infinite loops",
    "explanation": "Without a base case, a recursive function would call itself indefinitely, leading to a stack overflow error. It defines the termination condition.",
    "difficulty": "Beginner"
  },
  {
    "id": 10,
    "question": "In a Min-Heap data structure, where is the smallest element located?",
    "options": [
      "At the last leaf node",
      "At the root node",
      "In the left subtree",
      "It is not determinable without a search"
    ],
    "answer": "At the root node",
    "explanation": "A Min-Heap is a binary tree where the parent is always smaller than its children. Consequently, the smallest element is always at the top (root).",
    "difficulty": "Beginner"
  },
  {
    "id": 11,
    "question": "Which technique allows a function to call itself to solve a smaller instance of the problem?",
    "options": [
      "Iteration",
      "Recursion",
      "Abstraction",
      "Polymorphism"
    ],
    "answer": "Recursion",
    "explanation": "Recursion is a programming technique where a function calls itself directly or indirectly. It breaks down a problem into smaller, self-similar sub-problems.",
    "difficulty": "Beginner"
  },
  {
    "id": 12,
    "question": "What is the time complexity of searching for an element in a balanced Binary Search Tree (BST)?",
    "options": [
      "O(n)",
      "O(log n)",
      "O(n log n)",
      "O(1)"
    ],
    "answer": "O(log n)",
    "explanation": "In a balanced BST, each comparison discards half of the remaining tree, similar to binary search. This results in logarithmic height relative to the number of nodes.",
    "difficulty": "Beginner"
  },
  {
    "id": 13,
    "question": "Which algorithm design technique builds up a solution by choosing the 'best' option at the current step?",
    "options": [
      "Dynamic Programming",
      "Greedy Algorithm",
      "Divide and Conquer",
      "Backtracking"
    ],
    "answer": "Greedy Algorithm",
    "explanation": "A Greedy Algorithm makes the locally optimal choice at each stage with the hope of finding a global optimum. It does not reconsider previous choices.",
    "difficulty": "Beginner"
  },
  {
    "id": 14,
    "question": "What is the output of In-order traversal for a Binary Search Tree (BST)?",
    "options": [
      "Random order",
      "Level-wise sorted",
      "Sorted in ascending order",
      "Sorted in descending order"
    ],
    "answer": "Sorted in ascending order",
    "explanation": "By definition, a BST has left nodes < root < right nodes. In-order traversal (Left, Root, Right) naturally visits nodes in ascending sorted order.",
    "difficulty": "Beginner"
  },
  {
    "id": 15,
    "question": "Which data structure is best suited for implementing a LRU (Least Recently Used) Cache?",
    "options": [
      "Array",
      "Singly Linked List",
      "Doubly Linked List with Hash Map",
      "Stack"
    ],
    "answer": "Doubly Linked List with Hash Map",
    "explanation": "A Hash Map provides O(1) access, while a Doubly Linked List allows O(1) removal and insertion of nodes to track usage order. This combination is standard for LRU caches.",
    "difficulty": "Beginner"
  },
  {
    "id": 16,
    "question": "In the context of algorithm analysis, what does 'Space Complexity' measure?",
    "options": [
      "The number of lines of code written",
      "The amount of memory an algorithm needs to run",
      "The total time taken to execute the code",
      "The number of inputs the algorithm can handle"
    ],
    "answer": "The amount of memory an algorithm needs to run",
    "explanation": "Space complexity quantifies the total memory space required by an algorithm as a function of the input size, including both auxiliary space and input space.",
    "difficulty": "Beginner"
  },
  {
    "id": 17,
    "question": "What distinguishes a Linked List from an Array regarding memory allocation?",
    "options": [
      "Linked Lists require contiguous memory blocks",
      "Arrays are non-contiguous and dynamic",
      "Linked Lists use non-contiguous memory allocation",
      "Arrays cannot grow in size"
    ],
    "answer": "Linked Lists use non-contiguous memory allocation",
    "explanation": "Linked List nodes are stored at arbitrary memory locations linked by pointers. Arrays typically require a single, contiguous block of memory.",
    "difficulty": "Beginner"
  },
  {
    "id": 18,
    "question": "Which sorting algorithm divides the array into two halves, recursively sorts them, and then merges the sorted halves?",
    "options": [
      "Quick Sort",
      "Merge Sort",
      "Heap Sort",
      "Radix Sort"
    ],
    "answer": "Merge Sort",
    "explanation": "Merge Sort follows the Divide and Conquer strategy by splitting the array, sorting recursively, and merging the results. Quick Sort partitions rather than strictly merging.",
    "difficulty": "Beginner"
  },
  {
    "id": 19,
    "question": "What condition must a graph meet for Topological Sort to be possible?",
    "options": [
      "It must be a complete graph",
      "It must be a Directed Acyclic Graph (DAG)",
      "It must be undirected",
      "It must contain at least one cycle"
    ],
    "answer": "It must be a Directed Acyclic Graph (DAG)",
    "explanation": "Topological ordering implies a linear ordering of vertices such that for every directed edge u->v, u comes before v. This is impossible if a directed cycle exists.",
    "difficulty": "Beginner"
  },
  {
    "id": 20,
    "question": "What is the primary characteristic of a 'Greedy' algorithm compared to 'Dynamic Programming'?",
    "options": [
      "Greedy algorithms are always slower",
      "Greedy algorithms do not reconsider solutions to subproblems",
      "Greedy algorithms use memoization",
      "Greedy algorithms always find the global optimum"
    ],
    "answer": "Greedy algorithms do not reconsider solutions to subproblems",
    "explanation": "Greedy algorithms make a single, irrevocable choice at each step. Dynamic Programming breaks problems down and reuses solutions to overlapping subproblems to ensure optimality.",
    "difficulty": "Beginner"
  },
  {
    "id": 21,
    "question": "Which searching algorithm requires the list to be sorted and divides the search interval by the target value?",
    "options": [
      "Linear Search",
      "Binary Search",
      "Jump Search",
      "Exponential Search"
    ],
    "answer": "Binary Search",
    "explanation": "Binary Search compares the target value to the middle element of the sorted array and recursively searches the left or right subarray based on the comparison.",
    "difficulty": "Beginner"
  },
  {
    "id": 22,
    "question": "What is the time complexity of accessing an element in an array using its index?",
    "options": [
      "O(n)",
      "O(log n)",
      "O(1)",
      "O(n^2)"
    ],
    "answer": "O(1)",
    "explanation": "Arrays offer random access, meaning the memory address can be calculated directly using the base address and index offset. This takes constant time.",
    "difficulty": "Beginner"
  },
  {
    "id": 23,
    "question": "In a Hash Table, what is the term for two different keys hashing to the same index?",
    "options": [
      "Collision",
      "Rehashing",
      "Load Factor",
      "Indexing"
    ],
    "answer": "Collision",
    "explanation": "A collision occurs when a hash function generates the same index for multiple keys. Collision resolution strategies (like chaining) are required to handle this.",
    "difficulty": "Beginner"
  },
  {
    "id": 24,
    "question": "Which algorithm uses a 'pivot' element to partition the array for sorting?",
    "options": [
      "Merge Sort",
      "Bubble Sort",
      "Quick Sort",
      "Selection Sort"
    ],
    "answer": "Quick Sort",
    "explanation": "Quick Sort selects a 'pivot' element and partitions the array so that elements smaller than the pivot are on the left and larger elements are on the right.",
    "difficulty": "Beginner"
  },
  {
    "id": 25,
    "question": "What is the primary function of Dijkstra's algorithm?",
    "options": [
      "To find the Minimum Spanning Tree",
      "To find the shortest path between nodes in a graph",
      "To detect cycles in a graph",
      "To sort a graph's vertices"
    ],
    "answer": "To find the shortest path between nodes in a graph",
    "explanation": "Dijkstra's algorithm is a graph search algorithm that solves the single-source shortest path problem for a graph with non-negative edge weights.",
    "difficulty": "Beginner"
  },
  {
    "id": 26,
    "question": "Which of the following is NOT a characteristic of a good algorithm?",
    "options": [
      "Finiteness",
      "Ambiguity",
      "Effectiveness",
      "Input"
    ],
    "answer": "Ambiguity",
    "explanation": "An algorithm must be unambiguous; each step must be clear and have a single interpretation. Ambiguity makes an algorithm impossible to execute reliably.",
    "difficulty": "Beginner"
  },
  {
    "id": 27,
    "question": "What is a 'collision' in the context of Hash Maps?",
    "options": [
      "When two keys have the same value",
      "When two keys hash to the same bucket index",
      "When the hash map runs out of memory",
      "When a key is deleted"
    ],
    "answer": "When two keys hash to the same bucket index",
    "explanation": "Collisions happen when a hash function maps two distinct keys to the same location in the hash table. This must be managed via chaining or open addressing.",
    "difficulty": "Beginner"
  },
  {
    "id": 28,
    "question": "Which Big O notation represents an algorithm that grows exponentially?",
    "options": [
      "O(n)",
      "O(n^2)",
      "O(2^n)",
      "O(log n)"
    ],
    "answer": "O(2^n)",
    "explanation": "Exponential complexity (O(2^n)) means the time doubles with every addition to the input. It is typical for recursive solutions like calculating Fibonacci numbers without memoization.",
    "difficulty": "Beginner"
  },
  {
    "id": 29,
    "question": "What is the primary difference between a Stack and a Queue?",
    "options": [
      "Stacks allow random access, Queues do not",
      "Stacks are LIFO, Queues are FIFO",
      "Stacks use arrays, Queues use linked lists",
      "Stacks are faster than Queues"
    ],
    "answer": "Stacks are LIFO, Queues are FIFO",
    "explanation": "Stacks follow Last-In-First-Out (the last element added is the first removed), while Queues follow First-In-First-Out (the first element added is the first removed).",
    "difficulty": "Beginner"
  },
  {
    "id": 30,
    "question": "In graph theory, what is a 'Cycle'?",
    "options": [
      "A path that starts and ends at different vertices",
      "A path that starts and ends at the same vertex with no repeated edges",
      "A disconnected graph",
      "A vertex with no edges"
    ],
    "answer": "A path that starts and ends at the same vertex with no repeated edges",
    "explanation": "A cycle is a closed walk where the start and end vertices are identical, and no other vertices or edges are repeated (except the start/end vertex).",
    "difficulty": "Beginner"
  },
  {
    "id": 31,
    "question": "Which data structure is most efficient for checking if parentheses in an expression are balanced?",
    "options": [
      "Queue",
      "Priority Queue",
      "Stack",
      "Array"
    ],
    "answer": "Stack",
    "explanation": "A Stack allows you to push opening brackets and pop them when encountering closing brackets. If the stack is empty at the end, the brackets are balanced.",
    "difficulty": "Beginner"
  },
  {
    "id": 32,
    "question": "What is the 'Load Factor' in a Hash Table?",
    "options": [
      "The number of elements divided by the number of buckets",
      "The time taken to hash a key",
      "The number of collisions",
      "The memory used by the table"
    ],
    "answer": "The number of elements divided by the number of buckets",
    "explanation": "The load factor (n/k) measures how full the hash table is. It helps determine when to resize the table to maintain performance.",
    "difficulty": "Beginner"
  },
  {
    "id": 33,
    "question": "What does the term 'stable' mean regarding sorting algorithms?",
    "options": [
      "The algorithm always finishes in the same amount of time",
      "The algorithm maintains the relative order of equal elements",
      "The algorithm uses O(1) space",
      "The algorithm is recursive"
    ],
    "answer": "The algorithm maintains the relative order of equal elements",
    "explanation": "A stable sort preserves the relative order of records with equal keys. For example, if two people have the same name, the one who appeared first in the input stays first.",
    "difficulty": "Beginner"
  },
  {
    "id": 34,
    "question": "Which traversal technique explores a graph branch as deep as possible before backtracking?",
    "options": [
      "Breadth-First Search",
      "Depth-First Search",
      "Dijkstra's Algorithm",
      "A* Search"
    ],
    "answer": "Depth-First Search",
    "explanation": "DFS explores a path to its deepest point before backtracking. This behavior maps directly to a stack-based or recursive implementation.",
    "difficulty": "Beginner"
  },
  {
    "id": 35,
    "question": "In a Binary Search Tree (BST), where is a node with a value greater than the root's value always located?",
    "options": [
      "In the left subtree",
      "In the right subtree",
      "Directly above the root",
      "It can be anywhere"
    ],
    "answer": "In the right subtree",
    "explanation": "A BST property dictates that all nodes in the right subtree have keys greater than the root's key, and all nodes in the left subtree have keys smaller.",
    "difficulty": "Beginner"
  },
  {
    "id": 36,
    "question": "Under which specific condition does Dijkstra's algorithm fail to guarantee the correct shortest path?",
    "options": [
      "Graphs containing disconnected components",
      "Graphs with non-negative edge weights",
      "Graphs containing edges with negative weights",
      "Graphs containing cycles"
    ],
    "answer": "Graphs containing edges with negative weights",
    "explanation": "Dijkstra's greedy approach assumes that adding an edge to a path never shortens it, which is false if negative weights exist. Algorithms like Bellman-Ford handle negative weights correctly.",
    "difficulty": "Intermediate"
  },
  {
    "id": 37,
    "question": "In the context of Union-Find (Disjoint Set Union), what is the primary purpose of the 'Path Compression' optimization?",
    "options": [
      "To ensure the tree representing the set is always balanced",
      "To flatten the structure of the tree during find operations",
      "To reduce the time complexity of the union operation",
      "To prevent the formation of cycles within the set"
    ],
    "answer": "To flatten the structure of the tree during find operations",
    "explanation": "Path compression updates the parent pointer of every node traversed during a 'find' to point directly to the root. This significantly speeds up subsequent queries.",
    "difficulty": "Intermediate"
  },
  {
    "id": 38,
    "question": "Why is Kruskal's algorithm preferred over Prim's algorithm for sparse graphs?",
    "options": [
      "Kruskal's algorithm uses a priority queue for faster access",
      "Kruskal's algorithm operates on edges rather than vertices",
      "Prim's algorithm requires sorting all edges, which is slower",
      "Kruskal's algorithm does not require a disjoint set data structure"
    ],
    "answer": "Kruskal's algorithm operates on edges rather than vertices",
    "explanation": "Kruskal's complexity depends on the number of edges (E log E). In sparse graphs where E is close to V, this is more efficient than Prim's implementation using a priority queue, which depends on V.",
    "difficulty": "Intermediate"
  },
  {
    "id": 39,
    "question": "What is the time complexity of finding the Longest Common Subsequence (LCS) of two strings of lengths M and N using standard Dynamic Programming?",
    "options": [
      "O((M + N) log M)",
      "O(M * N)",
      "O(M + N)",
      "O(2^(M+N))"
    ],
    "answer": "O(M * N)",
    "explanation": "The standard DP solution builds a table of size (M+1) x (N+1). Each cell is filled in constant time based on the previous results.",
    "difficulty": "Intermediate"
  },
  {
    "id": 40,
    "question": "Which graph traversal algorithm uses a Queue data structure and is guaranteed to find the shortest path in an unweighted graph?",
    "options": [
      "Depth First Search (DFS)",
      "Breadth First Search (BFS)",
      "Dijkstra's Algorithm",
      "A* Search"
    ],
    "answer": "Breadth First Search (BFS)",
    "explanation": "BFS explores neighbors layer by layer. In an unweighted graph, the first time a node is reached via BFS, it is via the shortest path.",
    "difficulty": "Intermediate"
  },
  {
    "id": 41,
    "question": "What prerequisite must a graph meet for Topological Sorting to be possible?",
    "options": [
      "The graph must be a Directed Acyclic Graph (DAG)",
      "The graph must be fully connected",
      "The graph must contain only positive edge weights",
      "The graph must be undirected"
    ],
    "answer": "The graph must be a Directed Acyclic Graph (DAG)",
    "explanation": "A topological sort is a linear ordering of vertices such that for every directed edge u -> v, u comes before v. This is impossible if the graph contains a cycle.",
    "difficulty": "Intermediate"
  },
  {
    "id": 42,
    "question": "In a Segment Tree, what is the time complexity to update the value of a single element at a specific index?",
    "options": [
      "O(1)",
      "O(N)",
      "O(log N)",
      "O(N log N)"
    ],
    "answer": "O(log N)",
    "explanation": "A segment tree is a binary tree structure. Updating a leaf and propagating the change up to the root requires traversing the height of the tree, which is log N.",
    "difficulty": "Intermediate"
  },
  {
    "id": 43,
    "question": "Which algorithm technique is most suitable for finding the maximum flow in a flow network?",
    "options": [
      "Dijkstra's Algorithm",
      "Ford-Fulkerson Method",
      "Floyd-Warshall Algorithm",
      "Prim's Algorithm"
    ],
    "answer": "Ford-Fulkerson Method",
    "explanation": "The Ford-Fulkerson method (often implemented with Edmonds-Karp for BFS search) iteratively finds augmenting paths in the residual graph to maximize flow.",
    "difficulty": "Intermediate"
  },
  {
    "id": 44,
    "question": "What is the worst-case time complexity of the QuickSort algorithm?",
    "options": [
      "O(N)",
      "O(N log N)",
      "O(N^2)",
      "O(log N)"
    ],
    "answer": "O(N^2)",
    "explanation": "If the pivot selection consistently results in the most unbalanced partition (e.g., picking the smallest element in a sorted array), the depth of recursion becomes N, resulting in O(N^2).",
    "difficulty": "Intermediate"
  },
  {
    "id": 45,
    "question": "Which data structure is typically used to implement a Priority Queue efficiently?",
    "options": [
      "Hash Table",
      "Binary Heap",
      "Doubly Linked List",
      "Trie"
    ],
    "answer": "Binary Heap",
    "explanation": "Binary Heaps allow for O(1) access to the max/min element and O(log N) insertion and deletion, making them ideal for Priority Queues.",
    "difficulty": "Intermediate"
  },
  {
    "id": 46,
    "question": "In the context of the 0-1 Knapsack problem, why is a Greedy approach (always taking the item with the highest value-to-weight ratio) not optimal?",
    "options": [
      "It cannot handle fractional weights",
      "It does not guarantee global optimality due to discrete item selection",
      "It sorts items in ascending order of weight",
      "It has a worse time complexity than dynamic programming"
    ],
    "answer": "It does not guarantee global optimality due to discrete item selection",
    "explanation": "Unlike the Fractional Knapsack problem, you cannot take a fraction of an item. A high ratio item might consume capacity needed for two smaller items that sum to a greater total value.",
    "difficulty": "Intermediate"
  },
  {
    "id": 47,
    "question": "What distinguishes a Red-Black Tree from a standard Binary Search Tree (BST)?",
    "options": [
      "Red-Black Trees allow duplicate keys",
      "Red-Black Trees are self-balancing to guarantee O(log N) operations",
      "Red-Black Trees store keys only in the leaf nodes",
      "Red-Black Trees do not require rotations"
    ],
    "answer": "Red-Black Trees are self-balancing to guarantee O(log N) operations",
    "explanation": "Standard BSTs can degenerate into a linked list with O(N) operations. Red-Black trees enforce balancing properties during insertions and deletions.",
    "difficulty": "Intermediate"
  },
  {
    "id": 48,
    "question": "Which sorting algorithm is considered stable, meaning it preserves the relative order of equal elements?",
    "options": [
      "QuickSort",
      "HeapSort",
      "MergeSort",
      "Selection Sort"
    ],
    "answer": "MergeSort",
    "explanation": "MergeSort only merges elements when the left element is strictly less than the right. If they are equal, the left element is taken first, preserving the original order.",
    "difficulty": "Intermediate"
  },
  {
    "id": 49,
    "question": "What is the primary advantage of a Fenwick Tree (Binary Indexed Tree) over a Segment Tree?",
    "options": [
      "It supports range updates more efficiently",
      "It requires less memory and has a smaller constant factor",
      "It can handle floating-point numbers",
      "It is strictly easier to implement"
    ],
    "answer": "It requires less memory and has a smaller constant factor",
    "explanation": "Fenwick Trees use a compact array representation typically half the size of a Segment Tree array and utilize bitwise operations for faster query speeds.",
    "difficulty": "Intermediate"
  },
  {
    "id": 50,
    "question": "In the Traveling Salesman Problem (TSP), what is the approximate time complexity of the dynamic programming solution (Held-Karp) for N cities?",
    "options": [
      "O(N^2)",
      "O(N^2 * 2^N)",
      "O(N!)",
      "O(N log N)"
    ],
    "answer": "O(N^2 * 2^N)",
    "explanation": "The DP solution uses a state defined by the current city and a set of visited cities (subset). There are 2^N subsets and N cities, leading to O(N^2 * 2^N).",
    "difficulty": "Intermediate"
  },
  {
    "id": 51,
    "question": "Which algorithm is specifically designed to find the shortest path from every vertex to every other vertex in a graph?",
    "options": [
      "Dijkstra's Algorithm",
      "Bellman-Ford Algorithm",
      "Floyd-Warshall Algorithm",
      "Prim's Algorithm"
    ],
    "answer": "Floyd-Warshall Algorithm",
    "explanation": "Floyd-Warshall uses dynamic programming to check all possible intermediate vertices between every pair (i, j). Dijkstra and Bellman-Ford are single-source algorithms.",
    "difficulty": "Intermediate"
  },
  {
    "id": 52,
    "question": "What is the space complexity of an adjacency list representation of a graph with V vertices and E edges?",
    "options": [
      "O(V)",
      "O(E)",
      "O(V + E)",
      "O(V * E)"
    ],
    "answer": "O(V + E)",
    "explanation": "You need an array of size V to store the headers, and total nodes across all linked lists equals E. Thus, space is proportional to V + E.",
    "difficulty": "Intermediate"
  },
  {
    "id": 53,
    "question": "The failure function (or LPS array) in the Knuth-Morris-Pratt (KMP) algorithm is used to:",
    "options": [
      "Determine the edit distance between two strings",
      "Skip already matched characters to avoid redundant comparisons",
      "Calculate the hash value of the pattern string",
      "Identify palindromic substrings within the pattern"
    ],
    "answer": "Skip already matched characters to avoid redundant comparisons",
    "explanation": "When a mismatch occurs, the LPS array indicates the longest proper prefix of the pattern that is also a suffix, allowing the algorithm to 'jump' back without re-checking matched characters.",
    "difficulty": "Intermediate"
  },
  {
    "id": 54,
    "question": "In a Min-Heap, which operation takes O(1) time?",
    "options": [
      "Inserting a new element",
      "Deleting the minimum element",
      "Peeking at the minimum element",
      "Decreasing the key of an element"
    ],
    "answer": "Peeking at the minimum element",
    "explanation": "The minimum element is always at the root (index 0) of the Min-Heap array, so it can be accessed instantly.",
    "difficulty": "Intermediate"
  },
  {
    "id": 55,
    "question": "Which algorithm utilizes a 'Greedy' strategy to construct an optimal prefix-free code for data compression?",
    "options": [
      "Lempel-Ziv-Welch (LZW)",
      "Huffman Coding",
      "Run-Length Encoding (RLE)",
      "Burrows-Wheeler Transform"
    ],
    "answer": "Huffman Coding",
    "explanation": "Huffman Coding repeatedly combines the two least frequent nodes (greedy choice) to build a binary tree, ensuring optimal compression for the given frequencies.",
    "difficulty": "Intermediate"
  },
  {
    "id": 56,
    "question": "What is the result of applying a depth-limited Depth First Search (DFS) with increasing depth limits?",
    "options": [
      "Dijkstra's Algorithm",
      "Iterative Deepening DFS (IDDFS)",
      "Breadth First Search (BFS)",
      "Bidirectional Search"
    ],
    "answer": "Iterative Deepening DFS (IDDFS)",
    "explanation": "IDDFS repeatedly runs DFS with a depth limit of 0, 1, 2... etc. This combines the fast memory usage of DFS with the completeness of BFS.",
    "difficulty": "Intermediate"
  },
  {
    "id": 57,
    "question": "Which of the following problems can be solved most efficiently using a Trie (Prefix Tree)?",
    "options": [
      "Finding the median of a stream of integers",
      "Implementing an autocomplete system",
      "Calculating the minimum spanning tree",
      "Finding connected components in a graph"
    ],
    "answer": "Implementing an autocomplete system",
    "explanation": "Tries store strings where nodes represent prefixes. This allows efficient retrieval of all words sharing a given prefix, which is the core requirement for autocomplete.",
    "difficulty": "Intermediate"
  },
  {
    "id": 58,
    "question": "In the context of Bitmasking, what does the operation `(x & -x)` compute?",
    "options": [
      "The value of x shifted left by one",
      "The two's complement of x",
      "The rightmost set bit (lowest significant bit) of x",
      "The number of set bits in x"
    ],
    "answer": "The rightmost set bit (lowest significant bit) of x",
    "explanation": "In two's complement arithmetic, `-x` is `~x + 1`. The expression `x & -x` isolates the least significant 1-bit, which is useful in Fenwick Tree implementations.",
    "difficulty": "Intermediate"
  },
  {
    "id": 59,
    "question": "What distinguishes the 'Coin Change' problem (minimum number of coins) from the 'Unbounded Knapsack' problem?",
    "options": [
      "Coin Change requires a greedy solution, while Knapsack requires DP",
      "Coin Change minimizes weight, while Knapsack maximizes value",
      "Coin Change is an optimization problem for minimum coins; Unbounded Knapsack is for maximum value",
      "There is no theoretical difference; they are isomorphic"
    ],
    "answer": "Coin Change is an optimization problem for minimum coins; Unbounded Knapsack is for maximum value",
    "explanation": "Both allow unlimited use of items (coins). The Coin Change problem usually asks for the minimum count to reach a sum, whereas Knapsack typically maximizes value subject to a weight limit.",
    "difficulty": "Intermediate"
  },
  {
    "id": 60,
    "question": "What is the time complexity of the Sieve of Eratosthenes for finding all prime numbers up to N?",
    "options": [
      "O(N)",
      "O(N log log N)",
      "O(N log N)",
      "O(N^2)"
    ],
    "answer": "O(N log log N)",
    "explanation": "The algorithm marks multiples of each prime. The harmonic series of primes leads to the N log log N complexity.",
    "difficulty": "Intermediate"
  },
  {
    "id": 61,
    "question": "Which graph algorithm is based on the concept of the 'lowest common ancestor' and Eulerian tours to answer range minimum queries (RMQ)?",
    "options": [
      "Tarjan's Off-line LCA Algorithm",
      "Kosaraju's Algorithm",
      "Prim's Algorithm",
      "Edmonds' Algorithm"
    ],
    "answer": "Tarjan's Off-line LCA Algorithm",
    "explanation": "Tarjan's algorithm processes queries off-line using a Disjoint Set Union structure to find LCAs efficiently in nearly linear time.",
    "difficulty": "Intermediate"
  },
  {
    "id": 62,
    "question": "In the context of computational geometry, what does the 'Sweep Line' algorithm typically compute?",
    "options": [
      "The convex hull of a set of points",
      "The intersection points of a set of line segments",
      "The shortest path between two points",
      "The area of a polygon"
    ],
    "answer": "The intersection points of a set of line segments",
    "explanation": "The Sweep Line algorithm moves a vertical line across the plane to detect geometric events, efficiently finding intersections between segments.",
    "difficulty": "Intermediate"
  },
  {
    "id": 63,
    "question": "Which property is violated if a binary tree is rotated during an AVL Tree insertion?",
    "options": [
      "The binary search tree property",
      "The balance factor condition",
      "The heap property",
      "The node coloring property"
    ],
    "answer": "The balance factor condition",
    "explanation": "Rotations are performed specifically to restore the balance factor (height of left vs right subtree) to the valid range of -1, 0, or 1.",
    "difficulty": "Intermediate"
  },
  {
    "id": 64,
    "question": "What is the worst-case time complexity to search for an element in a B-Tree of order m?",
    "options": [
      "O(m)",
      "O(log_m N)",
      "O(m log_m N)",
      "O(N)"
    ],
    "answer": "O(m log_m N)",
    "explanation": "The height of a B-Tree is O(log_m N). At each node, we may perform a binary search or linear scan of m keys, leading to a complexity of O(m log_m N).",
    "difficulty": "Intermediate"
  },
  {
    "id": 65,
    "question": "Which of the following algorithms is guaranteed to find a Maximum Matching in a bipartite graph?",
    "options": [
      "Prim's Algorithm",
      "Hopcroft-Karp Algorithm",
      "Floyd-Warshall Algorithm",
      "Kruskal's Algorithm"
    ],
    "answer": "Hopcroft-Karp Algorithm",
    "explanation": "The Hopcroft-Karp algorithm repeatedly finds shortest augmenting paths using BFS, improving the flow until maximum matching is achieved.",
    "difficulty": "Intermediate"
  },
  {
    "id": 66,
    "question": "What is the defining characteristic of a 'Greedy' algorithm?",
    "options": [
      "It explores all possible paths to find the optimal solution",
      "It makes the locally optimal choice at each stage with the hope of finding a global optimum",
      "It divides the problem into smaller subproblems and solves them recursively",
      "It uses a random approach to avoid local minima"
    ],
    "answer": "It makes the locally optimal choice at each stage with the hope of finding a global optimum",
    "explanation": "Greedy algorithms build up a solution piece by piece, choosing the piece that offers the most immediate benefit without revisiting previous choices.",
    "difficulty": "Intermediate"
  },
  {
    "id": 67,
    "question": "In the context of hashing, what is 'Double Hashing'?",
    "options": [
      "Storing the hash value twice for verification",
      "A collision resolution method using two hash functions",
      "Creating two hash tables to split the load",
      "Hashing the key twice to form a 64-bit signature"
    ],
    "answer": "A collision resolution method using two hash functions",
    "explanation": "When a collision occurs, double hashing uses a second hash function to calculate the step size for the probe sequence, reducing primary clustering.",
    "difficulty": "Intermediate"
  },
  {
    "id": 68,
    "question": "What does the 'Master Theorem' provide a solution for?",
    "options": [
      "Calculating the time complexity of divide-and-conquer recurrences",
      "Determining if a graph is planar",
      "Finding the GCD of two numbers",
      "Solving linear Diophantine equations"
    ],
    "answer": "Calculating the time complexity of divide-and-conquer recurrences",
    "explanation": "The Master Theorem provides asymptotic analysis (Big O) for recurrence relations of the form T(n) = aT(n/b) + f(n).",
    "difficulty": "Intermediate"
  },
  {
    "id": 69,
    "question": "Which algorithm is used to test whether a polygon is convex?",
    "options": [
      "Checking if all interior angles are less than 180 degrees using cross products",
      "Running Dijkstra's algorithm on polygon vertices",
      "Counting the number of unique edges",
      "Applying the Sieve of Eratosthenes"
    ],
    "answer": "Checking if all interior angles are less than 180 degrees using cross products",
    "explanation": "For every triplet of consecutive vertices, one checks the sign of the cross product (z-component). A convex polygon requires all signs to be the same (all left or all right turns).",
    "difficulty": "Intermediate"
  },
  {
    "id": 70,
    "question": "What is the 'Sparse Table' data structure primarily used for?",
    "options": [
      "Dynamic updates and range minimum queries",
      "Static array range queries (like RMQ) without updates",
      "Storing graph adjacency lists efficiently",
      "Managing memory for sparse matrices"
    ],
    "answer": "Static array range queries (like RMQ) without updates",
    "explanation": "Sparse Tables pre-process information for O(1) queries on immutable arrays. They are not suitable for dynamic data because updates require O(N log N) reconstruction.",
    "difficulty": "Intermediate"
  }
]