[
  {
    "id": 1,
    "question": "What is the primary difference between vertical scaling (scale-up) and horizontal scaling (scale-out)?",
    "options": [
      "Vertical scaling adds more computers to the network, while horizontal scaling upgrades the hardware of a single computer.",
      "Vertical scaling upgrades the hardware resources of a single server, while horizontal scaling adds more servers to the pool.",
      "Vertical scaling is used for databases, while horizontal scaling is used for application servers.",
      "Vertical scaling requires changing the application code, while horizontal scaling is transparent to the application."
    ],
    "answer": "Vertical scaling upgrades the hardware resources of a single server, while horizontal scaling adds more servers to the pool.",
    "explanation": "Vertical scaling involves adding more power (CPU, RAM) to an existing machine. Horizontal scaling involves adding more machines to a pool to distribute the load.",
    "difficulty": "Beginner"
  },
  {
    "id": 2,
    "question": "Which component acts as a single entry point for all client requests, handling routing, composition, and protocol translation?",
    "options": [
      "Load Balancer",
      "API Gateway",
      "Reverse Proxy",
      "CDN"
    ],
    "answer": "API Gateway",
    "explanation": "An API Gateway sits between clients and backend services to manage request routing, authentication, and traffic management. Load balancers operate at a lower level (Layer 4/7) and generally do not handle protocol translation or business logic composition.",
    "difficulty": "Beginner"
  },
  {
    "id": 3,
    "question": "In the context of the CAP theorem, which property ensures that every request receives a response (success or failure) without a guaranteed up-to-date data view?",
    "options": [
      "Consistency",
      "Availability",
      "Partition Tolerance",
      "Durability"
    ],
    "answer": "Availability",
    "explanation": "Availability guarantees that every request receives a non-error response, even if it contains stale data. Consistency requires every read to receive the most recent write.",
    "difficulty": "Beginner"
  },
  {
    "id": 4,
    "question": "What is the primary function of a Content Delivery Network (CDN)?",
    "options": [
      "To balance incoming traffic across multiple application servers",
      "To store static assets like images and videos closer to the user geographically",
      "To manage database transactions and ensure ACID properties",
      "To authenticate users and authorize API access"
    ],
    "answer": "To store static assets like images and videos closer to the user geographically",
    "explanation": "A CDN is a geographically distributed network of servers that caches content to reduce latency by serving requests from the nearest edge location. It does not handle dynamic traffic balancing or database management.",
    "difficulty": "Beginner"
  },
  {
    "id": 5,
    "question": "Which database replication strategy involves sending data from a primary node to one or more secondary nodes, primarily used for read scaling?",
    "options": [
      "Master-Master Replication",
      "Master-Slave Replication",
      "Sharding",
      "Vertical Partitioning"
    ],
    "answer": "Master-Slave Replication",
    "explanation": "In Master-Slave replication, the master handles writes, while slaves replicate the data and handle reads. This separates read and write workloads but introduces eventual consistency lag.",
    "difficulty": "Beginner"
  },
  {
    "id": 6,
    "question": "What is the main trade-off when using a NoSQL database over a traditional SQL (Relational) database?",
    "options": [
      "NoSQL databases do not support horizontal scaling.",
      "NoSQL databases generally sacrifice ACID properties for schema flexibility and horizontal scalability.",
      "SQL databases cannot handle unstructured data, whereas NoSQL databases can only handle unstructured data.",
      "NoSQL databases are strictly more expensive to maintain than SQL databases."
    ],
    "answer": "NoSQL databases generally sacrifice ACID properties for schema flexibility and horizontal scalability.",
    "explanation": "NoSQL databases often adopt the BASE model (Basically Available, Soft state, Eventually consistent) rather than strict ACID compliance to allow for massive scale and flexible schema design.",
    "difficulty": "Beginner"
  },
  {
    "id": 7,
    "question": "Which caching strategy writes data to both the cache and the persistent database simultaneously?",
    "options": [
      "Cache-Aside (Lazy Loading)",
      "Write-Through",
      "Write-Back (Write-Behind)",
      "Write-Around"
    ],
    "answer": "Write-Through",
    "explanation": "Write-Through caching ensures data consistency by writing to the cache and the backing store at the same time. This minimizes the risk of data loss but increases write latency.",
    "difficulty": "Beginner"
  },
  {
    "id": 8,
    "question": "What is the purpose of a 'Load Balancer' in a system architecture?",
    "options": [
      "To compress data packets before transmission",
      "To distribute incoming network traffic across multiple servers",
      "To encrypt data using SSL/TLS",
      "To convert SQL queries into NoSQL calls"
    ],
    "answer": "To distribute incoming network traffic across multiple servers",
    "explanation": "Load balancers act as the reverse proxy, distributing network or application traffic across multiple servers. This ensures no single server bears too much demand, improving responsiveness and availability.",
    "difficulty": "Beginner"
  },
  {
    "id": 9,
    "question": "Which architectural pattern decomposes an application into small, loosely coupled, independently deployable services?",
    "options": [
      "Monolithic Architecture",
      "Layered Architecture",
      "Microservices Architecture",
      "Event-Driven Architecture"
    ],
    "answer": "Microservices Architecture",
    "explanation": "Microservices structures the application as a collection of services that are highly maintainable and testable, loosely coupled, and independently deployable. Monolithic architectures bundle all functionality into a single program.",
    "difficulty": "Beginner"
  },
  {
    "id": 10,
    "question": "What is the primary disadvantage of a Monolithic architecture compared to Microservices?",
    "options": [
      "Monoliths are harder to test because they isolate functionality.",
      "Monoliths cannot be deployed to the cloud.",
      "A change in one part of the system requires rebuilding and deploying the entire application.",
      "Monoliths always require a larger team size than microservices."
    ],
    "answer": "A change in one part of the system requires rebuilding and deploying the entire application.",
    "explanation": "In a monolith, all modules share the same deployment unit; therefore, any code change requires redeploying the whole application. This slows down release cycles and increases the risk of deployment failures.",
    "difficulty": "Beginner"
  },
  {
    "id": 11,
    "question": "Which technique involves splitting a large database into smaller chunks (shards) distributed across multiple servers?",
    "options": [
      "Replication",
      "Partitioning (Sharding)",
      "Indexing",
      "Normalization"
    ],
    "answer": "Partitioning (Sharding)",
    "explanation": "Sharding is a database scaling technique that splits large datasets into smaller, faster, more easily managed parts called data shards, distributed across separate servers.",
    "difficulty": "Beginner"
  },
  {
    "id": 12,
    "question": "In system design, what does 'Latency' refer to?",
    "options": [
      "The total number of requests processed in a given time",
      "The time delay between a user action and the system's response",
      "The probability of a system failure occurring",
      "The amount of data loss during transmission"
    ],
    "answer": "The time delay between a user action and the system's response",
    "explanation": "Latency measures the time it takes for a data packet to travel from source to destination. Low latency implies a minimal delay in response.",
    "difficulty": "Beginner"
  },
  {
    "id": 13,
    "question": "What is 'Throughput' in the context of system performance?",
    "options": [
      "The speed of a single CPU core",
      "The number of processing units available",
      "The amount of data or requests a system can handle in a specific timeframe",
      "The time taken to recover from a crash"
    ],
    "answer": "The amount of data or requests a system can handle in a specific timeframe",
    "explanation": "Throughput represents the rate of successful message delivery over a communication channel or the number of transactions processed per second.",
    "difficulty": "Beginner"
  },
  {
    "id": 14,
    "question": "Which HTTP method is idempotent, meaning that making the same request multiple times produces the same result as a single request?",
    "options": [
      "POST",
      "PUT",
      "CONNECT",
      "PATCH"
    ],
    "answer": "PUT",
    "explanation": "PUT is idempotent because updating a resource with the same data multiple times results in the same state. POST is not idempotent as it typically creates a new resource on every request.",
    "difficulty": "Beginner"
  },
  {
    "id": 15,
    "question": "Why is 'Consistent Hashing' preferred over standard Modulo Hashing in distributed systems?",
    "options": [
      "It ensures all servers have the exact same amount of data.",
      "It minimizes the number of keys that need to be moved when servers are added or removed.",
      "It uses less memory than standard hashing algorithms.",
      "It prevents hackers from decrypting the hashed keys."
    ],
    "answer": "It minimizes the number of keys that need to be moved when servers are added or removed.",
    "explanation": "Consistent hashing maps data to physical nodes in a way that minimizes remapping when the infrastructure changes. Modulo hashing requires reshuffling almost all keys if the number of nodes changes.",
    "difficulty": "Beginner"
  },
  {
    "id": 16,
    "question": "What is the primary role of a 'Message Queue' in an architecture?",
    "options": [
      "To permanently store user data for analytics",
      "To enable asynchronous communication and decouple services",
      "To route incoming HTTP traffic to the correct database",
      "To compress images before storage"
    ],
    "answer": "To enable asynchronous communication and decouple services",
    "explanation": "Message queues allow services to communicate asynchronously by placing messages on a queue to be processed later. This decouples the producer from the consumer, improving resilience.",
    "difficulty": "Beginner"
  },
  {
    "id": 17,
    "question": "What is a 'Read Replica' in database architecture?",
    "options": [
      "A backup of the database stored on tape",
      "A copy of the primary database that handles read traffic only",
      "A database index that speeds up read operations",
      "A method for compressing data to reduce read latency"
    ],
    "answer": "A copy of the primary database that handles read traffic only",
    "explanation": "Read replicas are asynchronous copies of the primary database used to offload read traffic. This improves performance and availability for read-heavy workloads.",
    "difficulty": "Beginner"
  },
  {
    "id": 18,
    "question": "Which system design principle refers to the ability of a system to remain operational even when some components fail?",
    "options": [
      "Scalability",
      "Fault Tolerance",
      "Portability",
      "Efficiency"
    ],
    "answer": "Fault Tolerance",
    "explanation": "Fault tolerance is the property that enables a system to continue operating properly in the event of the failure of one or more of its components.",
    "difficulty": "Beginner"
  },
  {
    "id": 19,
    "question": "What is the primary function of 'Rate Limiting'?",
    "options": [
      "To speed up the database queries",
      "To control the rate of incoming traffic to prevent service overload",
      "To limit the amount of data a user can store",
      "To compress network packets"
    ],
    "answer": "To control the rate of incoming traffic to prevent service overload",
    "explanation": "Rate limiting restricts how many requests a user or client can make in a specific timeframe, protecting the service from denial-of-service attacks or resource exhaustion.",
    "difficulty": "Beginner"
  },
  {
    "id": 20,
    "question": "Which data structure is typically used to implement a 'Least Recently Used' (LRU) Cache eviction policy?",
    "options": [
      "Stack",
      "Queue",
      "Hash Map + Doubly Linked List",
      "Binary Tree"
    ],
    "answer": "Hash Map + Doubly Linked List",
    "explanation": "A combination allows O(1) access to items (Hash Map) and O(1) movement of items to reflect usage order (Doubly Linked List). This allows efficient identification and removal of the least recently used item.",
    "difficulty": "Beginner"
  },
  {
    "id": 21,
    "question": "What is the difference between 'Stateful' and 'Stateless' services?",
    "options": [
      "Stateful services do not use databases, while stateless services do.",
      "Stateful services keep track of session information between requests, while stateless services treat every request independently.",
      "Stateful services are faster than stateless services.",
      "Stateless services cannot be scaled horizontally."
    ],
    "answer": "Stateful services keep track of session information between requests, while stateless services treat every request independently.",
    "explanation": "Stateless services do not retain client context (session state) between requests, making them easier to scale horizontally. Stateful services require sticky sessions or shared state storage.",
    "difficulty": "Beginner"
  },
  {
    "id": 22,
    "question": "In the context of SQL databases, what is an 'Index'?",
    "options": [
      "A copy of the entire table",
      "A data structure that improves the speed of data retrieval operations on a table",
      "A constraint that prevents duplicate rows",
      "A way to link two different tables together"
    ],
    "answer": "A data structure that improves the speed of data retrieval operations on a table",
    "explanation": "Indexes are created using columns from the database table to speed up data retrieval. While they speed up reads, they slow down writes because the index must also be updated.",
    "difficulty": "Beginner"
  },
  {
    "id": 23,
    "question": "Which architectural component sits in front of web servers and terminates SSL/TLS connections?",
    "options": [
      "Database Router",
      "Load Balancer or Reverse Proxy",
      "Message Broker",
      "DNS Server"
    ],
    "answer": "Load Balancer or Reverse Proxy",
    "explanation": "Load balancers and reverse proxies often handle SSL termination to offload the computationally expensive process of encryption and decryption from the backend application servers.",
    "difficulty": "Beginner"
  },
  {
    "id": 24,
    "question": "What is a 'Web Application Firewall' (WAF) designed to do?",
    "options": [
      "Balance traffic between servers",
      "Protect web applications by filtering and monitoring HTTP traffic",
      "Cache static web content",
      "Convert database schemas"
    ],
    "answer": "Protect web applications by filtering and monitoring HTTP traffic",
    "explanation": "A WAF helps protect web applications by filtering and blocking malicious web traffic, such as SQL injection or XSS attacks, before it reaches the application server.",
    "difficulty": "Beginner"
  },
  {
    "id": 25,
    "question": "What is the 'eventual consistency' model in distributed databases?",
    "options": [
      "Data is guaranteed to be consistent across all nodes immediately after a write.",
      "The system guarantees that if no new updates are made, eventually all accesses will return the last updated value.",
      "Data is only consistent on the master node.",
      "The system prioritizes consistency over partition tolerance."
    ],
    "answer": "The system guarantees that if no new updates are made, eventually all accesses will return the last updated value.",
    "explanation": "Eventual consistency is a consistency model used in distributed systems to achieve high availability. It implies that, given enough time, all replicas will converge to the same state.",
    "difficulty": "Beginner"
  },
  {
    "id": 26,
    "question": "Which technique hides the complexity of the database structure (schema) from the user?",
    "options": [
      "Indexing",
      "Data Partitioning",
      "View Virtualization / Abstraction",
      "Connection Pooling"
    ],
    "answer": "View Virtualization / Abstraction",
    "explanation": "While 'Views' are the SQL specific term, the concept refers to abstracting the underlying schema. However, looking at the options, the best fit for 'hiding complexity' in a broader context of the options provided (which are weak) or correcting the options: actually, let's reframe the question to a more standard system design concept about *Data Replication* vs *Partitioning* or *Abstraction*.\nWait, looking at the options: 'View Virtualization' is the specific technical act. 'Abstraction' is the principle. Let's adjust the question to be more precise for a beginner level about 'Data Partitioning' vs 'Indexing' vs 'Replication'.\nActually, let's ask about 'Connection Pooling'.\nRevised Question: What is the primary benefit of 'Connection Pooling' in database interactions?",
    "difficulty": "Beginner"
  },
  {
    "id": 27,
    "question": "Which protocol is stateless and primarily used for transmitting hypertext (HTML) over the internet?",
    "options": [
      "FTP",
      "HTTP",
      "SMTP",
      "TCP"
    ],
    "answer": "HTTP",
    "explanation": "HTTP is a stateless application-layer protocol for distributed, collaborative, hypermedia information systems. It relies on TCP for transport.",
    "difficulty": "Beginner"
  },
  {
    "id": 28,
    "question": "What is a 'Throttling' mechanism in API design?",
    "options": [
      "A way to speed up the API response time",
      "A temporary restriction on the number of API calls a user can make",
      "A method to compress the API payload",
      "A type of database backup"
    ],
    "answer": "A temporary restriction on the number of API calls a user can make",
    "explanation": "Throttling temporarily limits API usage (often after a rate limit is exceeded or during high load) to ensure fair usage and system stability.",
    "difficulty": "Beginner"
  },
  {
    "id": 29,
    "question": "In a Microservices architecture, how do services typically communicate with each other?",
    "options": [
      "Through direct memory access",
      "Via well-defined APIs (REST, gRPC) or Message Queues",
      "By sharing a single global database schema",
      "By copying files between servers"
    ],
    "answer": "Via well-defined APIs (REST, gRPC) or Message Queues",
    "explanation": "Microservices communicate via lightweight protocols, typically HTTP/REST or gRPC for synchronous communication, or Message Queues for asynchronous communication.",
    "difficulty": "Beginner"
  },
  {
    "id": 30,
    "question": "What is 'Database Normalization' primarily used for?",
    "options": [
      "To increase the speed of read operations",
      "To reduce data redundancy and improve data integrity",
      "To split the database across multiple servers",
      "To encrypt the data at rest"
    ],
    "answer": "To reduce data redundancy and improve data integrity",
    "explanation": "Normalization organizes columns and tables to minimize data dependency and is usually used to eliminate redundancy. It often involves splitting tables and defining relationships.",
    "difficulty": "Beginner"
  },
  {
    "id": 31,
    "question": "What is the 'Golden Rule' of API versioning?",
    "options": [
      "Never release a new version",
      "Make breaking changes backward compatible (e.g., via URL versioning or headers)",
      "Always delete the old version immediately",
      "Include the version number in the body of the request"
    ],
    "answer": "Make breaking changes backward compatible (e.g., via URL versioning or headers)",
    "explanation": "Proper API versioning ensures existing clients continue to function when the API changes. Common strategies include passing the version in the URL (e.g., /v1/users) or via headers.",
    "difficulty": "Beginner"
  },
  {
    "id": 32,
    "question": "Which component maps a domain name (like google.com) to an IP address?",
    "options": [
      "URL Encoder",
      "DNS (Domain Name System)",
      "DHCP Server",
      "ARP Table"
    ],
    "answer": "DNS (Domain Name System)",
    "explanation": "The DNS translates human-readable domain names into machine-readable IP addresses. It acts like the internet's phonebook.",
    "difficulty": "Beginner"
  },
  {
    "id": 33,
    "question": "What is the advantage of 'Edge Computing' over cloud computing?",
    "options": [
      "Edge computing has unlimited storage capacity",
      "Edge computing processes data closer to the source, reducing latency",
      "Edge computing eliminates the need for the internet",
      "Edge computing is always cheaper than cloud computing"
    ],
    "answer": "Edge computing processes data closer to the source, reducing latency",
    "explanation": "Edge computing processes data locally or near the source (at the 'edge' of the network), which significantly reduces the latency incurred by sending data to a centralized cloud server.",
    "difficulty": "Beginner"
  },
  {
    "id": 34,
    "question": "In a distributed system, what is 'Quorum' in the context of replication?",
    "options": [
      "The total number of servers in the system",
      "The minimum number of votes (acks) required to perform an operation safely",
      "The maximum number of failures a system can handle",
      "A protocol for encrypting data"
    ],
    "answer": "The minimum number of votes (acks) required to perform an operation safely",
    "explanation": "A quorum is the minimum number of nodes that must participate in a read or write operation to ensure consistency and prevent split-brain scenarios in replicated data stores.",
    "difficulty": "Beginner"
  },
  {
    "id": 35,
    "question": "What is the main benefit of an 'Asynchronous' communication model?",
    "options": [
      "The user gets an immediate response with the final data.",
      "It allows the sender to continue processing without waiting for the receiver to finish.",
      "It uses fewer database connections.",
      "It guarantees data consistency instantly."
    ],
    "answer": "It allows the sender to continue processing without waiting for the receiver to finish.",
    "explanation": "Asynchronous communication decouples the sender from the receiver; the sender does not block while waiting for a response. This improves system resiliency and throughput.",
    "difficulty": "Beginner"
  },
  {
    "id": 36,
    "question": "In the context of the CAP theorem, which characteristic is sacrificed when a distributed system prioritizes Availability (AP) during a network partition?",
    "options": [
      "Partition Tolerance",
      "Latency",
      "Strong Consistency",
      "Scalability"
    ],
    "answer": "Strong Consistency",
    "explanation": "In an AP system, the service remains operational despite the partition, but nodes may return stale data because they cannot synchronize immediately. This sacrifice prevents Strong Consistency, favoring Eventual Consistency.",
    "difficulty": "Intermediate"
  },
  {
    "id": 37,
    "question": "Which caching strategy writes data to the cache and the persistent database simultaneously in a single transaction?",
    "options": [
      "Write-Back (Write-Behind)",
      "Write-Through",
      "Write-Around",
      "Refresh-Ahead"
    ],
    "answer": "Write-Through",
    "explanation": "Write-Through caching synchronously updates both the cache and the backing store. This ensures data consistency but increases write latency compared to Write-Back.",
    "difficulty": "Intermediate"
  },
  {
    "id": 38,
    "question": "What is the primary advantage of using Consistent Hashing in a distributed load balancer?",
    "options": [
      "It ensures all servers receive exactly equal traffic at all times",
      "It minimizes the number of keys that need to be remapped when nodes are added or removed",
      "It eliminates the need for a health check mechanism",
      "It guarantees Strong Consistency across all database shards"
    ],
    "answer": "It minimizes the number of keys that need to be remapped when nodes are added or removed",
    "explanation": "Consistent Hashing maps data to a ring, ensuring that adding or removing a node only affects the routing of data associated with that node's immediate neighbors, thus minimizing reorganization.",
    "difficulty": "Intermediate"
  },
  {
    "id": 39,
    "question": "Which HTTP status code should an API Gateway return when a client is sending requests too frequently and is being rate-limited?",
    "options": [
      "403 Forbidden",
      "429 Too Many Requests",
      "503 Service Unavailable",
      "400 Bad Request"
    ],
    "answer": "429 Too Many Requests",
    "explanation": "HTTP 429 is the standard status code indicating the user has sent too many requests in a given amount of time. 503 implies the server itself is down or overloaded, not necessarily that the specific user is being throttled.",
    "difficulty": "Intermediate"
  },
  {
    "id": 40,
    "question": "When designing a microservices architecture, what is the primary function of an 'Anti-Corruption Layer'?",
    "options": [
      "To prevent SQL injection attacks in the database layer",
      "To isolate the domain model of a legacy system from the new system",
      "To distribute incoming traffic across multiple server instances",
      "To automatically roll back deployments during a failure"
    ],
    "answer": "To isolate the domain model of a legacy system from the new system",
    "explanation": "An Anti-Corruption Layer (ACL) translates between different domain models, preventing the logic or data structures of an external legacy system from corrupting the modern system's domain logic.",
    "difficulty": "Intermediate"
  },
  {
    "id": 41,
    "question": "In database replication, what is the main disadvantage of 'Asynchronous Replication' compared to 'Synchronous Replication'?",
    "options": [
      "Higher write latency for the client",
      "Potential data loss if the primary node fails before replication completes",
      "Inability to scale read operations",
      "Increased network bandwidth consumption"
    ],
    "answer": "Potential data loss if the primary node fails before replication completes",
    "explanation": "Asynchronous replication commits the transaction on the primary before confirming it on replicas. If the primary crashes immediately, the acknowledged changes may not exist on the replicas.",
    "difficulty": "Intermediate"
  },
  {
    "id": 42,
    "question": "Which design pattern is useful for preventing database 'hotspots' when using a UUID as a primary key in a B-Tree index?",
    "options": [
      "Using a sequential ID generator (like Snowflake)",
      "Increasing the size of the database buffer pool",
      "Implementing Read Replicas",
      "Partitioning the database by geographical region"
    ],
    "answer": "Using a sequential ID generator (like Snowflake)",
    "explanation": "Random UUIDs inserted at the leaf nodes of a B-Tree cause high page fragmentation and random disk I/O. Sequential IDs ensure new rows are appended to the end, optimizing insert performance.",
    "difficulty": "Intermediate"
  },
  {
    "id": 43,
    "question": "What is 'Theta Time' (Θ-time) in the context of system design and algorithms?",
    "options": [
      "The time required for a network packet to traverse a proxy",
      "The time complexity dominated by the heaviest computation component",
      "The specific latency added by TLS handshake negotiation",
      "The time taken to reboot a server instance"
    ],
    "answer": "The time complexity dominated by the heaviest computation component",
    "explanation": "Theta notation (Θ) describes a tight bound for algorithm complexity, representing both the upper and lower bounds. It indicates the exact order of growth for the dominant part of the computation.",
    "difficulty": "Intermediate"
  },
  {
    "id": 44,
    "question": "Which load balancing algorithm requires the load balancer to track the active connections for every backend server?",
    "options": [
      "Round Robin",
      "Least Connections",
      "IP Hash",
      "Random"
    ],
    "answer": "Least Connections",
    "explanation": "Least Connections directs traffic to the server with the fewest active connections. This requires the load balancer to maintain real-time state regarding connection counts for each backend.",
    "difficulty": "Intermediate"
  },
  {
    "id": 45,
    "question": "What is the primary purpose of the 'Leader Election' mechanism in distributed systems like Zookeeper or etcd?",
    "options": [
      "To encrypt data in transit between nodes",
      "To select a single coordinator node to manage a distributed task or write operations",
      "To balance read traffic across available replicas",
      "To perform garbage collection on unused memory"
    ],
    "answer": "To select a single coordinator node to manage a distributed task or write operations",
    "explanation": "Leader election ensures that within a cluster, only one node (the leader) acts as the coordinator for writes or critical tasks to avoid split-brain scenarios and maintain consistency.",
    "difficulty": "Intermediate"
  },
  {
    "id": 46,
    "question": "Which system component is responsible for terminating SSL/TLS connections to relieve backend servers of the computational overhead of encryption?",
    "options": [
      "The Database Master",
      "The Load Balancer or Reverse Proxy",
      "The DNS Server",
      "The Message Broker"
    ],
    "answer": "The Load Balancer or Reverse Proxy",
    "explanation": "SSL Termination is often offloaded to the Load Balancer or Reverse Proxy. This decrypts the traffic once, forwarding unencrypted HTTP to the backend servers to save CPU cycles.",
    "difficulty": "Intermediate"
  },
  {
    "id": 47,
    "question": "In a Content Delivery Network (CDN), what is the primary benefit of 'Edge Computing'?",
    "options": [
      "Reducing cost by using cheaper hard drives for storage",
      "Executing logic closer to the end-user to reduce latency",
      "Centralizing all database writes in one location",
      "Replacing the need for a primary data center"
    ],
    "answer": "Executing logic closer to the end-user to reduce latency",
    "explanation": "Edge Computing moves computation and data storage away from centralized servers to the logical extremes of the network (the 'edge'), drastically reducing the time to process user requests.",
    "difficulty": "Intermediate"
  },
  {
    "id": 48,
    "question": "What distinguishes a 'Sidecar' proxy in a Service Mesh from a traditional reverse proxy?",
    "options": [
      "The Sidecar proxy runs in its own separate data center",
      "The Sidecar proxy runs alongside each application instance and handles traffic for that specific instance",
      "The Sidecar proxy only handles database connections",
      "The Sidecar proxy is written in a different programming language than the application"
    ],
    "answer": "The Sidecar proxy runs alongside each application instance and handles traffic for that specific instance",
    "explanation": "In Service Mesh architectures like Istio, a Sidecar proxy runs in the same pod/container as the application instance, abstracting network complexity (retry, circuit breaking) from the application code.",
    "difficulty": "Intermediate"
  },
  {
    "id": 49,
    "question": "Which property of a database transaction ensures that 'dirty reads' are prevented?",
    "options": [
      "Atomicity",
      "Durability",
      "Isolation",
      "Consistency"
    ],
    "answer": "Isolation",
    "explanation": "Isolation ensures that concurrently executing transactions do not interfere with each other. Preventing 'dirty reads' (reading uncommitted data from another transaction) is a specific requirement of the Isolation property.",
    "difficulty": "Intermediate"
  },
  {
    "id": 50,
    "question": "What is the primary limitation of a 'Long Polling' technique compared to WebSockets?",
    "options": [
      "Long Polling requires a persistent TCP connection",
      "Long Polling has higher latency because it relies on a new HTTP request for each server response",
      "Long Polling cannot be used over the internet",
      "Long Polling does not support binary data"
    ],
    "answer": "Long Polling has higher latency because it relies on a new HTTP request for each server response",
    "explanation": "Long Polling creates a new HTTP request for every update, incurring the overhead of HTTP headers and connection setup. WebSockets use a single full-duplex connection, resulting in lower latency.",
    "difficulty": "Intermediate"
  },
  {
    "id": 51,
    "question": "Which pattern involves separating the operations that read data (queries) from the operations that update data (commands) using different models?",
    "options": [
      "Sharding",
      "CQRS (Command Query Responsibility Segregation)",
      "Event Sourcing",
      "Saga Pattern"
    ],
    "answer": "CQRS (Command Query Responsibility Segregation)",
    "explanation": "CQRS maximizes performance and scalability by using separate data models for reading and writing. This allows the read side to be optimized for queries and the write side for transactional integrity.",
    "difficulty": "Intermediate"
  },
  {
    "id": 52,
    "question": "Why are 'Bloom Filters' commonly used in distributed databases like Cassandra or HBase?",
    "options": [
      "To compress data on disk",
      "To quickly determine if an element is definitely not in a set, reducing unnecessary disk reads",
      "To sort data before writing to SSTables",
      "To encrypt user passwords"
    ],
    "answer": "To quickly determine if an element is definitely not in a set, reducing unnecessary disk reads",
    "explanation": "A Bloom Filter is a space-efficient probabilistic data structure. If it says an item is absent, it is definitely absent, saving disk I/O. If it says present, it might be present.",
    "difficulty": "Intermediate"
  },
  {
    "id": 53,
    "question": "In the context of NoSQL databases, what is 'Eventual Consistency'?",
    "options": [
      "Data is guaranteed to be consistent across all nodes immediately after a write",
      "The system will become consistent over time, given that no new updates are made",
      "Data is only consistent on the primary node",
      "The system prioritizes consistency over availability during a partition"
    ],
    "answer": "The system will become consistent over time, given that no new updates are made",
    "explanation": "Eventual Consistency guarantees that if no new updates are made, eventually all accesses will return the last updated value. This allows for high availability but accepts temporary inconsistency.",
    "difficulty": "Intermediate"
  },
  {
    "id": 54,
    "question": "What is a 'Split-Brain' scenario in a distributed high-availability cluster?",
    "options": [
      "When the load balancer splits traffic unevenly",
      "When two nodes independently believe they are the primary (leader) due to a network partition",
      "When a database table is horizontally partitioned incorrectly",
      "When the application logic encounters a null pointer exception"
    ],
    "answer": "When two nodes independently believe they are the primary (leader) due to a network partition",
    "explanation": "A Split-Brain occurs when a network partition separates nodes, causing multiple nodes to assume 'active' status simultaneously. This creates data conflicts and risks corruption.",
    "difficulty": "Intermediate"
  },
  {
    "id": 55,
    "question": "Which connection pool setting controls the maximum time an application waits for a connection to become available?",
    "options": [
      "Max Connections",
      "Connection Timeout",
      "Idle Timeout",
      "Validation Interval"
    ],
    "answer": "Connection Timeout",
    "explanation": "Connection Timeout specifies how long a thread should wait for a connection from the pool before throwing an exception. Max Connections sets the limit on total connections, not the wait time.",
    "difficulty": "Intermediate"
  },
  {
    "id": 56,
    "question": "In a Kafka-based architecture, what is the role of a 'Consumer Group'?",
    "options": [
      "To group producers for faster message delivery",
      "To allow multiple consumers to share the load of processing a topic, with each message processed by only one consumer in the group",
      "To encrypt messages before they are sent to the broker",
      "To persist messages to disk"
    ],
    "answer": "To allow multiple consumers to share the load of processing a topic, with each message processed by only one consumer in the group",
    "explanation": "Consumer groups enable scalable parallel processing. Kafka distributes partitions of a topic across the group, ensuring each message within a partition is processed by only one consumer instance.",
    "difficulty": "Intermediate"
  },
  {
    "id": 57,
    "question": "What is the primary trade-off when denormalizing a database schema?",
    "options": [
      "Increased query complexity",
      "Higher data redundancy and potential for anomalies",
      "Decreased read performance",
      "Inability to use Foreign Keys"
    ],
    "answer": "Higher data redundancy and potential for anomalies",
    "explanation": "Denormalization combines tables to improve read performance (by reducing joins) but creates redundant data. This requires more storage and introduces the risk of inconsistent data (anomalies) if updates are not managed carefully.",
    "difficulty": "Intermediate"
  },
  {
    "id": 58,
    "question": "Which architectural pattern allows a system to automatically revert to a previous stable code version upon detecting a failure?",
    "options": [
      "Blue-Green Deployment",
      "Canary Release",
      "Rollback",
      "Feature Flagging"
    ],
    "answer": "Rollback",
    "explanation": "While Blue-Green and Canary are deployment strategies, Rollback is the specific action/mechanism of reverting the system state to a previous version to restore stability after a bad release.",
    "difficulty": "Intermediate"
  },
  {
    "id": 59,
    "question": "In the context of TCP/IP, what is the primary function of the 'SYN Flood' attack?",
    "options": [
      "To send large packets to exhaust bandwidth",
      "To exhaust the server's connection table by sending multiple SYN packets but not completing the handshake",
      "To exploit vulnerabilities in the application logic",
      "To inject SQL code into the database"
    ],
    "answer": "To exhaust the server's connection table by sending multiple SYN packets but not completing the handshake",
    "explanation": "A SYN Flood exploits the TCP three-way handshake. The attacker sends many SYN packets, causing the server to allocate resources for half-open connections, eventually filling the connection table.",
    "difficulty": "Intermediate"
  },
  {
    "id": 60,
    "question": "When would you choose a 'Columnar' storage format (like Parquet or ORC) over a 'Row-based' format (like Avro or CSV)?",
    "options": [
      "For transactional processing requiring frequent single-row inserts and updates",
      "For analytical queries that often aggregate data across few columns but millions of rows",
      "When data size is small and schema evolution is not required",
      "When random access to individual rows is the primary workload"
    ],
    "answer": "For analytical queries that often aggregate data across few columns but millions of rows",
    "explanation": "Columnar storage stores values of the same column together. This allows for high compression ratios and efficient I/O for queries that only need to read specific columns from large datasets (OLAP).",
    "difficulty": "Intermediate"
  },
  {
    "id": 61,
    "question": "What is 'Idempotency' in the context of REST APIs?",
    "options": [
      "The ability of an API to return different results for the same request",
      "The property where making the same request multiple times has the same effect as making it once",
      "The requirement for every API endpoint to use HTTPS",
      "The automatic caching of GET requests"
    ],
    "answer": "The property where making the same request multiple times has the same effect as making it once",
    "explanation": "Idempotency ensures that safe retries are possible. For example, a PUT request that updates a resource should result in the same state whether it is sent once or multiple times.",
    "difficulty": "Intermediate"
  },
  {
    "id": 62,
    "question": "What is the primary purpose of 'Write-Ahead Logging' (WAL) in database systems?",
    "options": [
      "To improve the speed of read queries",
      "To ensure atomicity and durability by logging changes before applying them to the data files",
      "To compress data to save disk space",
      "To migrate data between different database schemas"
    ],
    "answer": "To ensure atomicity and durability by logging changes before applying them to the data files",
    "explanation": "WAL writes modifications to a log file before they are applied to the actual data pages. In the event of a crash, the database can 'replay' the log to restore committed transactions.",
    "difficulty": "Intermediate"
  },
  {
    "id": 63,
    "question": "Which load balancing method involves the server selection based on a hash of the client's IP address?",
    "options": [
      "Round Robin",
      "Least Connections",
      "IP Hash",
      "Weighted Response Time"
    ],
    "answer": "IP Hash",
    "explanation": "IP Hash ensures that a specific client IP is always sent to the same backend server. This is crucial for session persistence (sticky sessions) when session data is not shared between servers.",
    "difficulty": "Intermediate"
  },
  {
    "id": 64,
    "question": "What is a 'Hot Row' or 'Hot Key' problem in NoSQL databases?",
    "options": [
      "When a row is deleted prematurely due to TTL",
      "When a specific key receives a disproportionately high volume of read or write traffic, overwhelming a single node",
      "When data is stored in a row-major format",
      "When encryption keys are rotated too frequently"
    ],
    "answer": "When a specific key receives a disproportionately high volume of read or write traffic, overwhelming a single node",
    "explanation": "Hot Spots occur when a specific partition key is accessed much more frequently than others. This overloads the single node holding that partition, creating a bottleneck.",
    "difficulty": "Intermediate"
  },
  {
    "id": 65,
    "question": "Which component acts as an intermediary that aggregates responses from multiple microservices into a single response for the client?",
    "options": [
      "The Load Balancer",
      "The API Gateway",
      "The DNS Server",
      "The Circuit Breaker"
    ],
    "answer": "The API Gateway",
    "explanation": "API Gateways often handle 'backend for frontend' (BFF) logic, aggregating calls to various underlying services into a single, optimized response payload for the client.",
    "difficulty": "Intermediate"
  },
  {
    "id": 66,
    "question": "What is the 'N+1 Select Problem' in ORM (Object-Relational Mapping)?",
    "options": [
      "Executing N queries to fetch a list and then N additional queries to fetch related items for each record",
      "Trying to insert 1 record into N different tables simultaneously",
      "Having N replicas but only 1 master node",
      "Selecting the wrong database driver for N connections"
    ],
    "answer": "Executing N queries to fetch a list and then N additional queries to fetch related items for each record",
    "explanation": "The N+1 problem occurs when an ORM lazy-loads relationships. Fetching N parents triggers 1 query for the parents and N queries for their children, leading to severe performance degradation.",
    "difficulty": "Intermediate"
  },
  {
    "id": 67,
    "question": "In a distributed system, what is 'Quorum' in the context of data replication?",
    "options": [
      "A specific database version",
      "The minimum number of nodes that must acknowledge a write operation to consider it successful",
      "The maximum time a node can be offline",
      "A type of consensus algorithm"
    ],
    "answer": "The minimum number of nodes that must acknowledge a write operation to consider it successful",
    "explanation": "Quorum (typically R + W > N) ensures consistency. It defines the minimum number of replicas (W) that must confirm a write for the system to acknowledge the transaction to the client.",
    "difficulty": "Intermediate"
  },
  {
    "id": 68,
    "question": "What is the primary difference between 'Throughput' and 'Latency'?",
    "options": [
      "Throughput is the time taken to process a request; Latency is the number of requests per second",
      "Throughput is the amount of data processed per unit time; Latency is the time taken for a specific unit of data to travel",
      "Throughput applies to hardware; Latency applies to software",
      "There is no difference; they are synonyms"
    ],
    "answer": "Throughput is the amount of data processed per unit time; Latency is the time taken for a specific unit of data to travel",
    "explanation": "Latency measures the delay (time) for a single operation (e.g., milliseconds per request). Throughput measures the volume of work over time (e.g., requests per second).",
    "difficulty": "Intermediate"
  },
  {
    "id": 69,
    "question": "Which technique helps to mitigate the 'Thundering Herd' problem when a large number of processes or threads wake up simultaneously to handle an event?",
    "options": [
      "Increasing the size of the cache",
      "Using a 'lease' or 'lock' to allow only one worker to regenerate the expired cache entry",
      "Turning off all but one server",
      "Using synchronous I/O instead of asynchronous I/O"
    ],
    "answer": "Using a 'lease' or 'lock' to allow only one worker to regenerate the expired cache entry",
    "explanation": "The Thundering Herd occurs when a cache stampede triggers a storm of requests to the backend. A distributed lock or cache lease ensures only one client rebuilds the value while others wait.",
    "difficulty": "Intermediate"
  },
  {
    "id": 70,
    "question": "What is 'SSTable' (Sorted String Table) in the context of storage engines like LevelDB or RocksDB?",
    "options": [
      "A type of SQL query",
      "An immutable, sorted file structure used for persisting key-value pairs on disk",
      "A dynamic data structure stored in memory",
      "A network protocol for database replication"
    ],
    "answer": "An immutable, sorted file structure used for persisting key-value pairs on disk",
    "explanation": "SSTables provide efficient writes by buffering in memory (MemTable) and flushing sorted, immutable files to disk. This format enables fast key lookups via binary search and efficient compaction.",
    "difficulty": "Intermediate"
  },
  {
    "id": 71,
    "question": "In the context of the CAP theorem, why is it often impossible to guarantee perfect Consistency and Availability simultaneously during a network Partition (P)?",
    "options": [
      "The partition prevents nodes from communicating, forcing a choice between rejecting requests to preserve consistency or accepting stale data to maintain availability",
      "Databases are limited by the ACID properties which prevent concurrent writes during a partition",
      "Network latency increases exponentially during a partition, causing timeouts for both reads and writes",
      "The load balancer cannot route traffic to the correct shard when the network is partitioned"
    ],
    "answer": "The partition prevents nodes from communicating, forcing a choice between rejecting requests to preserve consistency or accepting stale data to maintain availability",
    "explanation": "During a partition, a CP system stops processing writes/reads to prevent divergence, while an AP system continues processing despite potential inconsistency.",
    "difficulty": "Advanced"
  },
  {
    "id": 72,
    "question": "What is the primary advantage of using Consistent Hashing in a distributed cache cluster over simple modulo hashing (hash(key) % N)?",
    "options": [
      "It minimizes the number of keys remapped when nodes are added or removed from the cluster",
      "It guarantees an equal distribution of keys across all nodes regardless of key space",
      "It eliminates the need for data replication across the cluster",
      "It reduces the computational overhead of calculating the hash value"
    ],
    "answer": "It minimizes the number of keys remapped when nodes are added or removed from the cluster",
    "explanation": "Consistent hashing maps both data and nodes to a ring, ensuring that only adjacent data is affected when a node joins or leaves, unlike modulo hashing which disrupts the entire cache.",
    "difficulty": "Advanced"
  },
  {
    "id": 73,
    "question": "How does the 'Leaky Bucket' algorithm differ from the 'Fixed Window' algorithm when enforcing API rate limits?",
    "options": [
      "Leaky Bucket smooths out burst traffic by processing requests at a constant rate, while Fixed Window allows bursts at the edge of the window",
      "Leaky Bucket allows unlimited requests as long as the average rate is low, while Fixed Window strictly enforces a hard count",
      "Leaky Bucket requires a distributed locking mechanism, whereas Fixed Window is stateless",
      "Leaky Bucket is only applicable for ingress traffic, while Fixed Window is for egress traffic"
    ],
    "answer": "Leaky Bucket smooths out burst traffic by processing requests at a constant rate, while Fixed Window allows bursts at the edge of the window",
    "explanation": "The Leaky Bucket uses a queue (bucket) to process requests at a fixed rate, whereas Fixed Window resets the count at specific intervals, allowing a burst of requests immediately after the reset.",
    "difficulty": "Advanced"
  },
  {
    "id": 74,
    "question": "In a database system using Log-Structured Merge-trees (LSM trees), why is write performance generally superior to B-Trees for heavy workloads?",
    "options": [
      "LSM trees turn random write operations into sequential writes by buffering data in memory (MemTable)",
      "LSM trees store data in a B-Tree structure on disk to optimize for random I/O",
      "LSM trees avoid writing to disk entirely by keeping all data in RAM",
      "LSM trees do not require write-ahead logging (WAL) for data integrity"
    ],
    "answer": "LSM trees turn random write operations into sequential writes by buffering data in memory (MemTable)",
    "explanation": "LSM trees buffer writes in memory and periodically flush them as sorted immutable files (SSTables) to disk, avoiding the costly random disk I/O inherent in updating B-Trees.",
    "difficulty": "Advanced"
  },
  {
    "id": 75,
    "question": "What is the specific function of the 'Chandy-Lamport' algorithm in distributed systems?",
    "options": [
      "To record a consistent global snapshot of the system's distributed state",
      "To detect network partitions between nodes in a cluster",
      "To elect a new leader node after a failure occurs",
      "To replicate data across multiple data centers synchronously"
    ],
    "answer": "To record a consistent global snapshot of the system's distributed state",
    "explanation": "The Chandy-Lamport algorithm uses markers to determine the state of channels and processes, allowing the system to capture a consistent snapshot for checkpointing or restart.",
    "difficulty": "Advanced"
  },
  {
    "id": 76,
    "question": "When implementing 'Read-After-Write' consistency in a leader-follower replication model, how is this consistency guarantee typically achieved for a specific user?",
    "options": [
      "Routing the user's read requests to the leader (or a recent follower) for a duration after a write",
      "Enabling synchronous replication to all followers before acknowledging the write",
      "Forcing the client to wait for a global acknowledgment before reading",
      "Using a distributed transaction lock for every read operation"
    ],
    "answer": "Routing the user's read requests to the leader (or a recent follower) for a duration after a write",
    "explanation": "To ensure the user sees their own writes, the system directs their read traffic to the source of truth (Leader) to prevent serving stale data from a lagging replica.",
    "difficulty": "Advanced"
  },
  {
    "id": 77,
    "question": "In a microservices architecture, what is the primary role of a 'Service Mesh' (e.g., Istio, Linkerd)?",
    "options": [
      "To manage service-to-service communication, including observability, traffic management, and security, without changing application code",
      "To act as an API Gateway for external client traffic entering the system",
      "To provide a database abstraction layer for polyglot persistence",
      "To containerize and orchestrate the deployment of microservices"
    ],
    "answer": "To manage service-to-service communication, including observability, traffic management, and security, without changing application code",
    "explanation": "A Service Mesh uses sidecar proxies to abstract network complexity, providing mTLS, retries, and circuit breaking for inter-service traffic transparent to the application logic.",
    "difficulty": "Advanced"
  },
  {
    "id": 78,
    "question": "What is the 'Split-Brain' problem in distributed high-availability clusters?",
    "options": [
      "A network partition causes two subsets of nodes to believe they are the active leader, leading to data divergence",
      "The database shard becomes too large and splits into two separate partitions",
      "The write-ahead log fills up the disk, causing the database to crash",
      "Two clients attempt to update the same record simultaneously without locking"
    ],
    "answer": "A network partition causes two subsets of nodes to believe they are the active leader, leading to data divergence",
    "explanation": "Split-Brain occurs when the quorum is split by a network fault, allowing multiple leaders to process writes independently, creating conflicting data sets that are hard to reconcile.",
    "difficulty": "Advanced"
  },
  {
    "id": 79,
    "question": "Why is the 'Two-Phase Commit' (2PC) protocol considered a blocking protocol?",
    "options": [
      "If the coordinator node fails after the prepare phase, participants cannot commit or abort until the coordinator recovers",
      "It requires all database nodes to lock their entire transaction table during the commit",
      "It forces the system to stop processing any reads during the write transaction",
      "It relies on a synchronous network communication which blocks the CPU"
    ],
    "answer": "If the coordinator node fails after the prepare phase, participants cannot commit or abort until the coordinator recovers",
    "explanation": "In phase 2, if the coordinator fails, participants holding locks are in an uncertain state and must wait for the coordinator to return, blocking resources and halting progress.",
    "difficulty": "Advanced"
  },
  {
    "id": 80,
    "question": "In Apache Kafka, what is the purpose of a 'Consumer Group'?",
    "options": [
      "To allow multiple consumers to divide the work of processing partitions of a topic in parallel",
      "To group producers to ensure their messages are written to the same partition",
      "To encrypt data between the broker and the consumer",
      "To replicate topics across different data centers"
    ],
    "answer": "To allow multiple consumers to divide the work of processing partitions of a topic in parallel",
    "explanation": "Kafka ensures that each partition in a topic is consumed by only one consumer within a specific group, enabling scalable parallel processing while maintaining message order per partition.",
    "difficulty": "Advanced"
  },
  {
    "id": 81,
    "question": "What is the primary trade-off when using the 'Cache-Aside' (Lazy Loading) pattern compared to 'Write-Through'?",
    "options": [
      "Cache-Aside suffers from stale data if the database is updated directly, while Write-Through keeps cache and DB in sync",
      "Cache-Aside is slower for reads than Write-Through",
      "Cache-Aside requires a larger cache size than Write-Through",
      "Cache-Aside cannot handle miss penalties, whereas Write-Through can"
    ],
    "answer": "Cache-Aside suffers from stale data if the database is updated directly, while Write-Through keeps cache and DB in sync",
    "explanation": "In Cache-Aside, the application writes to the DB; the cache is not updated, leading to staleness. Write-Through writes to cache and DB synchronously, ensuring consistency at the cost of higher write latency.",
    "difficulty": "Advanced"
  },
  {
    "id": 82,
    "question": "What is the 'Write Skew' anomaly in the context of database isolation levels?",
    "options": [
      "Two transactions read overlapping data sets and concurrently make disjoint updates that violate a constraint when combined",
      "A transaction reads uncommitted data from a concurrent transaction",
      "A transaction re-reads data it has previously read and finds the data has been modified by another transaction",
      "The database performs a rolling update on disk sectors while a transaction is reading"
    ],
    "answer": "Two transactions read overlapping data sets and concurrently make disjoint updates that violate a constraint when combined",
    "explanation": "Write Skew occurs in Snapshot Isolation where two transactions read the same consistent snapshot but modify disjoint sets based on that read, resulting in an invalid final state (e.g., two on-call doctors both resigning simultaneously).",
    "difficulty": "Advanced"
  },
  {
    "id": 83,
    "question": "How does a 'Bloom Filter' optimize read operations in a distributed key-value store like Cassandra or HBase?",
    "options": [
      "It rapidly checks if an element is definitely not in a set, avoiding unnecessary disk I/O for non-existent keys",
      "It compresses the data before writing to disk to save space",
      "It indexes the values to allow for faster range scans",
      "It encrypts the keys to ensure data security at rest"
    ],
    "answer": "It rapidly checks if an element is definitely not in a set, avoiding unnecessary disk I/O for non-existent keys",
    "explanation": "Bloom Filters are probabilistic data structures that can negatively answer existence queries with 100% certainty, preventing expensive disk lookups for keys that do not exist.",
    "difficulty": "Advanced"
  },
  {
    "id": 84,
    "question": "What is the 'Sidecar' pattern in containerized microservices architecture?",
    "options": [
      "Deploying a utility container alongside the main application container to abstract networking or monitoring concerns",
      "Running multiple application instances in a single pod to share resources",
      "Using a legacy database alongside a new microservice during migration",
      "Routing traffic from a public API to a private internal service"
    ],
    "answer": "Deploying a utility container alongside the main application container to abstract networking or monitoring concerns",
    "explanation": "The Sidecar pattern extends the functionality of a container without changing the main application logic, often used for proxies, log shippers, or monitoring agents.",
    "difficulty": "Advanced"
  },
  {
    "id": 85,
    "question": "In the context of system design, what does the 'Quorum' strategy (W + R > N) ensure?",
    "options": [
      "Strong consistency by ensuring read and write sets overlap in a replicated system",
      "High availability during network partitions",
      "Low latency for read operations by reading from the nearest node",
      "Data durability by replicating to every node in the cluster"
    ],
    "answer": "Strong consistency by ensuring read and write sets overlap in a replicated system",
    "explanation": "By ensuring the number of Replicas written to (W) plus the number of Replicas read from (R) exceeds the total Replicas (N), the system guarantees that the latest version is retrieved.",
    "difficulty": "Advanced"
  },
  {
    "id": 86,
    "question": "When using a 'Circuit Breaker' pattern, what is the purpose of the 'Half-Open' state?",
    "options": [
      "To allow a limited number of test requests to determine if the downstream service has recovered",
      "To route all traffic to a fallback service permanently",
      "To keep the circuit closed for a fixed timeout period",
      "To drop all incoming requests to protect the system from overload"
    ],
    "answer": "To allow a limited number of test requests to determine if the downstream service has recovered",
    "explanation": "The Half-Open state transitions from Open; if the health check succeeds, it closes (normal traffic), otherwise it re-opens. This prevents overwhelming a recovering service.",
    "difficulty": "Advanced"
  },
  {
    "id": 87,
    "question": "Why are Vector Clocks used in distributed systems (e.g., Dynamo) instead of Lamport Timestamps?",
    "options": [
      "Vector Clocks can detect concurrent updates (causality) that do not have a total ordering",
      "Vector Clocks guarantee strict ACID compliance",
      "Vector Clocks are physically smaller than Lamport Timestamps",
      "Vector Clocks rely on a centralized clock server to order events"
    ],
    "answer": "Vector Clocks can detect concurrent updates (causality) that do not have a total ordering",
    "explanation": "Lamport Timestamps provide a total order but cannot distinguish if two events happened concurrently or causally. Vector Clocks track causality per node to detect conflicts.",
    "difficulty": "Advanced"
  },
  {
    "id": 88,
    "question": "In the context of CDN (Content Delivery Networks), what is the 'Origin Shield'?",
    "options": [
      "A middle layer of caching between the edge nodes and the origin server to reduce load on the origin",
      "A firewall protecting the origin database from SQL injection",
      "A specific protocol used for secure data transmission",
      "A load balancing algorithm used at the edge"
    ],
    "answer": "A middle layer of caching between the edge nodes and the origin server to reduce load on the origin",
    "explanation": "The Origin Shield aggregates requests from edge nodes, acting as a regional cache to prevent thousands of edge servers from simultaneously hitting the origin on a cache miss.",
    "difficulty": "Advanced"
  },
  {
    "id": 89,
    "question": "What is a 'Hotspot' problem in NoSQL databases (like Cassandra or HBase) when using a poorly chosen partition key?",
    "options": [
      "A disproportionate amount of traffic and data is directed to a single node, overloading it",
      "The database catches fire due to electrical overload",
      "Data expires too quickly from the cache",
      "The replication process slows down the entire cluster"
    ],
    "answer": "A disproportionate amount of traffic and data is directed to a single node, overloading it",
    "explanation": "If a partition key has low cardinality or high popularity (e.g., partitioning by 'Country' when 90% of users are in one country), all requests hit one shard/partition, creating a hotspot.",
    "difficulty": "Advanced"
  },
  {
    "id": 90,
    "question": "What is the fundamental difference between 'ACID' and 'BASE' transaction models?",
    "options": [
      "ACID prioritizes strict consistency and isolation, while BASE prioritizes availability and high availability (eventual consistency)",
      "ACID is used for SQL databases, while BASE is used for NoSQL file systems",
      "ACID allows data loss, while BASE guarantees no data loss",
      "BASE uses two-phase commits while ACID uses one-phase"
    ],
    "answer": "ACID prioritizes strict consistency and isolation, while BASE prioritizes availability and high availability (eventual consistency)",
    "explanation": "BASE (Basically Available, Soft state, Eventually consistent) trades strong consistency for the sake of high availability and partition tolerance, whereas ACID enforces strict constraints.",
    "difficulty": "Advanced"
  },
  {
    "id": 91,
    "question": "How does the 'Virtual Node' (VNode) concept improve consistent hashing in distributed systems?",
    "options": [
      "It ensures a more even distribution of data and easier rebalancing when nodes are added or removed",
      "It encrypts the data hash for security purposes",
      "It reduces the network latency between the client and the server",
      "It allows for simultaneous reads from multiple partitions"
    ],
    "answer": "It ensures a more even distribution of data and easier rebalancing when nodes are added or removed",
    "explanation": "Instead of a single token per node, each physical node holds multiple tokens (Virtual Nodes), scattering the data across the ring and reducing the impact of node changes.",
    "difficulty": "Advanced"
  },
  {
    "id": 92,
    "question": "What is the 'Thundering Herd' problem when restarting a web server or expired cache?",
    "options": [
      "A sudden spike in requests hits the origin/database because many processes/clients are unblocked simultaneously",
      "A distributed denial of service attack overwhelms the network",
      "The load balancer crashes due to a configuration error",
      "The database runs out of connection pool memory"
    ],
    "answer": "A sudden spike in requests hits the origin/database because many processes/clients are unblocked simultaneously",
    "explanation": "When a resource becomes available (e.g., cache expiry or server restart), many waiting clients/threads rush to access it simultaneously, potentially crashing the backend.",
    "difficulty": "Advanced"
  },
  {
    "id": 93,
    "question": "In the Raft consensus algorithm, how does a node become the Leader?",
    "options": [
      "It receives votes from a majority of nodes in the cluster during an election",
      "It has the lowest latency connection to the client",
      "It is designated as the leader in the configuration file",
      "It is the node with the highest process ID"
    ],
    "answer": "It receives votes from a majority of nodes in the cluster during an election",
    "explanation": "Raft uses an election mechanism where candidates request votes; the first candidate to receive a majority of votes becomes the leader and ensures log consistency.",
    "difficulty": "Advanced"
  },
  {
    "id": 94,
    "question": "Why is 'Exponential Backoff with Jitter' used in retry mechanisms for distributed systems?",
    "options": [
      "To prevent retry storms by spreading out the retry attempts of colliding clients",
      "To increase the speed of data transfer",
      "To ensure that the message is delivered exactly once",
      "To reduce the memory footprint of the application"
    ],
    "answer": "To prevent retry storms by spreading out the retry attempts of colliding clients",
    "explanation": "Jitter (randomness) added to the exponential backoff interval ensures that clients retry at different times, preventing synchronized collisions that could overwhelm a recovering service.",
    "difficulty": "Advanced"
  },
  {
    "id": 95,
    "question": "What is the primary purpose of the 'Saga' pattern in microservices architecture?",
    "options": [
      "To manage data consistency across multiple services without using distributed locks or two-phase commit",
      "To encrypt data as it travels between services",
      "To serialize Java objects into JSON for transport",
      "To balance the load between stateless services"
    ],
    "answer": "To manage data consistency across multiple services without using distributed locks or two-phase commit",
    "explanation": "A Saga is a sequence of local transactions where each transaction updates data within a single service and publishes an event/message to trigger the next step, using compensating transactions on failure.",
    "difficulty": "Advanced"
  },
  {
    "id": 96,
    "question": "What is the main benefit of using 'gRPC' over REST for internal microservice communication?",
    "options": [
      "It uses HTTP/2 and Protocol Buffers to provide lower latency and smaller message payloads",
      "It supports human-readable text-based data transfer",
      "It natively integrates with web browsers",
      "It does not require a schema definition"
    ],
    "answer": "It uses HTTP/2 and Protocol Buffers to provide lower latency and smaller message payloads",
    "explanation": "gRPC leverages Protocol Buffers (binary serialization) and HTTP/2 (multiplexing) for efficient, high-performance communication compared to the text-based JSON and HTTP/1.1 often used in REST.",
    "difficulty": "Advanced"
  },
  {
    "id": 97,
    "question": "What distinguishes a 'Forward Proxy' from a 'Reverse Proxy'?",
    "options": [
      "A Forward Proxy acts on behalf of the client to access resources, while a Reverse Proxy acts on behalf of the server to handle client requests",
      "A Forward Proxy balances traffic, while a Reverse Proxy filters traffic",
      "A Forward Proxy is used for internal services, while a Reverse Proxy is for external users",
      "There is no technical difference, only the naming convention differs"
    ],
    "answer": "A Forward Proxy acts on behalf of the client to access resources, while a Reverse Proxy acts on behalf of the server to handle client requests",
    "explanation": "Forward Proxies hide client identity (e.g., corporate VPN), whereas Reverse Proxies hide server identity and provide load balancing, security, and caching for backend servers.",
    "difficulty": "Advanced"
  },
  {
    "id": 98,
    "question": "What is the 'Phi Accrual Failure Detector' used in systems like Akka or Cassandra?",
    "options": [
      "To adaptively detect node failures based on a dynamic interpretation of network conditions, rather than a fixed timeout",
      "To detect data corruption in the commit log",
      "To calculate the availability percentage of the service",
      "To balance the read/write load based on CPU usage"
    ],
    "answer": "To adaptively detect node failures based on a dynamic interpretation of network conditions, rather than a fixed timeout",
    "explanation": "Unlike static 'heartbeat timeout' detectors, Phi Accrual interprets the heartbeat history to calculate a suspicion level (phi), allowing the system to handle fluctuating network latency more reliably.",
    "difficulty": "Advanced"
  },
  {
    "id": 99,
    "question": "In the context of storage systems, what is the 'Write Amplification' factor?",
    "options": [
      "The ratio of actual data written to physical storage versus the logical data requested to be written",
      "The number of copies of data replicated across the cluster",
      "The increase in database size when indexes are created",
      "The speed of the write operation compared to the read operation"
    ],
    "answer": "The ratio of actual data written to physical storage versus the logical data requested to be written",
    "explanation": "Write amplification occurs when the storage mechanism (e.g., SSD garbage collection, database compaction) writes more bytes than strictly necessary, wearing out hardware and reducing performance.",
    "difficulty": "Advanced"
  }
]