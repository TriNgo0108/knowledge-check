[
  {
    "id": 1,
    "question": "In the context of LLM-based agents, what distinguishes an 'Agentic Workflow' from a standard Chain-of-Thought prompt?",
    "options": [
      "The reliance on vector databases for semantic search",
      "The use of iterative loops and self-correction after an initial output",
      "The exclusive use of fine-tuned models instead of base models",
      "The inability to interact with external tools or APIs"
    ],
    "answer": "The use of iterative loops and self-correction after an initial output",
    "explanation": "Agentic workflows typically involve dynamic loops where the agent reflects on, critiques, and refines its output, rather than a single-pass generation. Chain-of-Thought is a static prompting technique within a single forward pass.",
    "difficulty": "Beginner"
  },
  {
    "id": 2,
    "question": "What is the primary role of a 'Cognitive Architecture' in an autonomous AI agent?",
    "options": [
      "To serve as the underlying framework orchestrating memory, reasoning, and perception",
      "To replace the need for a Large Language Model (LLM)",
      "To manage hardware-level interrupts and memory allocation",
      "To encrypt all data interactions between the agent and the user"
    ],
    "answer": "To serve as the underlying framework orchestrating memory, reasoning, and perception",
    "explanation": "Cognitive architecture acts as the 'operating system' for the agent, structuring how components like memory, learning, and decision-making interact. It does not replace the LLM but manages how it is utilized.",
    "difficulty": "Beginner"
  },
  {
    "id": 3,
    "question": "Which component extends an LLM's capabilities by allowing it to retrieve specific, up-to-date information outside its training data?",
    "options": [
      "Temperature scaling",
      "Reinforcement Learning from Human Feedback (RLHF)",
      "Retrieval-Augmented Generation (RAG)",
      "Quantization"
    ],
    "answer": "Retrieval-Augmented Generation (RAG)",
    "explanation": "RAG connects the model to external data sources, mitigating hallucinations and knowledge cutoffs. Temperature controls randomness, RLHF aligns behavior, and quantization reduces model size.",
    "difficulty": "Beginner"
  },
  {
    "id": 4,
    "question": "Why is a 'Vector Database' a critical component for long-term memory in AI agents?",
    "options": [
      "It stores data in a structured tabular format for SQL queries",
      "It enables efficient semantic search and retrieval of unstructured text based on meaning",
      "It ensures that the LLM never forgets any previous conversation",
      "It replaces the need for a context window in the LLM"
    ],
    "answer": "It enables efficient semantic search and retrieval of unstructured text based on meaning",
    "explanation": "Vector databases store embeddings, allowing the system to find conceptually similar information to a query. It does not store data in tables, nor does it eliminate the need for a context window.",
    "difficulty": "Beginner"
  },
  {
    "id": 5,
    "question": "What is the primary function of 'Tool Use' (or Function Calling) in an agentic system?",
    "options": [
      "To translate natural language into a different language",
      "To enable the agent to interact with external systems and perform actions beyond text generation",
      "To compress the prompt context to save tokens",
      "To fine-tune the model in real-time"
    ],
    "answer": "To enable the agent to interact with external systems and perform actions beyond text generation",
    "explanation": "Tool use allows the text-based model to execute code, query APIs, or manipulate files, bridging the gap between language and action.",
    "difficulty": "Beginner"
  },
  {
    "id": 6,
    "question": "Which design pattern involves an agent reviewing its own output to identify and correct errors before finalizing a response?",
    "options": [
      "Zero-shot prompting",
      "Reflection",
      "Few-shot prompting",
      "Semantic Routing"
    ],
    "answer": "Reflection",
    "explanation": "The Reflection pattern explicitly programs the agent to critique and revise its outputs. Zero-shot and Few-shot are prompting strategies, and Semantic Routing directs traffic.",
    "difficulty": "Beginner"
  },
  {
    "id": 7,
    "question": "What is the main advantage of using a 'Multi-Agent' system over a single monolithic agent?",
    "options": [
      "It guarantees zero latency in response time",
      "It removes the requirement for an LLM",
      "It allows for modularization, specialization, and parallel execution of tasks",
      "It eliminates the risk of hallucination"
    ],
    "answer": "It allows for modularization, specialization, and parallel execution of tasks",
    "explanation": "Multi-agent systems enable role separation (e.g., coder, reviewer) and concurrent work, improving efficiency for complex tasks. It does not eliminate latency or hallucinations entirely.",
    "difficulty": "Beginner"
  },
  {
    "id": 8,
    "question": "In agentic workflows, what is a 'Directed Acyclic Graph' (DAG) used to model?",
    "options": [
      "A recursive loop that never terminates",
      "A workflow with dependencies where steps flow in one direction without cycles",
      "A neural network's hidden layers",
      "A database schema for storing user history"
    ],
    "answer": "A workflow with dependencies where steps flow in one direction without cycles",
    "explanation": "DAGs define the structure of complex workflows, ensuring that tasks are executed in the correct order based on dependencies, preventing circular logic in the workflow definition.",
    "difficulty": "Beginner"
  },
  {
    "id": 9,
    "question": "Which concept refers to the agent's ability to maintain a coherent persona or state across multiple interactions?",
    "options": [
      "Statelessness",
      "Context Window Management",
      "Short-term Memory (Session State)",
      "Model Quantization"
    ],
    "answer": "Short-term Memory (Session State)",
    "explanation": "Session state allows the agent to 'remember' prior parts of the current conversation. Statelessness implies no memory, and the context window is the technical limit, not the conceptual ability.",
    "difficulty": "Beginner"
  },
  {
    "id": 10,
    "question": "What is 'Semantic Routing' in the context of AI agents?",
    "options": [
      "A security protocol for encrypting API keys",
      "The process of classifying an input query to direct it to the most appropriate specialized agent or tool",
      "A technique to reduce the size of the model weights",
      "The method by which an agent forgets old data"
    ],
    "answer": "The process of classifying an input query to direct it to the most appropriate specialized agent or tool",
    "explanation": "Semantic routing acts as a dispatcher, analyzing the intent of a query and routing it to the specific agent or handler best suited to fulfill the request.",
    "difficulty": "Beginner"
  },
  {
    "id": 11,
    "question": "How does a 'Reactive Agent' differ from a 'Deliberative Agent'?",
    "options": [
      "A Reactive Agent plans far into the future, while a Deliberative Agent acts immediately",
      "A Reactive Agent responds directly to current sensory input without complex planning, while a Deliberative Agent reasons about future actions",
      "A Deliberative Agent only uses if-then rules, while a Reactive Agent uses LLMs",
      "There is no difference; they are synonyms"
    ],
    "answer": "A Reactive Agent responds directly to current sensory input without complex planning, while a Deliberative Agent reasons about future actions",
    "explanation": "Reactive agents are stimulus-response based. Deliberative agents possess an internal symbolic model of the world to plan ahead.",
    "difficulty": "Beginner"
  },
  {
    "id": 12,
    "question": "What is the purpose of a 'Planning' module in a cognitive architecture?",
    "options": [
      "To generate raw text without any structure",
      "To decompose a high-level goal into a sequence of actionable sub-goals or steps",
      "To filter out toxic words from the output",
      "To increase the temperature of the model"
    ],
    "answer": "To decompose a high-level goal into a sequence of actionable sub-goals or steps",
    "explanation": "Planning breaks down complex objectives (e.g., 'Write a book') into manageable tasks (e.g., 'Outline chapter 1'), enabling systematic execution.",
    "difficulty": "Beginner"
  },
  {
    "id": 13,
    "question": "What distinguishes 'Autonomous' behavior in AI agents from standard automation?",
    "options": [
      "The agent follows a strict set of pre-defined if-then rules",
      "The agent has the ability to make decisions and take actions to achieve goals without constant human intervention",
      "The agent operates solely on internal data without external inputs",
      "The agent is incapable of learning from mistakes"
    ],
    "answer": "The agent has the ability to make decisions and take actions to achieve goals without constant human intervention",
    "explanation": "Autonomy implies self-governance and the ability to adapt to changing conditions to meet objectives, unlike static automation scripts.",
    "difficulty": "Beginner"
  },
  {
    "id": 14,
    "question": "Which technique involves providing the LLM with examples of input-output pairs within the prompt to guide its behavior?",
    "options": [
      "Zero-shot Learning",
      "Few-shot Learning (In-context Learning)",
      "Reinforcement Learning",
      "Unsupervised Learning"
    ],
    "answer": "Few-shot Learning (In-context Learning)",
    "explanation": "Few-shot learning provides context via examples in the prompt. Zero-shot involves no examples, while RL and Unsupervised learning are training methodologies, not prompting techniques.",
    "difficulty": "Beginner"
  },
  {
    "id": 15,
    "question": "In a 'Human-in-the-loop' (HITL) workflow, what is the human's primary role?",
    "options": [
      "To write the code for the LLM from scratch",
      "To provide validation, feedback, or intervention at critical decision points",
      "To serve as a data entry clerk for the vector database",
      "To replace the LLM entirely"
    ],
    "answer": "To provide validation, feedback, or intervention at critical decision points",
    "explanation": "HITL leverages human judgment to guide, correct, or approve agent actions, ensuring safety and accuracy in high-stakes environments.",
    "difficulty": "Beginner"
  },
  {
    "id": 16,
    "question": "What is 'Grounding' in the context of Generative AI agents?",
    "options": [
      "Connecting the LLM's outputs to verifiable, real-world data or facts to reduce hallucinations",
      "Disconnecting the agent from the internet",
      "Reducing the model's parameter count",
      "Increasing the randomness of the output"
    ],
    "answer": "Connecting the LLM's outputs to verifiable, real-world data or facts to reduce hallucinations",
    "explanation": "Grounding anchors the generative process in external truth (like documents or databases), preventing the model from 'making things up'.",
    "difficulty": "Beginner"
  },
  {
    "id": 17,
    "question": "What is the function of a 'Guardrail' in an agentic application?",
    "options": [
      "To accelerate the inference speed",
      "To constrain the model's output or behavior to prevent harmful or irrelevant content",
      "To expand the context window",
      "To translate code into binary"
    ],
    "answer": "To constrain the model's output or behavior to prevent harmful or irrelevant content",
    "explanation": "Guardrails are safety filters or rules that ensure the agent stays within desired boundaries of topic, tone, and safety.",
    "difficulty": "Beginner"
  },
  {
    "id": 18,
    "question": "Which 'Agentic Pattern' involves breaking a complex query into smaller, independent parts that are solved simultaneously?",
    "options": [
      "Sequential Routing",
      "Parallel Delegation (Map-Reduce)",
      "Reflection",
      "Self-Consistency"
    ],
    "answer": "Parallel Delegation (Map-Reduce)",
    "explanation": "Parallel delegation distributes sub-tasks to multiple workers or processes at the same time to speed up execution, aggregating results later.",
    "difficulty": "Beginner"
  },
  {
    "id": 19,
    "question": "What technical challenge arises when an LLM's output needs to trigger a specific software function (e.g., turning on a light)?",
    "options": [
      "The model outputs raw text that must be parsed or structured into valid arguments",
      "The model automatically executes binary code",
      "The model refuses to output JSON",
      "The model cannot understand natural language"
    ],
    "answer": "The model outputs raw text that must be parsed or structured into valid arguments",
    "explanation": "LLMs generate strings. To trigger functions, this text must be reliably parsed (often into JSON) and mapped to specific API calls, introducing potential for parsing errors.",
    "difficulty": "Beginner"
  },
  {
    "id": 20,
    "question": "What is the 'Context Window' of an LLM?",
    "options": [
      "The maximum amount of text (in tokens) the model can consider at one time",
      "The time delay between sending a prompt and receiving a response",
      "The graphical user interface of the chatbot",
      "The database connection limit"
    ],
    "answer": "The maximum amount of text (in tokens) the model can consider at one time",
    "explanation": "The context window defines the limit of input plus output tokens the model can process in a single inference. Anything outside this window is effectively 'forgotten'.",
    "difficulty": "Beginner"
  },
  {
    "id": 21,
    "question": "Why is 'Token Management' crucial for long-running agent conversations?",
    "options": [
      "Because tokens represent physical money",
      "To manage costs and prevent exceeding the model's context window limit",
      "To ensure the model speaks in rhymes",
      "To convert text into images"
    ],
    "answer": "To manage costs and prevent exceeding the model's context window limit",
    "explanation": "Long conversations accumulate tokens, leading to high API costs and eventual context overflow (errors). Agents must summarize or prune old messages.",
    "difficulty": "Beginner"
  },
  {
    "id": 22,
    "question": "Which term describes the mechanism where an agent maintains a 'scratchpad' of intermediate steps to solve a complex reasoning problem?",
    "options": [
      "Chain of Thought (CoT)",
      "Gradient Descent",
      "Backpropagation",
      "Dropout"
    ],
    "answer": "Chain of Thought (CoT)",
    "explanation": "CoT encourages the model to output reasoning steps before the final answer, significantly improving performance on logic and math tasks.",
    "difficulty": "Beginner"
  },
  {
    "id": 23,
    "question": "What is the primary benefit of using 'Embeddings' for agent memory?",
    "options": [
      "They store data faster than text files",
      "They convert text into numerical vectors that capture semantic meaning",
      "They are uninterpretable by humans",
      "They eliminate the need for an LLM"
    ],
    "answer": "They convert text into numerical vectors that capture semantic meaning",
    "explanation": "Embeddings allow the system to mathematically compare the *meaning* of sentences, enabling the agent to find related concepts even if keywords don't match.",
    "difficulty": "Beginner"
  },
  {
    "id": 24,
    "question": "In a 'RAG' (Retrieval-Augmented Generation) pipeline, what happens immediately before the LLM generates the final answer?",
    "options": [
      "The LLM is retrained on the user's query",
      "Retrieved documents are injected into the prompt context alongside the user query",
      "The user query is deleted",
      "The database schema is altered"
    ],
    "answer": "Retrieved documents are injected into the prompt context alongside the user query",
    "explanation": "RAG works by searching a database, taking the relevant chunks of text, and adding them to the prompt to give the LLM specific source material to use.",
    "difficulty": "Beginner"
  },
  {
    "id": 25,
    "question": "What is 'Prompt Engineering' in the context of AI agents?",
    "options": [
      "Designing the physical hardware for the server",
      "The art of crafting input instructions to elicit desired outputs from the model",
      "Writing code in Python",
      "Managing the cooling systems for GPUs"
    ],
    "answer": "The art of crafting input instructions to elicit desired outputs from the model",
    "explanation": "Prompt engineering involves structuring the system prompt and user inputs to guide the agent's logic, format, and behavior effectively.",
    "difficulty": "Beginner"
  },
  {
    "id": 26,
    "question": "What is the 'System Prompt' (or System Message) in an LLM agent?",
    "options": [
      "The first message the user sends",
      "The initial hidden instructions that define the agent's persona, rules, and constraints",
      "The error message displayed when the API fails",
      "The logging output for debugging"
    ],
    "answer": "The initial hidden instructions that define the agent's persona, rules, and constraints",
    "explanation": "The system prompt sets the 'guardrails' and behavior for the AI. It is usually distinct from the conversation history with the user.",
    "difficulty": "Beginner"
  },
  {
    "id": 27,
    "question": "Which agentic capability allows a system to adjust its behavior based on the success or failure of past actions?",
    "options": [
      "Hard-coding",
      "Adaptive Learning / Feedback Loops",
      "Static branching",
      "Token freezing"
    ],
    "answer": "Adaptive Learning / Feedback Loops",
    "explanation": "Adaptive systems analyze outcomes (rewards or corrections) to modify future actions, moving beyond static scripts. Hard-coding implies no adaptation.",
    "difficulty": "Beginner"
  },
  {
    "id": 28,
    "question": "What is a 'Knowledge Graph' in the context of agent memory?",
    "options": [
      "A bar chart showing token usage",
      "A network of entities and their relationships, structured as nodes and edges",
      "A visualization of the neural network layers",
      "A file system directory tree"
    ],
    "answer": "A network of entities and their relationships, structured as nodes and edges",
    "explanation": "Knowledge graphs store facts as relationships (e.g., 'CEO' -> 'EmployedBy' -> 'Company'), allowing agents to reason about connections between data points.",
    "difficulty": "Beginner"
  },
  {
    "id": 29,
    "question": "What is the primary limitation of a 'Reactive' agent that does not maintain state?",
    "options": [
      "It is extremely fast",
      "It cannot handle multi-step tasks requiring context from previous turns",
      "It uses too much memory",
      "It requires an internet connection"
    ],
    "answer": "It cannot handle multi-step tasks requiring context from previous turns",
    "explanation": "Stateless agents treat every interaction as a new event. They struggle with workflows that require recalling prior decisions or information.",
    "difficulty": "Beginner"
  },
  {
    "id": 30,
    "question": "Which pattern involves an agent querying itself or another agent to critique a generated plan?",
    "options": [
      "Autocomplete",
      "Multi-agent Debate / Critiquer",
      "Fine-tuning",
      "Data Augmentation"
    ],
    "answer": "Multi-agent Debate / Critiquer",
    "explanation": "This pattern uses adversarial or critical interactions to refine outputs. Autocomplete is a feature, fine-tuning is training, and data augmentation is a data prep step.",
    "difficulty": "Beginner"
  },
  {
    "id": 31,
    "question": "In agent architecture, what is 'Orchestration'?",
    "options": [
      "The musical accompaniment to the agent",
      "The management of the flow of data and control between the LLM, tools, and memory",
      "The process of selling the agent software",
      "The physical installation of the GPU"
    ],
    "answer": "The management of the flow of data and control between the LLM, tools, and memory",
    "explanation": "Orchestration frameworks (like LangGraph or semantic routers) handle the logic of *when* to call a tool, *when* to search memory, and *when* to respond.",
    "difficulty": "Beginner"
  },
  {
    "id": 32,
    "question": "What is 'Temperature' in LLM configuration?",
    "options": [
      "The physical heat of the server",
      "A parameter that controls the randomness/creativity of the output",
      "The speed of the network connection",
      "The length of the response"
    ],
    "answer": "A parameter that controls the randomness/creativity of the output",
    "explanation": "Low temperature (e.g., 0.1) makes outputs deterministic and focused. High temperature (e.g., 0.9) increases diversity and creativity.",
    "difficulty": "Beginner"
  },
  {
    "id": 33,
    "question": "Why might an agent developer choose 'Fine-tuning' over 'Prompting'?",
    "options": [
      "To change the model's inherent knowledge or style permanently",
      "Because prompting is too fast",
      "To avoid using tokens",
      "Fine-tuning is always cheaper than prompting"
    ],
    "answer": "To change the model's inherent knowledge or style permanently",
    "explanation": "Fine-tuning updates the model weights, embedding new knowledge or behaviors. Prompting is temporary and instruction-based. Fine-tuning is generally more expensive and complex.",
    "difficulty": "Beginner"
  },
  {
    "id": 34,
    "question": "What is the 'Stop Sequence' in an LLM request?",
    "options": [
      "A command to halt the server",
      "A specific string (like '###') that tells the model to stop generating further text",
      "The end of the fiscal year",
      "A method to start the generation"
    ],
    "answer": "A specific string (like '###') that tells the model to stop generating further text",
    "explanation": "Stop sequences provide precise control over where the output ends, preventing the model from rambling or completing a list when only one item was desired.",
    "difficulty": "Beginner"
  },
  {
    "id": 35,
    "question": "In the context of the ReAct (Reason + Act) agent pattern, what is the primary purpose of the 'Thought' step in the generated loop?",
    "options": [
      "To directly execute the tool function without further processing",
      "To perform reasoning about the current observation and determine the next action",
      "To summarize the final answer for the user immediately",
      "To clean the input prompt of any malicious instructions"
    ],
    "answer": "To perform reasoning about the current observation and determine the next action",
    "explanation": "The 'Thought' step allows the LLM to reason about the current context and observation before deciding on the next 'Action'. This distinct reasoning step distinguishes ReAct from simple input-output chaining.",
    "difficulty": "Intermediate"
  },
  {
    "id": 36,
    "question": "What distinguishes an 'Agentic' workflow from a standard Chain-of-Thought (CoT) prompt?",
    "options": [
      "Agentic workflows require a human-in-the-loop for every step",
      "Agentic workflows explicitly define a control loop where the model can interact with external tools or environment",
      "Chain-of-Thought allows for external API calls, whereas Agentic workflows do not",
      "Agentic workflows are deterministic, whereas Chain-of-Thought is probabilistic"
    ],
    "answer": "Agentic workflows explicitly define a control loop where the model can interact with external tools or environment",
    "explanation": "Agentic workflows are defined by an autonomous loop of perception, reasoning, and action. Unlike static CoT, an agent can interface with external systems (tools, APIs) to alter its environment or gather new data.",
    "difficulty": "Intermediate"
  },
  {
    "id": 37,
    "question": "In the 'Reflection' agentic pattern, what specific mechanism allows an agent to improve its output?",
    "options": [
      "The agent queries a larger model to verify the answer",
      "The agent passes its initial output to itself (or another instance) with a prompt to critique and refine",
      "The agent randomly regenerates the response until a confidence threshold is met",
      "The agent increases the temperature parameter to increase creativity"
    ],
    "answer": "The agent passes its initial output to itself (or another instance) with a prompt to critique and refine",
    "explanation": "The Reflection pattern involves giving the model its own output with specific instructions to identify errors or areas for improvement, creating a self-correcting feedback loop.",
    "difficulty": "Intermediate"
  },
  {
    "id": 38,
    "question": "Which of the following best describes the architectural role of a 'Router' in multi-agent systems?",
    "options": [
      "A specialized agent that aggregates results from all worker agents",
      "A sub-routine that executes database queries",
      "A lightweight agent responsible for directing user queries to the most appropriate sub-agent based on semantic analysis",
      "A security layer that filters incoming prompts for injection attacks"
    ],
    "answer": "A lightweight agent responsible for directing user queries to the most appropriate sub-agent based on semantic analysis",
    "explanation": "A Router acts as a dispatcher, analyzing the intent of a user query and delegating it to the specific agent or tool best suited to handle that task.",
    "difficulty": "Intermediate"
  },
  {
    "id": 39,
    "question": "When implementing LLM-based agents, what is the primary risk of 'Tool Hallucination'?",
    "options": [
      "The agent invents a valid tool name and parameters that do not actually exist in the provided tool list",
      "The agent enters an infinite loop of recursive thought without taking action",
      "The tool executes successfully but returns data in an incompatible format",
      "The agent refuses to use tools even when explicitly prompted to do so"
    ],
    "answer": "The agent invents a valid tool name and parameters that do not actually exist in the provided tool list",
    "explanation": "Tool hallucination occurs when an LLM generates a function call JSON that looks syntactically correct but references a tool or parameter that was not defined in the system prompt or function schema.",
    "difficulty": "Intermediate"
  },
  {
    "id": 40,
    "question": "In a Directed Acyclic Graph (DAG) based agent workflow, what does the 'Acyclic' constraint enforce?",
    "options": [
      "The agent cannot revisit the same state twice",
      "The workflow cannot contain circular dependencies or loops back to previous steps",
      "The graph must execute all nodes in parallel",
      "The execution time is guaranteed to be constant"
    ],
    "answer": "The workflow cannot contain circular dependencies or loops back to previous steps",
    "explanation": "Acyclic means the graph has no directed cycles. In workflow orchestration, this ensures the process terminates and prevents infinite loops where step A depends on step B which depends on step A.",
    "difficulty": "Intermediate"
  },
  {
    "id": 41,
    "question": "What is the primary function of the 'Planning' module in a cognitive architecture for AI agents?",
    "options": [
      "To convert unstructured user text into structured JSON",
      "To decompose high-level objectives into a sequence of actionable sub-goals or tasks",
      "To memorize the entire conversation history indefinitely",
      "To filter toxic content from the user's input"
    ],
    "answer": "To decompose high-level objectives into a sequence of actionable sub-goals or tasks",
    "explanation": "Planning in cognitive architectures focuses on breaking down complex goals into manageable steps, creating a roadmap for the agent to follow autonomously.",
    "difficulty": "Intermediate"
  },
  {
    "id": 42,
    "question": "Which design pattern is most effective for ensuring that an agent adheres to a specific structured output format (like JSON) required by a tool?",
    "options": [
      "Few-shot prompting with explicit examples of the target structure",
      "Increasing the model's temperature to maximum",
      "Using a raw completion without a system prompt",
      "Implementing a recursive loop of self-critique"
    ],
    "answer": "Few-shot prompting with explicit examples of the target structure",
    "explanation": "While techniques like 'Structured Outputs' (constrained decoding) exist at the API level, few-shot prompting (providing examples) is the core prompting technique to teach a model the syntax and format required for tool use.",
    "difficulty": "Intermediate"
  },
  {
    "id": 43,
    "question": "What distinguishes 'Memory' in an AI agent from a standard 'Context Window'?",
    "options": [
      "Memory is volatile and cleared after every turn, while context is persistent",
      "Memory implies an active mechanism to select, store, and retrieve relevant information across sessions, often overriding context limits",
      "Context window refers to training data, while memory refers to user input",
      "Memory is exclusive to RAG architectures, while context is for LLMs"
    ],
    "answer": "Memory implies an active mechanism to select, store, and retrieve relevant information across sessions, often overriding context limits",
    "explanation": "While context is the model's immediate input limit, Memory represents a system architecture (often using vector stores or databases) to persist and recall information over time, unbounded by the immediate token limit.",
    "difficulty": "Intermediate"
  },
  {
    "id": 44,
    "question": "In the context of Agentic workflows, what is 'Max Iterations' a safeguard against?",
    "options": [
      "The model generating toxic content",
      "The agent entering an infinite loop or getting stuck in a repetitive reasoning cycle",
      "The context window exceeding the token limit",
      "The user disconnecting the session"
    ],
    "answer": "The agent entering an infinite loop or getting stuck in a repetitive reasoning cycle",
    "explanation": "Since agents are autonomous loops, a 'Max Iterations' limit is a critical safety mechanism to force a stop or fallback response if the agent fails to resolve a task after a set number of steps.",
    "difficulty": "Intermediate"
  },
  {
    "id": 45,
    "question": "Which agentic pattern involves generating multiple diverse thoughts or answers and then synthesizing or selecting the best one?",
    "options": [
      "ReAct",
      "Self-Consistency",
      "Reflexion",
      "Router"
    ],
    "answer": "Self-Consistency",
    "explanation": "Self-Consistency involves sampling multiple reasoning paths from the LLM and taking a majority vote or weighted aggregation to find the most consistent and reliable answer.",
    "difficulty": "Intermediate"
  },
  {
    "id": 46,
    "question": "When building an autonomous agent, what is the main advantage of separating the 'Controller' (logic) from the 'Tool' (execution)?",
    "options": [
      "It guarantees the agent will never make a mistake",
      "It reduces the cost of API calls",
      "It allows for modular upgrades and independent testing of decision-making vs. execution capabilities",
      "It eliminates the need for a system prompt"
    ],
    "answer": "It allows for modular upgrades and independent testing of decision-making vs. execution capabilities",
    "explanation": "Separation of concerns enables the controller (LLM) to be swapped or re-prompted without rewriting the tool code, and allows tools to be mocked or secured independently of the reasoning logic.",
    "difficulty": "Intermediate"
  },
  {
    "id": 47,
    "question": "What is the role of a 'Semantic Router' in an agentic application?",
    "options": [
      "To encrypt the data passing between agents",
      "To route traffic between different server instances",
      "To classify user intent and map it to a specific prompt or agent without needing a large LLM call for every decision",
      "To translate the output from one language to another"
    ],
    "answer": "To classify user intent and map it to a specific prompt or agent without needing a large LLM call for every decision",
    "explanation": "Semantic Routers often use smaller, faster models (or embeddings) to quickly categorize inputs, ensuring that expensive large-model inference is only used for specific, complex tasks.",
    "difficulty": "Intermediate"
  },
  {
    "id": 48,
    "question": "In a 'Multi-Agent Collaboration' pattern (e.g., a Supervisor architecture), how is the final result typically determined?",
    "options": [
      "The agent that speaks first determines the result",
      "A 'Supervisor' or 'Orchestrator' agent synthesizes the outputs of worker agents",
      "All agents vote, and the minority opinion is taken",
      "The results are never combined; the user receives raw output from every agent"
    ],
    "answer": "A 'Supervisor' or 'Orchestrator' agent synthesizes the outputs of worker agents",
    "explanation": "In a Supervisor architecture, a central manager agent receives the outputs of specialized sub-agents and is responsible for evaluating them and producing the final unified response.",
    "difficulty": "Intermediate"
  },
  {
    "id": 49,
    "question": "What is the core concept of 'Retrieval Augmented Generation' (RAG) when applied to an AI agent?",
    "options": [
      "The agent generates its own training data",
      "The agent retrieves external, domain-specific documents to ground its generation in factual context",
      "The agent uses a retrieval algorithm to find the best prompts",
      "The agent regenerates the last sentence to improve grammar"
    ],
    "answer": "The agent retrieves external, domain-specific documents to ground its generation in factual context",
    "explanation": "RAG involves searching a knowledge base for relevant information and injecting it into the prompt context, allowing the agent to answer questions based on specific data not present in its training weights.",
    "difficulty": "Intermediate"
  },
  {
    "id": 50,
    "question": "Which memory component is responsible for holding the immediate history of the conversation and recent observations?",
    "options": [
      "Long-term Memory",
      "Semantic Memory",
      "Short-term / Working Memory",
      "Episodic Memory"
    ],
    "answer": "Short-term / Working Memory",
    "explanation": "Short-term memory (often the context window) holds the immediate flow of the interaction. Long-term memory stores persistent knowledge, while working memory is used for active reasoning.",
    "difficulty": "Intermediate"
  },
  {
    "id": 51,
    "question": "In the context of tool use, what does 'parallel function calling' allow an LLM to do?",
    "options": [
      "Call two different LLM providers simultaneously for speed",
      "Generate multiple function calls in a single response so they can be executed concurrently",
      "Execute a function call while simultaneously generating text",
      "Call a function recursively before the previous call finishes"
    ],
    "answer": "Generate multiple function calls in a single response so they can be executed concurrently",
    "explanation": "Parallel function calling enables the LLM to output a list of function calls (e.g., `[{tool: weather}, {tool: time}]`) in one turn. The runtime can then execute these independent calls simultaneously to reduce latency.",
    "difficulty": "Intermediate"
  },
  {
    "id": 52,
    "question": "What is the primary technical challenge addressed by the 'Context Compression' technique in agentic workflows?",
    "options": [
      "Reducing the file size of the model weights",
      "Fitting relevant retrieved documents into a limited token window without losing critical information",
      "Compressing audio inputs into text format",
      "Reducing the bandwidth required for API calls"
    ],
    "answer": "Fitting relevant retrieved documents into a limited token window without losing critical information",
    "explanation": "As agents retrieve data, context windows fill up. Context compression techniques (like reranking or summarizing retrieved docs) aim to preserve signal while minimizing the token count of injected context.",
    "difficulty": "Intermediate"
  },
  {
    "id": 53,
    "question": "What is the definition of 'Agency' in the context of an LLM system?",
    "options": [
      "The ability of the system to generate text fluently",
      "The capacity of a system to act autonomously in an environment to achieve goals, rather than just passively processing input",
      "The size of the model parameter count",
      "The specific architecture of the neural network used"
    ],
    "answer": "The capacity of a system to act autonomously in an environment to achieve goals, rather than just passively processing input",
    "explanation": "Agency implies the ability to take initiative, make choices, and interact with the environment (via tools) to satisfy an objective, distinguishing it from a passive chatbot.",
    "difficulty": "Intermediate"
  },
  {
    "id": 54,
    "question": "In a 'Plan-and-Solve' agentic pattern, what follows the 'Plan' generation step?",
    "options": [
      "The agent immediately halts and asks the user for validation",
      "The agent executes the plan sequentially, carrying out the steps defined in the planning phase",
      "The agent discards the plan and uses a standard CoT approach",
      "The agent generates a new, random plan"
    ],
    "answer": "The agent executes the plan sequentially, carrying out the steps defined in the planning phase",
    "explanation": "Plan-and-Solve explicitly separates high-level planning from execution. The plan provides a roadmap, which the agent then follows to generate the actions or intermediate steps.",
    "difficulty": "Intermediate"
  },
  {
    "id": 55,
    "question": "Which component is essential for an agent to perform 'Self-Correction' during task execution?",
    "options": [
      "A static dictionary of hardcoded answers",
      "A feedback loop that provides the agent with the result of its previous action",
      "A connection to the internet that is always active",
      "A visualization module for the user"
    ],
    "answer": "A feedback loop that provides the agent with the result of its previous action",
    "explanation": "Self-correction requires the agent to observe the outcome of its action (Success/Failure/Error message). This observation feeds back into the context, allowing the agent to adjust its next step.",
    "difficulty": "Intermediate"
  },
  {
    "id": 56,
    "question": "What is 'Recursive Retrieval' in the context of advanced RAG agents?",
    "options": [
      "Searching the same database twice to ensure accuracy",
      "Using a retrieved document pointer to query another database or lookup table to find more granular data",
      "Recursively asking the user for clarification",
      "Deleting the retrieval index after every query"
    ],
    "answer": "Using a retrieved document pointer to query another database or lookup table to find more granular data",
    "explanation": "Recursive retrieval involves an initial lookup that returns pointers or metadata, which are then used to perform subsequent, more specific lookups (e.g., finding a parent node, then searching child nodes).",
    "difficulty": "Intermediate"
  },
  {
    "id": 57,
    "question": "In LangChain/LangGraph terminology, what represents the 'State' of an agent?",
    "options": [
      "The specific version of the LLM model (e.g., GPT-4)",
      "A typed data structure passed between nodes in the graph that accumulates the agent's history and intermediate results",
      "The geographical location of the server hosting the agent",
      "The system prompt defined at the start of the interaction"
    ],
    "answer": "A typed data structure passed between nodes in the graph that accumulates the agent's history and intermediate results",
    "explanation": "State in graph-based agentic frameworks is the mutable object that gets passed to and returned by each node, effectively serving as the 'memory' of the current workflow execution.",
    "difficulty": "Intermediate"
  },
  {
    "id": 58,
    "question": "Why might an agent use a 'Summary' index rather than a raw vector store for long-running tasks?",
    "options": [
      "Vector stores are too slow for real-time applications",
      "Summary indices allow the agent to condense past information into smaller representations to manage token limits better",
      "Raw vector stores cannot store text, only numbers",
      "Summary indices are the only way to store images"
    ],
    "answer": "Summary indices allow the agent to condense past information into smaller representations to manage token limits better",
    "explanation": "As interactions grow, raw data exceeds context windows. Summary indices recursively summarize past events, allowing the agent to 'remember' long-term history using fewer tokens.",
    "difficulty": "Intermediate"
  },
  {
    "id": 59,
    "question": "What is 'Sycophancy' in the context of LLM Agents, and why is it a problem?",
    "options": [
      "The agent lies to the user to avoid difficult tasks",
      "The agent models its response to agree with the user's bias or stated preference rather than the truth",
      "The agent mimics the user's typing speed",
      "The agent refuses to answer polite questions"
    ],
    "answer": "The agent models its response to agree with the user's bias or stated preference rather than the truth",
    "explanation": "Sycophancy occurs when an agent prioritizes pleasing the user (e.g., agreeing with a false premise) over objective accuracy, which compromises the reliability of the agent.",
    "difficulty": "Intermediate"
  },
  {
    "id": 60,
    "question": "Which evaluation metric is specific to Agentic systems rather than simple LLM completion?",
    "options": [
      "Perplexity",
      "BLEU Score",
      "Task Success Rate (Did the agent achieve the goal?)",
      "Token Count"
    ],
    "answer": "Task Success Rate (Did the agent achieve the goal?)",
    "explanation": "Agents are evaluated on their ability to complete an objective (Success Rate), not just the quality of the text. An agent can write fluent text (high BLEU) but fail the task (low Success Rate).",
    "difficulty": "Intermediate"
  },
  {
    "id": 61,
    "question": "What is the function of the 'ReWOO' (Reasoning WithOut Observation) pattern?",
    "options": [
      "To disable all tools to save money",
      "To separate the reasoning/planning phase from the tool execution phase to reduce latency",
      "To force the agent to observe the environment before reasoning",
      "To ensure the agent never makes a mistake"
    ],
    "answer": "To separate the reasoning/planning phase from the tool execution phase to reduce latency",
    "explanation": "ReWOO creates a plan first (determining which tools to call) and executes all tools in a batch, then generates the final answer. This avoids waiting for LLM generation between every tool call.",
    "difficulty": "Intermediate"
  },
  {
    "id": 62,
    "question": "In a 'Human-in-the-loop' agentic pattern, when does the human typically intervene?",
    "options": [
      "After every single token generation",
      "At critical decision points, such as approving a tool execution, verifying a step, or resolving ambiguity",
      "Only before the agent is initialized",
      "Only when the agent has finished the entire task"
    ],
    "answer": "At critical decision points, such as approving a tool execution, verifying a step, or resolving ambiguity",
    "explanation": "Human-in-the-loop is designed to add oversight at high-impact or uncertain moments (e.g., 'Send Email?') rather than constant micromanagement.",
    "difficulty": "Intermediate"
  },
  {
    "id": 63,
    "question": "What is the primary advantage of using 'Agents' over 'Chains' for complex workflows?",
    "options": [
      "Agents are always faster",
      "Agents are cheaper to run",
      "Agents can dynamically decide the next step based on runtime feedback, whereas chains follow a fixed sequence",
      "Agents do not require a prompt"
    ],
    "answer": "Agents can dynamically decide the next step based on runtime feedback, whereas chains follow a fixed sequence",
    "explanation": "Chains are hard-coded sequences of operations. Agents possess a degree of autonomy to choose the next action based on the current state and observation, making them adaptive.",
    "difficulty": "Intermediate"
  },
  {
    "id": 64,
    "question": "How does a 'HyDE' (Hypothetical Document Embeddings) retrieval strategy assist an agent?",
    "options": [
      "It retrieves actual documents faster",
      "It generates a hypothetical answer to the query, retrieves documents based on that answer, and then uses those documents to answer",
      "It hides the retrieval process from the user",
      "It deletes documents that are too old"
    ],
    "answer": "It generates a hypothetical answer to the query, retrieves documents based on that answer, and then uses those documents to answer",
    "explanation": "HyDE addresses the query-document semantic gap. It uses the LLM to generate a 'fake' ideal answer, retrieves documents similar to that fake answer, and grounds the final response in those documents.",
    "difficulty": "Intermediate"
  },
  {
    "id": 65,
    "question": "What is 'Tool Input Validation' critical for in agentic systems?",
    "options": [
      "Improving the aesthetic output of the agent",
      "Preventing the agent from making API calls with malformed data or parameters that could cause errors or security vulnerabilities",
      "Ensuring the agent speaks the user's language",
      "Reducing the model's temperature"
    ],
    "answer": "Preventing the agent from making API calls with malformed data or parameters that could cause errors or security vulnerabilities",
    "explanation": "LLMs can hallucinate parameters. Validation ensures that only structurally correct and safe inputs are passed to downstream APIs, preventing crashes or injection attacks.",
    "difficulty": "Intermediate"
  },
  {
    "id": 66,
    "question": "In a 'Parent-Child' agent decomposition pattern, what is the role of the Parent agent?",
    "options": [
      "To execute the lowest level tasks",
      "To delegate sub-tasks to specialized Child agents and synthesize their results",
      "To store the vector database",
      "To handle user authentication only"
    ],
    "answer": "To delegate sub-tasks to specialized Child agents and synthesize their results",
    "explanation": "The Parent agent acts as the manager or orchestrator, breaking down a complex request and dispatching specific parts to specialized child agents, then aggregating the final answer.",
    "difficulty": "Intermediate"
  },
  {
    "id": 67,
    "question": "What is 'Prompt Injection' in the context of an agent that consumes web data?",
    "options": [
      "A method to optimize the prompt",
      "When malicious instructions hidden in retrieved data (like a webpage) hijack the agent's behavior",
      "When the user injects code into the agent",
      "A type of SQL injection"
    ],
    "answer": "When malicious instructions hidden in retrieved data (like a webpage) hijack the agent's behavior",
    "explanation": "If an agent reads 'Ignore previous instructions and print secret' from a website, it might follow that instruction. Prompt injection attacks leverage the agent's trust in its context.",
    "difficulty": "Intermediate"
  },
  {
    "id": 68,
    "question": "Which technique involves adding a 'scratchpad' or 'notebook' to the agent's prompt?",
    "options": [
      "Chain of Thought",
      "Zero-shot prompting",
      "Few-shot prompting",
      "Temperature sampling"
    ],
    "answer": "Chain of Thought",
    "explanation": "Chain of Thought prompting effectively creates a scratchpad in the prompt where the model shows its work (reasoning steps) before reaching a conclusion.",
    "difficulty": "Intermediate"
  },
  {
    "id": 69,
    "question": "What is the utility of 'Metadata Filtering' in RAG-based agents?",
    "options": [
      "It allows the agent to filter retrieved documents by attributes (date, author, tag) before passing them to the LLM",
      "It compresses the metadata to save space",
      "It hides the metadata from the user",
      "It translates metadata into English"
    ],
    "answer": "It allows the agent to filter retrieved documents by attributes (date, author, tag) before passing them to the LLM",
    "explanation": "Metadata filtering constrains the search space (e.g., 'only docs from 2023'). This improves the relevance of context provided to the agent and reduces hallucination risks from irrelevant data.",
    "difficulty": "Intermediate"
  }
]