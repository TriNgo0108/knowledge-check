[
  {
    "id": 1,
    "question": "Which architectural style decomposes a system into small, independent services that communicate over well-defined APIs?",
    "options": [
      "Monolithic Architecture",
      "Microservices Architecture",
      "Serverless Architecture",
      "Layered Architecture"
    ],
    "answer": "Microservices Architecture",
    "explanation": "Microservices architecture structures an application as a collection of loosely coupled, independently deployable services. Monolithic architectures bundle functionality into a single unit, while Serverless abstracts server management.",
    "difficulty": "Beginner"
  },
  {
    "id": 2,
    "question": "What is the primary difference between Vertical Scaling (Scaling Up) and Horizontal Scaling (Scaling Out)?",
    "options": [
      "Vertical Scaling adds more computers, while Horizontal Scaling adds more power to existing computers.",
      "Vertical Scaling adds more power to a single computer, while Horizontal Scaling adds more computers.",
      "Vertical Scaling is limited by cloud provider availability, while Horizontal Scaling is unlimited.",
      "Horizontal Scaling requires code changes, while Vertical Scaling is purely configuration-based."
    ],
    "answer": "Vertical Scaling adds more power to a single computer, while Horizontal Scaling adds more computers.",
    "explanation": "Vertical scaling increases the capacity of a single node (CPU/RAM), whereas horizontal scaling increases the number of nodes. Horizontal scaling generally offers better fault tolerance and upper limits.",
    "difficulty": "Beginner"
  },
  {
    "id": 3,
    "question": "In the context of distributed systems, what does the CAP theorem state is impossible to guarantee simultaneously?",
    "options": [
      "Consistency, Availability, and Partition Tolerance",
      "Concurrency, Availability, and Performance",
      "Consistency, Authentication, and Privacy",
      "Cost, Availability, and Partition Tolerance"
    ],
    "answer": "Consistency, Availability, and Partition Tolerance",
    "explanation": "The CAP theorem states a distributed data store can only provide two of three guarantees: Consistency, Availability, and Partition Tolerance. During a network partition (P), one must choose between C and A.",
    "difficulty": "Beginner"
  },
  {
    "id": 4,
    "question": "Which load balancing algorithm distributes incoming requests sequentially to each server in the pool?",
    "options": [
      "Least Connections",
      "Round Robin",
      "IP Hash",
      "Weighted Response Time"
    ],
    "answer": "Round Robin",
    "explanation": "Round Robin iterates through a list of servers in order, sending each request to the next server. Least Connections routes to the server with the fewest active requests, and IP Hash uses the client IP.",
    "difficulty": "Beginner"
  },
  {
    "id": 5,
    "question": "What is the primary function of a Reverse Proxy in a system architecture?",
    "options": [
      "To distribute static content to edge locations",
      "To forward client requests to backend servers on behalf of the client",
      "To balance traffic between different database shards",
      "To authenticate users before they reach the firewall"
    ],
    "answer": "To forward client requests to backend servers on behalf of the client",
    "explanation": "A reverse proxy sits in front of web servers, forwarding client requests to those servers. It provides security, load balancing, and acceleration, whereas a CDN distributes content.",
    "difficulty": "Beginner"
  },
  {
    "id": 6,
    "question": "Which caching strategy writes data to the cache and the persistent database simultaneously?",
    "options": [
      "Write-Through Cache",
      "Write-Back Cache",
      "Write-Around Cache",
      "Refresh-Ahead Cache"
    ],
    "answer": "Write-Through Cache",
    "explanation": "Write-Through writes data to both the cache and the backing store synchronously. Write-Back (Write-Behind) writes to the cache first and persists later, introducing a risk of data loss.",
    "difficulty": "Beginner"
  },
  {
    "id": 7,
    "question": "Which database property is defined as 'all nodes see the same data at the same time'?",
    "options": [
      "Availability",
      "Partition Tolerance",
      "Consistency",
      "Durability"
    ],
    "answer": "Consistency",
    "explanation": "In distributed systems (and CAP theorem), Consistency means every read receives the most recent write or an error. Availability ensures every request receives a response, regardless of state.",
    "difficulty": "Beginner"
  },
  {
    "id": 8,
    "question": "What is the primary advantage of using a Message Queue over direct HTTP communication for inter-service communication?",
    "options": [
      "Stronger typing",
      "Synchronous request/response pattern",
      "Decoupling and buffering of messages",
      "Faster response times"
    ],
    "answer": "Decoupling and buffering of messages",
    "explanation": "Message queues enable asynchronous processing, allowing services to operate independently and buffering requests if the consumer is slow. HTTP communication is typically synchronous and requires the receiver to be available.",
    "difficulty": "Beginner"
  },
  {
    "id": 9,
    "question": "In database terminology, what is the process of splitting a large database into smaller chunks across multiple servers called?",
    "options": [
      "Replication",
      "Sharding",
      "Partitioning",
      "Indexing"
    ],
    "answer": "Sharding",
    "explanation": "Sharding distributes a single dataset across multiple databases (horizontal scaling). Replication copies data to multiple nodes for availability, and Partitioning divides data on a single instance.",
    "difficulty": "Beginner"
  },
  {
    "id": 10,
    "question": "Which component acts as a single entry point for microservices, handling routing, composition, and authentication?",
    "options": [
      "Load Balancer",
      "API Gateway",
      "Service Mesh",
      "Message Broker"
    ],
    "answer": "API Gateway",
    "explanation": "An API Gateway is the single point of entry for all clients, handling cross-cutting concerns like routing, auth, and rate limiting. A Service Mesh handles service-to-service communication internally.",
    "difficulty": "Beginner"
  },
  {
    "id": 11,
    "question": "What is the main trade-off when using a SQL (Relational) database compared to a NoSQL database?",
    "options": [
      "SQL databases offer horizontal scaling at the cost of complex schemas.",
      "SQL databases offer ACID transactions and rigid schemas, while NoSQL offers flexibility and horizontal scaling.",
      "SQL databases are eventually consistent, while NoSQL databases are strongly consistent.",
      "SQL databases cannot handle joins, whereas NoSQL databases optimize them."
    ],
    "answer": "SQL databases offer ACID transactions and rigid schemas, while NoSQL offers flexibility and horizontal scaling.",
    "explanation": "SQL databases prioritize data integrity (ACID) and structure (schemas), making scaling vertically common. NoSQL prioritizes availability, flexible schemas, and horizontal scaling.",
    "difficulty": "Beginner"
  },
  {
    "id": 12,
    "question": "Which mechanism is used to prevent a single client from overwhelming an API server with too many requests?",
    "options": [
      "Throttling or Rate Limiting",
      "Circuit Breaking",
      "Input Sanitization",
      "Database Indexing"
    ],
    "answer": "Throttling or Rate Limiting",
    "explanation": "Rate limiting restricts the number of requests a user can make in a timeframe. Circuit breaking prevents an application from trying an operation that is likely to fail (downstream dependency).",
    "difficulty": "Beginner"
  },
  {
    "id": 13,
    "question": "What distinguishes a 'Stateless' service from a 'Stateful' one?",
    "options": [
      "A stateless service stores user session data in a database.",
      "A stateless service does not retain client context between requests.",
      "A stateful service cannot be scaled horizontally.",
      "A stateless service requires sticky sessions."
    ],
    "answer": "A stateless service does not retain client context between requests.",
    "explanation": "Stateless services treat every request independently, containing all necessary information. This enables easy horizontal scaling, whereas stateful services require affinity to specific servers.",
    "difficulty": "Beginner"
  },
  {
    "id": 14,
    "question": "In Event-Driven Architecture, what is the role of an 'Event Bus'?",
    "options": [
      "To store events forever for audit purposes",
      "To transmit events between producers and consumers without them knowing each other",
      "To filter events based on user permissions",
      "To convert synchronous HTTP calls to asynchronous ones"
    ],
    "answer": "To transmit events between producers and consumers without them knowing each other",
    "explanation": "An Event Bus decouples senders (producers) from receivers (consumers). It routes events, allowing services to communicate indirectly. Persistence is a secondary feature of specific implementations like Kafka.",
    "difficulty": "Beginner"
  },
  {
    "id": 15,
    "question": "What is the primary benefit of using a Content Delivery Network (CDN)?",
    "options": [
      "To secure the database from SQL injection",
      "To reduce latency by serving content from geographically closer edge servers",
      "To balance load between application servers",
      "To compress server-side logic"
    ],
    "answer": "To reduce latency by serving content from geographically closer edge servers",
    "explanation": "CDNs cache static assets (images, CSS, video) in edge locations near users. This minimizes the physical distance data must travel, reducing latency and load on origin servers.",
    "difficulty": "Beginner"
  },
  {
    "id": 16,
    "question": "Which caching eviction policy removes the item that has not been used for the longest time?",
    "options": [
      "LFU (Least Frequently Used)",
      "LRU (Least Recently Used)",
      "FIFO (First In, First Out)",
      "LIFO (Last In, First Out)"
    ],
    "answer": "LRU (Least Recently Used)",
    "explanation": "LRU evicts the cache entry that has gone the longest without being accessed. LFU evicts the least frequently accessed item, and FIFO removes the oldest item regardless of access pattern.",
    "difficulty": "Beginner"
  },
  {
    "id": 17,
    "question": "What is 'Idempotency' in the context of API design?",
    "options": [
      "The ability of an API to handle multiple identical requests without causing side effects beyond the first request.",
      "The guarantee that a request returns data in the same format every time.",
      "The security measure that prevents unauthorized access.",
      "The process of converting XML to JSON."
    ],
    "answer": "The ability of an API to handle multiple identical requests without causing side effects beyond the first request.",
    "explanation": "An idempotent operation can be applied multiple times with the same result as a single execution (e.g., HTTP PUT/DELETE). This is crucial for handling retries safely.",
    "difficulty": "Beginner"
  },
  {
    "id": 18,
    "question": "Which design pattern helps a system detect failure and prevent cascading crashes by temporarily stopping requests to a failing service?",
    "options": [
      "Retry Pattern",
      "Circuit Breaker Pattern",
      "Sidecar Pattern",
      "Bulkhead Pattern"
    ],
    "answer": "Circuit Breaker Pattern",
    "explanation": "The Circuit Breaker stops calls to a service if failures reach a threshold, allowing the service time to recover. The Retry Pattern immediately retries, which can worsen the load during an outage.",
    "difficulty": "Beginner"
  },
  {
    "id": 19,
    "question": "What is 'Read Replication' used for?",
    "options": [
      "To improve write performance on the primary database",
      "To improve read performance by distributing read requests to copy databases",
      "To encrypt data at rest",
      "To merge data from two different tables"
    ],
    "answer": "To improve read performance by distributing read requests to copy databases",
    "explanation": "Read replicas are copies of the primary database that handle read traffic. This offloads the primary node, allowing it to focus exclusively on write operations.",
    "difficulty": "Beginner"
  },
  {
    "id": 20,
    "question": "In system design, what does 'Latency' refer to?",
    "options": [
      "The total number of requests processed per second.",
      "The time it takes for a unit of work (a request) to complete.",
      "The duration a system remains operational before crashing.",
      "The percentage of failed requests."
    ],
    "answer": "The time it takes for a unit of work (a request) to complete.",
    "explanation": "Latency measures the delay (time) between a request and its response. Throughput measures the volume of work over time (requests per second).",
    "difficulty": "Beginner"
  },
  {
    "id": 21,
    "question": "Which of the following is a characteristic of 'Strong Consistency' in a database?",
    "options": [
      "Reads may return stale data.",
      "A read guarantees the most recent write.",
      "The system remains available during a network partition.",
      "Data is written asynchronously."
    ],
    "answer": "A read guarantees the most recent write.",
    "explanation": "Strong consistency ensures that once a write is acknowledged, any subsequent read will return that updated value. This often comes at the cost of latency or availability during partitions.",
    "difficulty": "Beginner"
  },
  {
    "id": 22,
    "question": "What is the primary function of an Index in a database?",
    "options": [
      "To reduce the storage size of the table.",
      "To speed up data retrieval operations at the cost of write performance and storage.",
      "To enforce foreign key constraints.",
      "To backup the data."
    ],
    "answer": "To speed up data retrieval operations at the cost of write performance and storage.",
    "explanation": "Indexes create lookup structures (like B-Trees) to find rows quickly. However, they slow down INSERT/UPDATE operations (because the index must be updated) and consume disk space.",
    "difficulty": "Beginner"
  },
  {
    "id": 23,
    "question": "Why is 'Connection Pooling' used in database architectures?",
    "options": [
      "To encrypt the data passing between the app and the database.",
      "To reduce the overhead of establishing a new connection for every request.",
      "To allow multiple users to share the same username.",
      "To replicate the database across regions."
    ],
    "answer": "To reduce the overhead of establishing a new connection for every request.",
    "explanation": "Creating connections is expensive. Pooling maintains a set of open connections that can be reused, significantly improving performance and reducing latency.",
    "difficulty": "Beginner"
  },
  {
    "id": 24,
    "question": "What is 'Horizontal Partitioning' (often referred to as Sharding) primarily intended to address?",
    "options": [
      "Data security risks",
      "Scalability limits of a single database instance",
      "Slow SQL query syntax",
      "Lack of backups"
    ],
    "answer": "Scalability limits of a single database instance",
    "explanation": "Sharding splits a large database into smaller, faster, more easily managed parts (shards) spread across multiple servers. This addresses the limitation that a single server cannot hold infinite data.",
    "difficulty": "Beginner"
  },
  {
    "id": 25,
    "question": "Which HTTP status code is typically returned when a Rate Limiter has blocked a request?",
    "options": [
      "200 OK",
      "403 Forbidden",
      "429 Too Many Requests",
      "503 Service Unavailable"
    ],
    "answer": "429 Too Many Requests",
    "explanation": "HTTP 429 is the standard status code indicating the user has sent too many requests in a given amount of time. 503 usually indicates server overload, not specific client throttling.",
    "difficulty": "Beginner"
  },
  {
    "id": 26,
    "question": "What is a 'Cold Start' in Serverless computing?",
    "options": [
      "The time it takes to start the server physically.",
      "The delay that occurs when a function instance is created for the first time or after being idle.",
      "The process of cooling down a data center.",
      "A security check performed before code execution."
    ],
    "answer": "The delay that occurs when a function instance is created for the first time or after being idle.",
    "explanation": "Cold starts happen when a cloud provider allocates resources and initializes the runtime environment for a function, adding latency before the code executes.",
    "difficulty": "Beginner"
  },
  {
    "id": 27,
    "question": "Which hashing technique ensures that adding a server to a cache cluster minimizes the number of keys that need to be remapped?",
    "options": [
      "Modulo Hashing",
      "Consistent Hashing",
      "Random Hashing",
      "Linear Hashing"
    ],
    "answer": "Consistent Hashing",
    "explanation": "Consistent hashing maps keys to a continuum (ring), ensuring that adding or removing a server only affects the keys immediately adjacent to it. Modulo hashing changes almost every mapping.",
    "difficulty": "Beginner"
  },
  {
    "id": 28,
    "question": "What is 'Event Sourcing'?",
    "options": [
      "Storing only the current state of an entity.",
      "Persisting a sequence of state-changing events rather than just the current state.",
      "Triggering an event when the CPU usage is high.",
      "Sourcing events from a third-party API."
    ],
    "answer": "Persisting a sequence of state-changing events rather than just the current state.",
    "explanation": "Event sourcing stores all changes to an application state as a log of events. This allows for auditing and rebuilding state, unlike CRUD which overwrites the current state.",
    "difficulty": "Beginner"
  },
  {
    "id": 29,
    "question": "Which load balancing strategy ensures that a specific client always connects to the same server during a session?",
    "options": [
      "Round Robin",
      "Least Connections",
      "Session Affinity (Sticky Sessions)",
      "Random"
    ],
    "answer": "Session Affinity (Sticky Sessions)",
    "explanation": "Session Affinity routes a user's requests to the same server based on cookies or IP, ensuring session state is preserved. Other algorithms distribute requests without regard to history.",
    "difficulty": "Beginner"
  },
  {
    "id": 30,
    "question": "What is the purpose of the 'Sidecar Pattern' in microservices?",
    "options": [
      "To run multiple instances of the main application for load balancing.",
      "To deploy core application logic separately from infrastructure features like logging or monitoring.",
      "To scale the database vertically.",
      "To act as a hardware load balancer."
    ],
    "answer": "To deploy core application logic separately from infrastructure features like logging or monitoring.",
    "explanation": "The Sidecar pattern deploys utility components (networking, monitoring, config) alongside the main service in the same container/VM, keeping the main service logic clean.",
    "difficulty": "Beginner"
  },
  {
    "id": 31,
    "question": "In a 'Publish-Subscribe' messaging pattern, how do components interact?",
    "options": [
      "The subscriber sends a request directly to the publisher.",
      "The publisher sends messages to a topic, and the broker delivers them to all subscribers.",
      "The publisher polls the subscriber for updates.",
      "Both components share a database table."
    ],
    "answer": "The publisher sends messages to a topic, and the broker delivers them to all subscribers.",
    "explanation": "Pub/Sub decouples publishers from subscribers via a broker. Publishers broadcast to topics, and the broker distributes messages to interested subscribers asynchronously.",
    "difficulty": "Beginner"
  },
  {
    "id": 32,
    "question": "What is a 'Single Point of Failure' (SPOF)?",
    "options": [
      "A component whose failure stops the entire system from functioning.",
      "The moment when a software bug is first detected.",
      "A specific location in the data center.",
      "The initial step in deploying an application."
    ],
    "answer": "A component whose failure stops the entire system from functioning.",
    "explanation": "A SPOF is a critical part of a system with no redundancy. If that specific component fails, the entire service goes down, violating high availability principles.",
    "difficulty": "Beginner"
  },
  {
    "id": 33,
    "question": "Which of the following best describes 'Database Normalization'?",
    "options": [
      "Combining tables to reduce read time.",
      "Organizing data to reduce redundancy and improve data integrity.",
      "Replicating data across multiple servers.",
      "Deleting old data to save space."
    ],
    "answer": "Organizing data to reduce redundancy and improve data integrity.",
    "explanation": "Normalization involves structuring a relational database to reduce data dependency and duplication (anomalies). It typically involves splitting tables, though this can increase read query complexity.",
    "difficulty": "Beginner"
  },
  {
    "id": 34,
    "question": "What is the main benefit of using 'Asynchronous Communication' between microservices?",
    "options": [
      "It guarantees that the receiver is processing the message immediately.",
      "It allows the sender to continue processing without waiting for the receiver's response.",
      "It simplifies the debugging process.",
      "It removes the need for a message broker."
    ],
    "answer": "It allows the sender to continue processing without waiting for the receiver's response.",
    "explanation": "Asynchronous communication decouples the execution timeline; the sender fires an event/message and moves on. This improves resilience and performance, though it introduces eventual consistency.",
    "difficulty": "Beginner"
  },
  {
    "id": 35,
    "question": "What is the role of a 'Service Discovery' mechanism in a microservices architecture?",
    "options": [
      "To find the cost of running a specific service.",
      "To allow services to dynamically find the network location (IP/Port) of other services.",
      "To scan code for bugs before deployment.",
      "To archive logs of retired services."
    ],
    "answer": "To allow services to dynamically find the network location (IP/Port) of other services.",
    "explanation": "In dynamic environments (cloud/Kubernetes), service IP addresses change. Service Discovery (like Eureka, Consul, or DNS) enables services to locate and communicate with each other automatically.",
    "difficulty": "Beginner"
  },
  {
    "id": 36,
    "question": "In the context of the CAP theorem, how does a CP (Consistency and Partition Tolerance) database behave during a network partition?",
    "options": [
      "It continues to accept writes to maintain availability, resolving conflicts asynchronously.",
      "It rejects all write and read requests to prevent data divergence until the partition is healed.",
      "It routes all traffic to the nearest data center, accepting stale reads.",
      "It automatically promotes a replica node to master to ensure zero downtime."
    ],
    "answer": "It rejects all write and read requests to prevent data divergence until the partition is healed.",
    "explanation": "A CP system prioritizes consistency over availability; if nodes cannot communicate (partition), it must error or block requests to ensure all nodes see the same data. An AP system would accept writes and resolve conflicts later. Routing to the nearest data center implies eventual consistency (AP).",
    "difficulty": "Intermediate"
  },
  {
    "id": 37,
    "question": "What is the primary trade-off when implementing a Write-Through caching strategy?",
    "options": [
      "Data in the cache is highly likely to be stale compared to the database.",
      "Write latency is increased because data must be written to both the cache and the database.",
      "Read performance is degraded because the cache is frequently invalidated.",
      "The system becomes prone to race conditions during concurrent writes."
    ],
    "answer": "Write latency is increased because data must be written to both the cache and the database.",
    "explanation": "Write-Through ensures cache consistency by synchronously writing to the backing store and cache, which adds latency to the write path. Write-Back (or Write-Behind) improves write latency but risks data loss. Stale data is characteristic of Write-Back or Lazy Loading schemes.",
    "difficulty": "Intermediate"
  },
  {
    "id": 38,
    "question": "When using Consistent Hashing for load balancing, why is the addition or removal of a node efficient?",
    "options": [
      "It only requires rehashing the keys that map to the specific node added or removed.",
      "It automatically rebalances all keys across the cluster using a modulo operation.",
      "It requires a full cluster restart to update the hash table mapping.",
      "It eliminates the need for virtual nodes by using physical addressing."
    ],
    "answer": "It only requires rehashing the keys that map to the specific node added or removed.",
    "explanation": "Consistent hashing maps both data and nodes to a ring, ensuring that only the keys assigned to the affected node (and its immediate neighbors) need remapping. Modulo hashing requires rehashing all data when the node count changes.",
    "difficulty": "Intermediate"
  },
  {
    "id": 39,
    "question": "Which operation is strictly idempotent in the context of RESTful API design?",
    "options": [
      "POST /create-resource",
      "PATCH /update-resource",
      "DELETE /resource-id",
      "PUT /resource-id"
    ],
    "answer": "PUT /resource-id",
    "explanation": "PUT is idempotent because updating a resource with the same state multiple times yields the same result (the resource is in that specific state). DELETE is also idempotent, but standard teaching often highlights PUT's state replacement aspect as the classic definition; however, between PUT and DELETE, PUT is the strongest example of state idempotency. POST is not idempotent as it creates new resources. PATCH may or may not be idempotent depending on the implementation.",
    "difficulty": "Intermediate"
  },
  {
    "id": 40,
    "question": "How does a Chord protocol differ from a simple Rendezvous hashing strategy in a Distributed Hash Table (DHT)?",
    "options": [
      "Chord uses a ring topology to ensure O(log N) lookup complexity, whereas Rendezvous hashing scans all nodes.",
      "Chord requires a central directory to track node locations, while Rendezvous does not.",
      "Rendezvous hashing guarantees O(1) lookup time, while Chord guarantees O(N).",
      "Chord stores full replicas of data on every node, while Rendezvous stores fragments."
    ],
    "answer": "Chord uses a ring topology to ensure O(log N) lookup complexity, whereas Rendezvous hashing scans all nodes.",
    "explanation": "Chord organizes nodes in a ring and utilizes finger tables to achieve O(log N) lookups. Rendezvous hashing (Highest Random Weight) typically requires hashing the key against every node ID to find the highest weight, which is O(N).",
    "difficulty": "Intermediate"
  },
  {
    "id": 41,
    "question": "In a Microservices architecture, what is the primary function of the 'Sidecar' pattern?",
    "options": [
      "To act as an API Gateway routing external traffic to internal services.",
      "To isolate infrastructure concerns (logging, monitoring, config) from the business logic in the main application.",
      "To serve as a read-replica database for the primary service instance.",
      "To manage the UI state of the frontend application."
    ],
    "answer": "To isolate infrastructure concerns (logging, monitoring, config) from the business logic in the main application.",
    "explanation": "The Sidecar pattern deploys a helper process alongside the main service to abstract away cross-cutting concerns like networking or observability. API Gateway handles external routing. Read-replicas are database infrastructure components.",
    "difficulty": "Intermediate"
  },
  {
    "id": 42,
    "question": "What is a 'Split Brain' scenario in distributed systems, and how is it typically mitigated?",
    "options": [
      "It occurs when a network partition isolates nodes, leading to multiple leaders; mitigated by Quorum.",
      "It occurs when the database runs out of memory; mitigated by vertical scaling.",
      "It is a deadlock in multithreading; mitigated by lock ordering.",
      "It is a security breach in the firewall; mitigated by encryption."
    ],
    "answer": "It occurs when a network partition isolates nodes, leading to multiple leaders; mitigated by Quorum.",
    "explanation": "Split Brain happens when distinct sets of nodes believe they are the active master (or leader) due to a communication failure, causing data corruption. A Quorum (requiring a majority vote) prevents a minority partition from electing a leader.",
    "difficulty": "Intermediate"
  },
  {
    "id": 43,
    "question": "Why is the 'Two-Phase Commit' (2PC) protocol considered blocking and detrimental to system availability?",
    "options": [
      "It requires only one participant to commit, speeding up the process.",
      "If the coordinator fails, participants must keep their locks held indefinitely while waiting for resolution.",
      "It allows participants to commit their transactions independently without coordination.",
      "It relies on asynchronous communication which never fails."
    ],
    "answer": "If the coordinator fails, participants must keep their locks held indefinitely while waiting for resolution.",
    "explanation": "In 2PC, if the coordinator fails after sending the 'prepare' phase, participants are blocked in a 'prepared' state with resources locked until the coordinator recovers. This reduces availability and creates a bottleneck.",
    "difficulty": "Intermediate"
  },
  {
    "id": 44,
    "question": "When designing a system for high write throughput, which database engine configuration is theoretically optimal?",
    "options": [
      "A normalized SQL database with heavy foreign key constraints.",
      "A Log-Structured Merge-tree (LSM tree) based storage engine.",
      "A B-Tree based storage engine with high read optimization.",
      "A single-node relational database with ACID compliance."
    ],
    "answer": "A Log-Structured Merge-tree (LSM tree) based storage engine.",
    "explanation": "LSM trees (used in Cassandra, HBase, RocksDB) turn random writes into sequential writes in memory (MemTable), which are flushed to disk, offering significantly higher write throughput than B-Trees which require random disk I/O for updates.",
    "difficulty": "Intermediate"
  },
  {
    "id": 45,
    "question": "What is the specific advantage of using a Bloom filter as a pre-check in a database read path?",
    "options": [
      "It guarantees that the data exists on the disk.",
      "It eliminates the need for a database index.",
      "It rapidly detects if an element is definitely not in a set, reducing disk I/O for non-existent keys.",
      "It compresses the actual database records to save storage space."
    ],
    "answer": "It rapidly detects if an element is definitely not in a set, reducing disk I/O for non-existent keys.",
    "explanation": "Bloom filters are space-efficient probabilistic structures that guarantee no false negatives; if the filter says 'no', the key is definitely not there. This saves expensive disk lookups for missing data (preventing cache penetration), though they can have false positives.",
    "difficulty": "Intermediate"
  },
  {
    "id": 46,
    "question": "In the context of Load Balancing algorithms, why might 'Least Connections' be preferred over 'Round Robin'?",
    "options": [
      "Round Robin ignores server weight, whereas Least Connections prioritizes it.",
      "Least Connections directs traffic based on server capacity rather than request count.",
      "Least Connections accounts for servers with differing request processing times to prevent overload.",
      "Round Robin requires sticky sessions, while Least Connections does not."
    ],
    "answer": "Least Connections accounts for servers with differing request processing times to prevent overload.",
    "explanation": "Least Connections routes requests to the server with the fewest active connections, preventing a server from being overloaded while it processes long-running tasks, whereas Round Robin blindly distributes traffic regardless of load duration.",
    "difficulty": "Intermediate"
  },
  {
    "id": 47,
    "question": "What distinguishes 'Optimistic Locking' from 'Pessimistic Locking' in database transaction management?",
    "options": [
      "Optimistic locking reads the data and checks for version changes on write; Pessimistic locking locks the data immediately upon read.",
      "Optimistic locking uses database-level mutexes; Pessimistic locking uses application-level retries.",
      "Optimistic locking prevents dirty reads; Pessimistic locking prevents phantom reads.",
      "Optimistic locking is only for reads; Pessimistic locking is only for writes."
    ],
    "answer": "Optimistic locking reads the data and checks for version changes on write; Pessimistic locking locks the data immediately upon read.",
    "explanation": "Optimistic locking assumes low contention and validates data versions only at commit time. Pessimistic locking assumes high contention and acquires a database lock on the resource immediately to block others.",
    "difficulty": "Intermediate"
  },
  {
    "id": 48,
    "question": "Which property of the CAP theorem forces a system to return an error or timeout during a partition if it chooses Consistency?",
    "options": [
      "Partition Tolerance",
      "High Availability",
      "Consistency",
      "Latency"
    ],
    "answer": "High Availability",
    "explanation": "According to the CAP theorem, a system can only provide two of the three guarantees. If a system chooses Consistency and Partition Tolerance (CP), it must sacrifice Availability (stop accepting writes) to prevent divergence.",
    "difficulty": "Intermediate"
  },
  {
    "id": 49,
    "question": "In a Publish/Subscribe (Pub/Sub) system using topics, what mechanism ensures that a message is not lost if a subscriber is down?",
    "options": [
      "The Publisher buffers the message indefinitely.",
      "The Subscriber pushes a 'NACK' (Negative Acknowledgement) to the Publisher.",
      "Durable Queues or Subscriptions retain messages for the subscriber until they are consumed.",
      "The load balancer detects the failure and routes to a different subscriber."
    ],
    "answer": "Durable Queues or Subscriptions retain messages for the subscriber until they are consumed.",
    "explanation": "Durable subscriptions (supported by systems like Kafka or RabbitMQ) persist messages on the broker's disk. The publisher sends once, and the broker holds the message until the specific durable subscriber comes back online and acknowledges it.",
    "difficulty": "Intermediate"
  },
  {
    "id": 50,
    "question": "When comparing HTTP/1.1 and HTTP/2, which feature significantly reduces the overhead of establishing connections?",
    "options": [
      "Multiplexing allows multiple requests over a single TCP connection.",
      "Binary encoding reduces header size.",
      "Server Push allows sending resources before they are requested.",
      "Header Compression (HPACK) reduces text redundancy."
    ],
    "answer": "Multiplexing allows multiple requests over a single TCP connection.",
    "explanation": "While header compression helps, Multiplexing is the primary architectural change that allows multiple requests/responses to run in parallel over a single TCP connection, eliminating the need for multiple TCP handshakes (Head-of-Line blocking removal).",
    "difficulty": "Intermediate"
  },
  {
    "id": 51,
    "question": "What is the 'Thundering Herd' problem, and how does it relate to cache expiry?",
    "options": [
      "It occurs when multiple threads write to the same cache key simultaneously.",
      "It happens when a hot cache entry expires, causing a flood of requests to hit the origin database simultaneously.",
      "It is a network storm caused by multicast packets.",
      "It occurs when a database fails over to a replica, causing latency."
    ],
    "answer": "It happens when a hot cache entry expires, causing a flood of requests to hit the origin database simultaneously.",
    "explanation": "When a popular key expires, many concurrent requests might miss the cache and all query the database to repopulate it. This is mitigated by 'Locking' or 'Stale-While-Revalidate' to allow only one request to update the cache.",
    "difficulty": "Intermediate"
  },
  {
    "id": 52,
    "question": "Which database partitioning strategy is most effective for a dataset where queries predominantly request a specific 'User' and all associated data?",
    "options": [
      "Range Partitioning",
      "Hash Partitioning",
      "Vertical Partitioning",
      "Directory-based Partitioning"
    ],
    "answer": "Hash Partitioning",
    "explanation": "Hash partitioning (or consistent hashing based on UserID) ensures that all data for a specific user is located on the same shard. Range partitioning can lead to hotspots, and Vertical partitioning separates by column, not row distribution.",
    "difficulty": "Intermediate"
  },
  {
    "id": 53,
    "question": "What is the primary function of a 'Circuit Breaker' in a distributed system?",
    "options": [
      "To reroute traffic to a backup data center.",
      "To prevent a cascading failure by stopping calls to a failing service after a threshold is reached.",
      "To compress data packets before transmission.",
      "To limit the rate of incoming requests per IP address."
    ],
    "answer": "To prevent a cascading failure by stopping calls to a failing service after a threshold is reached.",
    "explanation": "A Circuit Breaker detects when a remote service is failing (e.g., high timeout rate) and 'trips' to immediately reject calls, preventing the client from exhausting resources waiting on the failed service. This allows the failing service time to recover.",
    "difficulty": "Intermediate"
  },
  {
    "id": 54,
    "question": "Why is 'Event Sourcing' distinct from traditional state persistence in a database?",
    "options": [
      "It stores only the current state of the entity.",
      "It stores a sequence of state-changing events rather than just the current state.",
      "It uses a NoSQL database instead of SQL.",
      "It requires a monolithic architecture to function correctly."
    ],
    "answer": "It stores a sequence of state-changing events rather than just the current state.",
    "explanation": "Event Sourcing persists the history of changes (events) as the source of truth. The current state is derived by replaying these events. Traditional persistence overwrites the current state, losing the history of how it was reached.",
    "difficulty": "Intermediate"
  },
  {
    "id": 55,
    "question": "What is the primary disadvantage of using a SQL database for 'Graph' relationships compared to a native Graph Database?",
    "options": [
      "SQL databases cannot handle ACID transactions.",
      "Recursive traversal of multi-hop relationships requires expensive JOINs.",
      "SQL databases do not support indexing.",
      "Graph databases cannot scale horizontally."
    ],
    "answer": "Recursive traversal of multi-hop relationships requires expensive JOINs.",
    "explanation": "In SQL, querying friends-of-friends (N-depth) requires self-joins which are computationally expensive (O(N^M)). Graph databases use index-free adjacency (pointers) allowing O(N) traversal performance.",
    "difficulty": "Intermediate"
  },
  {
    "id": 56,
    "question": "In a Distributed System, what does 'Vector Clock' logic help to resolve?",
    "options": [
      "Network packet loss.",
      "Determining causality between events in different replicas.",
      "Authenticating user identity.",
      "Encrypting data at rest."
    ],
    "answer": "Determining causality between events in different replicas.",
    "explanation": "Vector Clocks track the version history of data across distributed nodes without a central clock. They allow the system to determine if one event happened before, after, or concurrently with another (causality detection), helping to resolve conflicts in eventual consistency models.",
    "difficulty": "Intermediate"
  },
  {
    "id": 57,
    "question": "What characterizes a 'Stateful' service versus a 'Stateless' service in a scaling context?",
    "options": [
      "Stateful services require sticky sessions (affinity) to route requests to the same server holding the session context.",
      "Stateful services do not require a database.",
      "Stateless services store user data in the local file system.",
      "Stateless services cannot be load balanced."
    ],
    "answer": "Stateful services require sticky sessions (affinity) to route requests to the same server holding the session context.",
    "explanation": "Stateful services retain client context (session state) in memory between requests, necessitating that the load balancer routes subsequent requests to the same specific server. Stateless services treat every request independently and can be scaled horizontally without affinity.",
    "difficulty": "Intermediate"
  },
  {
    "id": 58,
    "question": "Why is 'Vertical Partitioning' (Row Splitting) used in database design?",
    "options": [
      "To distribute data across multiple physical servers.",
      "To separate columns with different access patterns into different tables to optimize cache and I/O.",
      "To encrypt sensitive data in the database.",
      "To increase the write throughput of the master node."
    ],
    "answer": "To separate columns with different access patterns into different tables to optimize cache and I/O.",
    "explanation": "Vertical partitioning splits a 'wide' table by columns (e.g., putting rarely accessed 'comments' in a separate table from 'user_profile'). This reduces the amount of data read from disk for frequent queries that only need the core columns.",
    "difficulty": "Intermediate"
  },
  {
    "id": 59,
    "question": "What is the 'Lease' mechanism used in Leader Election and Distributed Locks?",
    "options": [
      "A cryptographic key used to encrypt communication.",
      "A time-bounded grant that expires if not renewed, preventing deadlocks during failures.",
      "A permanent token given to a master node.",
      "A database transaction isolation level."
    ],
    "answer": "A time-bounded grant that expires if not renewed, preventing deadlocks during failures.",
    "explanation": "A lease has an expiration time (TTL). If the leader crashes or gets partitioned, the lease expires automatically, allowing other nodes to claim leadership. This avoids the 'Split Brain' scenario where a failed leader holds a lock forever.",
    "difficulty": "Intermediate"
  },
  {
    "id": 60,
    "question": "In the context of NoSQL databases, what does 'Eventually Consistent' mean?",
    "options": [
      "Data is guaranteed to be consistent across all nodes immediately after a write.",
      "The system will become consistent if no new updates are made to the data item, but reads may return stale data.",
      "Data is written asynchronously to a single node.",
      "The system sacrifices partition tolerance for consistency."
    ],
    "answer": "The system will become consistent if no new updates are made to the data item, but reads may return stale data.",
    "explanation": "Eventual consistency guarantees that if an update is made, eventually all accesses will return that update. However, intermediate reads may return stale data until the propagation finishes.",
    "difficulty": "Intermediate"
  },
  {
    "id": 61,
    "question": "Which cache eviction policy approximates the Least Recently Used (LRU) algorithm using a probabilistic approach?",
    "options": [
      "LFU (Least Frequently Used)",
      "FIFO (First In First Out)",
      "ARC (Adaptive Replacement Cache)",
      "W-TinyLFU (Window-TinyLFU)"
    ],
    "answer": "ARC (Adaptive Replacement Cache)",
    "explanation": "ARC attempts to improve upon LRU by dynamically balancing between recency and frequency using a probabilistic history list. LFU tracks frequency. W-TinyLFU uses a frequency sketch. While all are advanced, ARC is the classic probabilistic improvement over standard LRU logic, though W-TinyLFU is the modern heavy hitter. For intermediate certification, ARC is the standard 'better LRU' distractor/correct logic, but technically W-TinyLFU relies on Count-Min Sketch. Let's correct the focus: **LFU** tracks frequency, **LRU** tracks recency. **ARC** manages the balance.",
    "difficulty": "Intermediate"
  },
  {
    "id": 62,
    "question": "What is the primary benefit of using gRPC over REST for internal microservice communication?",
    "options": [
      "gRPC uses human-readable JSON format.",
      "gRPC uses Protocol Buffers (binary) and HTTP/2, offering lower latency and built-in code generation.",
      "gRPC is stateless, while REST is stateful.",
      "gRPC runs directly on the network layer, bypassing TCP."
    ],
    "answer": "gRPC uses Protocol Buffers (binary) and HTTP/2, offering lower latency and built-in code generation.",
    "explanation": "gRPC leverages HTTP/2 for multiplexing and binary Protocol Buffers for serialization, which is faster and lighter than JSON/Text. It also defines the service interface in .proto files, generating client/server code stubs automatically.",
    "difficulty": "Intermediate"
  },
  {
    "id": 63,
    "question": "How does a 'Read Replica' function in a standard database setup?",
    "options": [
      "It accepts both read and write traffic and syncs to the master.",
      "It asynchronously replicates data from the Master node and handles read traffic to scale reads.",
      "It performs shard splitting on the write master.",
      "It acts as a transaction coordinator."
    ],
    "answer": "It asynchronously replicates data from the Master node and handles read traffic to scale reads.",
    "explanation": "Read Replicas copy data changes from a write-primary Master. They allow scaling of read operations by offloading SELECT queries from the Master, which handles all write operations.",
    "difficulty": "Intermediate"
  },
  {
    "id": 64,
    "question": "In System Design, what is 'Backpressure'?",
    "options": [
      "The force exerted by a cooling fan in a server rack.",
      "A mechanism to handle flow control when a producer produces data faster than a consumer can process it.",
      "The security policy applied to incoming DDoS traffic.",
      "The latency caused by database index rebuilding."
    ],
    "answer": "A mechanism to handle flow control when a producer produces data faster than a consumer can process it.",
    "explanation": "Backpressure signals the producer to slow down or buffer data when the consumer is overwhelmed, preventing resource exhaustion (OOM) or crash. It is crucial in streaming systems (e.g., Kafka, Reactive streams).",
    "difficulty": "Intermediate"
  },
  {
    "id": 65,
    "question": "What is the 'Facade' pattern as applied to Microservices (specifically regarding API Gateways)?",
    "options": [
      "It merges multiple microservices into a single deployable unit.",
      "It provides a simplified, unified interface to a set of interfaces within a subsystem, hiding complexity.",
      "It encrypts all traffic between services.",
      "It acts as a load balancer for the database."
    ],
    "answer": "It provides a simplified, unified interface to a set of interfaces within a subsystem, hiding complexity.",
    "explanation": "The Facade pattern (often implemented by an API Gateway) aggregates calls to multiple underlying microservices into a single endpoint for the client, reducing chattiness and hiding backend complexity.",
    "difficulty": "Intermediate"
  },
  {
    "id": 66,
    "question": "When designing a URL Shortener (like Bit.ly), why is a base-62 encoding scheme (a-z, A-Z, 0-9) often used for the unique ID?",
    "options": [
      "It provides encryption for the original URL.",
      "It compresses the 64-bit integer database ID into a shorter string of alphanumeric characters.",
      "It ensures that the URL is case-insensitive.",
      "It prevents SQL injection attacks on the database."
    ],
    "answer": "It compresses the 64-bit integer database ID into a shorter string of alphanumeric characters.",
    "explanation": "Base-62 encoding represents large numbers (unique IDs) as short strings, maximizing the number of permutations with the fewest characters. It is efficient for storage and user experience, though case-sensitivity can be a UX downside.",
    "difficulty": "Intermediate"
  },
  {
    "id": 67,
    "question": "What is the 'Virtual Node' concept in Consistent Hashing?",
    "options": [
      "A serverless function instance.",
      "Multiple logical points on the hash ring assigned to a single physical machine to ensure balanced distribution.",
      "A Docker container running a hypervisor.",
      "A backup database node."
    ],
    "answer": "Multiple logical points on the hash ring assigned to a single physical machine to ensure balanced distribution.",
    "explanation": "Without virtual nodes, a physical node only owns one range on the ring, leading to potential data imbalance. By assigning many virtual nodes (random IDs) to one physical node, the data is distributed more uniformly across the cluster.",
    "difficulty": "Intermediate"
  },
  {
    "id": 68,
    "question": "In a 'Sharded' database architecture, what is the 'Routing Layer' responsible for?",
    "options": [
      "Encrypting the data before it reaches the shard.",
      "Maintaining a mapping table or service to determine which shard holds a specific data key.",
      "Replicating data across all shards.",
      "Compressing the database logs."
    ],
    "answer": "Maintaining a mapping table or service to determine which shard holds a specific data key.",
    "explanation": "The routing layer (often a Config Service or Directory Service) tracks the metadata of which key-range or hash belongs to which shard. It directs queries to the correct database instance.",
    "difficulty": "Intermediate"
  },
  {
    "id": 69,
    "question": "Which strategy allows a system to handle 'Hot Partitions' in a sharded database?",
    "options": [
      "Increasing the RAM on the database server.",
      "Rebalancing or splitting the hot partition into smaller ranges and distributing them.",
      "Switching from SQL to NoSQL.",
      "Disabling write operations on the hot partition."
    ],
    "answer": "Rebalancing or splitting the hot partition into smaller ranges and distributing them.",
    "explanation": "A hot partition receives disproportionate traffic. The solution is to split the range or hash space of that partition into two (or more) and move them to different nodes (resharding) to spread the load.",
    "difficulty": "Intermediate"
  },
  {
    "id": 70,
    "question": "What is the primary function of a 'Message Broker' (like RabbitMQ) compared to a 'Log Aggregator' (like Kafka)?",
    "options": [
      "Brokers are designed for high-throughput streaming; Aggregators are for enterprise messaging.",
      "Brokers typically delete messages after consumption; Aggregators retain messages for a duration.",
      "Brokers use pull-based consumption; Aggregators use push-based.",
      "There is no technical difference; the terms are interchangeable."
    ],
    "answer": "Brokers typically delete messages after consumption; Aggregators retain messages for a duration.",
    "explanation": "Traditional Message Queues (RabbitMQ) track consumption and remove messages once acknowledged by a consumer. Log-based systems (Kafka) persist messages for a set retention period (regardless of consumption) to support replay and multiple independent consumers.",
    "difficulty": "Intermediate"
  }
]